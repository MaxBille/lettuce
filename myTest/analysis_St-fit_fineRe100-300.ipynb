{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "res = np.arange(100,320,20)  # Re 100-300 in steps of 20\n",
    "bcs = [\"hwbbc2\", \"ibb1c2\"]\n",
    "\n",
    "base_path = \"/home/mbille/Documents/cluster_hbrs_home/02_lbm_simulations/data_231031_c2d_compare3D_fineRe100-300_GPD30_DpY10_BGK_T300\"\n",
    "\n",
    "paths_dict = dict() # path matches\n",
    "res_dict = dict() # lists of available gpds\n",
    "\n",
    "# create path_dict: keys= bc_col Combination, values: lists of paths to gpd-variants\n",
    "for bc in bcs:\n",
    "    paths_dict[bc] = []\n",
    "    res_dict[bc] = []\n",
    "    for re in res:\n",
    "        dir_names = glob(base_path+\"/*c2d_compare3D_fineRe100-300_GPD30_DpY10_BGK_T300_\"+bc+\"_Re\"+str(re)+\"_*\")\n",
    "        if len(dir_names)>1:\n",
    "            print(\"(!) Warning: more than 1 simulation for:\", bc+\"_Re\"+str(re))\n",
    "            print(dir_names)\n",
    "        elif len(dir_names) == 1:\n",
    "            # this is what we want: one unique simulation found\n",
    "            paths_dict[bc].append(*dir_names)\n",
    "            res_dict[bc].append(re)\n",
    "\n",
    "#        print(base_path+\"/*c2d_compare3D_fineRe100-300_GPD30_DpY10_BGK_T300_\"+bc+\"_Re\"+str(re)+\"_*\")\n",
    "#        print(bc+\"_Re\"+str(re)+\"_*:\",dir_names)\n",
    "#        print(paths_dict[bc])\n",
    "\n",
    "#print(gpds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# FIT SINE WAVE -> STROUHAL NUMBER\n",
    "#res = np.arange(100,320,20)  # Re 100-300 in steps of 20\n",
    "bcs = [\"hwbbc2\", \"ibb1c2\"]\n",
    "\n",
    "filename = \"/lift_coefficient.txt\"\n",
    "periodic_start=0.9\n",
    "\n",
    "# function to fit\n",
    "def sine_func(xx,a,b,c,d):\n",
    "    return a*np.sin(2*np.pi*b*xx+c)+d\n",
    "\n",
    "for bc in bcs:\n",
    "    lift_St_fit = np.zeros((2,len(res_dict[bc])))\n",
    "    lift_St_fit[0] = res_dict[bc]\n",
    "    for re_i in range(len(lift_St_fit[0])):\n",
    "        # load timeseries\n",
    "        lift_timeseries = np.loadtxt(paths_dict[bc][re_i]+filename)\n",
    "        ph=periodic_start\n",
    "        if res_dict[bc][re_i] == 300:\n",
    "            periodic_start=0.95\n",
    "        lift_converged = lift_timeseries[int(lift_timeseries.shape[0]*periodic_start-1):]\n",
    "        periodic_start=ph\n",
    "\n",
    "        # fit sine_wave\n",
    "        coefficients, sheeesh = curve_fit(sine_func, lift_converged[:,1], lift_converged[:,2], p0=(0.7,0.2,0.5,0))\n",
    "\n",
    "        # plot fit and save to Desktop/St_Fits/...\n",
    "        fig, ax = plt.subplots(constrained_layout=True)\n",
    "        plt.plot(lift_converged[:,1], lift_converged[:,2], lift_converged[:,1], sine_func(lift_converged[:,1], *coefficients))\n",
    "        plt.legend([\"lift\", \"fit\"])\n",
    "        ax.set_xlabel(\"physical time / s\")\n",
    "        ax.set_ylabel(\"Coefficient of Lift\")\n",
    "        ax.set_ylim([-1,1])\n",
    "        plt.savefig(\"/home/mbille/Desktop/St_Fits/St_LiftFit_2D_\"+bc+\"_Re\"+str(res_dict[bc][re_i])+\".png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # store St\n",
    "        lift_St_fit[1,re_i]=coefficients[1]\n",
    "    np.savetxt(\"/home/mbille/Desktop/St_Fits/St_LiftFit_2D_\"+bc+\"-St(Re).txt\", lift_St_fit, header=\"2D, DpY19, D2Q9, \"+bc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# AVERAGE PEAKS OF LIFT -> Cl_max(mean)\n",
    "\n",
    "#bcs= [\"fwbb\"]\n",
    "#cols=[\"kbc\"]\n",
    "\n",
    "filename = \"/lift_coefficient.txt\"\n",
    "periodic_start=0.75\n",
    "\n",
    "for bc in bcs:\n",
    "    lift_Cl_maxmean = np.zeros((2,len(res_dict[bc])))\n",
    "    lift_Cl_maxmean[0] = res_dict[bc]\n",
    "    for re_i in range(len(lift_Cl_maxmean[0])):\n",
    "        # load timeseries\n",
    "        lift_timeseries = np.loadtxt(paths_dict[bc][re_i]+filename)\n",
    "        lift_converged = lift_timeseries[int(lift_timeseries.shape[0]*periodic_start-1):]\n",
    "\n",
    "        # find peaks\n",
    "        #peaks_max = find_peaks(lift_converged[:,2], prominence=lift_converged[:,2].max())  # prominence: \"the minimum height necessary to descend to get from the summit to any higher terrain\"\n",
    "        peaks_max = find_peaks(lift_converged[:,2], prominence=lift_converged[:,2].max()-(lift_converged[:,2].max()+lift_converged[:,2].min())*0.5)\n",
    "        lift_Cl_maxmean[1,re_i] = lift_converged[peaks_max[0],2].mean()\n",
    "\n",
    "        # plot fit and save to Desktop/St_Fits/...\n",
    "        fig, ax = plt.subplots(constrained_layout=True)\n",
    "        ax.plot(lift_timeseries[:,1], lift_timeseries[:,2])\n",
    "        plt.scatter(lift_converged[peaks_max[0],1],lift_converged[peaks_max[0],2],marker=\"+\", facecolors=\"r\")\n",
    "        plt.axhline(y=lift_Cl_maxmean[1,re_i], color=\"r\", ls=\"--\", lw=0.5)\n",
    "        plt.legend([\"lift\", \"Cl_maxmean\"])\n",
    "        ax.set_xlabel(\"physical time / s\")\n",
    "        ax.set_ylabel(\"Coefficient of Lift\")\n",
    "        ax.set_ylim([-1,1])\n",
    "        plt.savefig(\"/home/mbille/Desktop/Cl_Peaks/Cl_Peaks_2D_\"+bc+\"_Re\"+str(res_dict[bc][re_i])+\".png\")\n",
    "        plt.close(fig)\n",
    "    np.savetxt(\"/home/mbille/Desktop/Cl_Peaks/Cl_Peaks_2D_\"+bc+\"-Cl(Re).txt\", lift_Cl_maxmean, header=\"2D, DpY19, D2Q9, \"+bc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.7215750477431399"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_converged[:,2].min()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7213720431780384"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_converged[:,2].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
