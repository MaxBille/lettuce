{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant:  h2\n",
      "logVRAM:  False\n",
      "calcForceCoefficients: True\n",
      "logVRAM is True so choose n_steps\n",
      "dir_name: /data_230929_132431_test_reporter_bug\n",
      "using IBB1 from h2\n",
      "Re_g =  39.9999999999998\n",
      "IBB initialization took 0.14382481575012207seconds\n",
      "shape_LU: 400 x 200 x 60\n",
      "T with 2 steps: 0.01 seconds\n",
      "n_steps to simulate 1 second: 173.21 steps\n",
      "n_steps to simulate 140 seconds: 24249.4 steps\n",
      "GPD = 5\n",
      "area_rel: 1.0695212175775366\n",
      "(!) Lift times rho, force_sum, FCoeff:  3.9999576983973384e-08 7.520000508520752e-06 2.7439999030320905e-05\n",
      " - O.R. i, time: 0 0.00011968900071224198\n",
      " - O.R.observable() i, time: 0 0.00011706900113495067\n",
      "(!) Drag times: rho, force_sum, FCoeff:  4.999856173526496e-08 3.0600003810832277e-06 1.3750001016887836e-05\n",
      " - O.R. i, time: 0 4.669900044973474e-05\n",
      " - O.R.observable() i, time: 0 4.500899922277313e-05\n",
      "(!) Lift times rho, force_sum, FCoeff:  3.9999576983973384e-08 2.0099996618228033e-06 1.1400001312722452e-05\n",
      " - O.R. i, time: 1 0.4335684960005892\n",
      " - O.R.observable() i, time: 1 0.4335656059993198\n",
      "(!) Drag times: rho, force_sum, FCoeff:  7.00001692166552e-08 4.220000846544281e-06 9.195900020131376e-05\n",
      " - O.R. i, time: 1 0.0001322879998042481\n",
      " - O.R.observable() i, time: 1 0.0001301180000155\n",
      "(!) Lift times rho, force_sum, FCoeff:  3.9999576983973384e-08 2.0300012693041936e-06 1.1590000212891027e-05\n",
      " - O.R. i, time: 2 0.40592864000063855\n",
      " - O.R.observable() i, time: 2 0.40592586000093434\n",
      "(!) Drag times: rho, force_sum, FCoeff:  5.00003807246685e-08 4.1500006773276255e-06 7.94890001998283e-05\n",
      " - O.R. i, time: 2 0.00011838899990834761\n",
      " - O.R.observable() i, time: 2 0.00011630900007730816\n",
      "MLUPS: 11.352388468741983\n",
      "PU-Time:  0.011547005383792518  seconds\n",
      "number of steps: 2\n",
      "runtime:  0.8457322120666504 seconds ( 0.01 minutes )\n",
      "collision avg. time: 0.0009387890004290966 seconds (0.22 %)\n",
      "streaming avg. time: 0.000896859500244318 seconds (0.21 %)\n",
      "boundary avg. time: 0.00097215849928034 seconds (0.23 %)\n",
      "reporter avg. time: 0.41991336600040086 seconds (99.34 %)\n",
      "current VRAM (MB):  1121.95556640625\n",
      "max. VRAM (MB):  5374.8515625\n",
      "CPU % avg. over last 1 min, 5 min, 15 min;  0.32 0.86 1.33\n",
      "current total RAM usage [MB]: 7106.01 of 64220.02 MB\n",
      "peak-finding didn't work... probably no significant peaks visible (Re<46?), or periodic region not reached (T too small)\n",
      "Cd, simple mean: 6.405986852087151e-14\n",
      "Cl_peaks: \n",
      "min 7.216449660063514e-15 \n",
      "max 7.216449660063514e-15\n",
      "Frequency Peak: 0.0 +- 57.73502691896257 Hz\n"
     ]
    }
   ],
   "source": [
    "import lettuce as lt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from lettuce import LettuceException\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from lettuce.unit import UnitConversion\n",
    "from lettuce.util import append_axes\n",
    "from lettuce.boundary import SlipBoundary, EquilibriumBoundaryPU, BounceBackBoundary, HalfwayBounceBackBoundary, FullwayBounceBackBoundary, EquilibriumOutletP, AntiBounceBackOutlet\n",
    "# from lettuce.flows.obstaclemax3D import ObstacleMax3D\n",
    "#from lettuce.flows.obstacleCylinder import ObstacleCylinder\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import shutil\n",
    "from pyevtk.hl import imageToVTK\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "##################################################\n",
    "# ARGUMENT PARSING\n",
    "# parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "# parser.add_argument(\"--re\", default=200, type=float, help=\"Reynolds number\")\n",
    "# parser.add_argument(\"--n_steps\", default=100000, type=int, help=\"number of steps to simulate, overwritten by t_target, if t_target is >0\")\n",
    "# parser.add_argument(\"--gpd\", default=20, type=int, help=\"number of gridpoints per diameter\")\n",
    "# parser.add_argument(\"--dpx\", default=0, type=int, help=\"domain length in diameters\")\n",
    "# parser.add_argument(\"--dpy\", default=19, type=float, help=\"domain height in diameters\")\n",
    "# parser.add_argument(\"--dpz\", default=0, type=float, help=\"domain width in diameters\")\n",
    "# parser.add_argument(\"--t_target\", default=0, type=float, help=\"time in PU to simulate\")\n",
    "# parser.add_argument(\"--collision\", default=\"bgk\", help=\"collision operator (bgk, kbc, reg)\")\n",
    "# parser.add_argument(\"--lateral_walls\", default='periodic', help=\"boundary condition in y direction (periodic, bounceback, slip)\")\n",
    "# parser.add_argument(\"--bc_type\", default='fwbb', help=\"bounce back algorithm (fwbb, hwbb, ibb1)\")\n",
    "# parser.add_argument(\"--name\", default=\"3Dcylinder\", help=\"name of the simulation, appears in output directory name\")\n",
    "# parser.add_argument(\"--stencil\", default=\"D3Q27\", help=\"stencil (D3Q27, D3Q19, D3Q15)\")\n",
    "# parser.add_argument(\"--output_vtk\", default=False, help=\"output vtk-data with 10 fps (large!)\")\n",
    "# parser.add_argument(\"--device\", default=\"cuda:0\", help=\"cuda-device for multi-gpu nodes cuda:[0,1,2,3]\")\n",
    "# parser.add_argument(\"--calcDragLift\", default=True, type=bool, help=\"calculate and output drag- and lift-coefficient over time\")\n",
    "# parser.add_argument(\"--calcUProfiles\", default=False, type=bool, help=\"calculate average velocity profiles as in Di Ilio et al. 2018 and output plots and time-averages data for plots\")\n",
    "# parser.add_argument(\"--outputUProfiles\", default=False, type=bool, help=\"output average velocity profiles over time (full timeseries)\")\n",
    "# parser.add_argument(\"--nan_reporter\", default=False, type=bool, help=\"stop simulation if NaN is detected in f field\")\n",
    "# parser.add_argument(\"--logVRAM\", default=0, type=int, help=\"run 1 step and log the VRAM over all substeps\")\n",
    "# parser.add_argument(\"--variant\", default=\"ref\", help=\"which variant of IBB1 and simulation class to use (ref, h1, h2, dv1, dv2)\")\n",
    "#\n",
    "# args = vars(parser.parse_args())\n",
    "args = dict()\n",
    "\n",
    "args[\"re\"] = 200\n",
    "args[\"n_steps\"] = 2\n",
    "args[\"gpd\"] = 5\n",
    "args[\"dpx\"] = 0\n",
    "args[\"dpy\"] = 40\n",
    "args[\"dpz\"] = 12\n",
    "args[\"t_target\"] = 0\n",
    "args[\"collision\"] = \"bgk\"\n",
    "args[\"lateral_walls\"] = \"periodic\"\n",
    "args[\"bc_type\"] = 'ibb1'\n",
    "args[\"name\"] = \"test_reporter_bug\"\n",
    "args[\"stencil\"] = \"D3Q27\"\n",
    "args[\"output_vtk\"] = False\n",
    "args[\"device\"] = \"cuda:0\"\n",
    "args[\"calcDragLift\"] = True\n",
    "args[\"calcUProfiles\"] = False\n",
    "args[\"outputUProfiles\"] = False\n",
    "args[\"nan_reporter\"] = False\n",
    "args[\"logVRAM\"] = False\n",
    "args[\"variant\"] = \"h2\"\n",
    "\n",
    "\n",
    "\n",
    "device = args[\"device\"]  # also taken as \"cuda_device\" below (!)\n",
    "#logVRAM = args[\"logVRAM\"]\n",
    "variant = args[\"variant\"]\n",
    "calculate_force_coefficients = args[\"calcDragLift\"]\n",
    "\n",
    "##################################################\n",
    "# START VRAM-log if requested\n",
    "\n",
    "if args[\"logVRAM\"]:\n",
    "    def log_VRAM(title):\n",
    "       timestamp1 = datetime.datetime.now()\n",
    "       timestamp1 = timestamp1.strftime(\"%y%m%d\")+\"_\"+timestamp1.strftime(\"%H%M%S\")+\"_\"+timestamp1.strftime(\"%f\")\n",
    "       vram_history_file.write(str(title).ljust(40) + \";\"# + \"; timestamp, c, p;   \"\n",
    "                         + str(timestamp1).rjust(22) + \";\"\n",
    "                         + str(round(torch.cuda.memory_allocated(device=device) / 1024 / 1024, 2)).rjust(10) + \";\"\n",
    "                         + str(round(torch.cuda.max_memory_allocated(device=device) / 1024 / 1024, 2)).rjust(10) + \";\"\n",
    "                         )\n",
    "       torch.cuda.reset_peak_memory_stats()\n",
    "       timestamp1 = datetime.datetime.now()\n",
    "       timestamp1 = timestamp1.strftime(\"%y%m%d\")+\"_\"+timestamp1.strftime(\"%H%M%S\")\n",
    "       vram_history_file.write(str(timestamp1).rjust(22) + \"\\n\")\n",
    "else:\n",
    "    def log_VRAM(title):\n",
    "        pass\n",
    "\n",
    "print(\"variant: \", variant)\n",
    "print(\"logVRAM: \", args[\"logVRAM\"])\n",
    "print(\"calcForceCoefficients:\", calculate_force_coefficients)\n",
    "\n",
    "##################################################\n",
    "# PARAMETERS\n",
    "\n",
    "re = args[\"re\"]  # Reynoldszahl\n",
    "Ma = 0.05  # Machzahl\n",
    "if args[\"logVRAM\"]:\n",
    "    n_steps = 1  # only run 1 step, if logVRAM==True\n",
    "    print(\"logVRAM is True so run 1 step\")\n",
    "else:\n",
    "    n_steps = args[\"n_steps\"]  # Schrittzahl\n",
    "    print(\"logVRAM is True so choose n_steps\")\n",
    "setup_diameter = 1  # D_PU = char_length_pu -> this defines the PU-Reference\n",
    "flow_velocity = 1  # U_PU = char_velocity_pu -> this defines the PU-Reference velocity (u_max or u_mean of inflow)\n",
    "\n",
    "if re > 1000:\n",
    "    periodic_start = 0.4\n",
    "else:\n",
    "    periodic_start = 0.9  # relative starting point of peak_finding for Cd_mean Measurement to cut of any transients\n",
    "\n",
    "gridpoints_per_diameter = args[\"gpd\"]  # gp_per_D -> this defines the resolution ( D_LU = GPD+1)\n",
    "domain_height_in_D = args[\"dpy\"]  # D/Y  -> this defines the domain-size and total number of Lattice-Nodes\n",
    "if args[\"dpx\"] == 0:\n",
    "    domain_length_in_D = 2 * domain_height_in_D  # D/X = domain length in X- / flow-direction\n",
    "else:\n",
    "    domain_length_in_D = args[\"dpx\"]\n",
    "domain_width_in_D = args[\n",
    "    \"dpz\"]  # D/Z = DpZ = diameters per domain width in Z-direction -> domain size in periodic 3rd dimension\n",
    "if args[\"dpz\"] == 0:  # no z-deptth -> create pseudo 2D-domain with 3D stencil\n",
    "    domain_width_in_D = 1 / gridpoints_per_diameter\n",
    "\n",
    "# if DpY is even, resulting GPD can't be odd for symmetrical cylinder and channel\n",
    "# ...if DpY is even, GPD will be corrected to be even for symemtrical cylinder\n",
    "# ...use odd DpY to use odd GPD\n",
    "gpd_correction = False\n",
    "#if domain_height_in_D % 2 == 0 and gridpoints_per_diameter % 2 != 0:\n",
    "#    gpd_correction = True  # gpd_was_corrected-flag\n",
    "#    gpd_setup = gridpoints_per_diameter  # store old gpd for output\n",
    "#    gridpoints_per_diameter = int(gridpoints_per_diameter / 2) * 2  # make gpd even\n",
    "#    print(\"(!) domain_height_in_D (DpY) is even, gridpoints_per_diameter will be \" + str(\n",
    "#        gridpoints_per_diameter) + \". Use odd domain_height_in_D (DpY) to enable use of odd GPD!\")\n",
    "\n",
    "# OVERWRITE n_steps, if t_target is given\n",
    "T_target = 140\n",
    "if args[\"t_target\"] > 0:\n",
    "    print(\"t_target is >0\")\n",
    "    T_target = args[\"t_target\"]\n",
    "    print(\"t_target is\", T_target)\n",
    "    if args[\"logVRAM\"] == False:\n",
    "        n_steps = int(T_target * ((gridpoints_per_diameter) / setup_diameter) * (flow_velocity / (Ma * 1 / np.sqrt(3))))\n",
    "        print(\"n_steps is set to \", n_steps, \"because T_target was\", T_target)\n",
    "\n",
    "# SIMULATOR settings\n",
    "u_init = 0  # initial velocity field: # 0: uniform u=0, # 1: uniform u=1, # 2: parabolic, amplitude u_char_lu (similar to poiseuille-flow)\n",
    "perturb_init = True  # perturb initial symmetry by small sine-wave in initial velocity field -> triggers Karman-vortex street for Re > 46\n",
    "lateral_walls = args[\"lateral_walls\"]\n",
    "bc_type = args[\"bc_type\"]\n",
    "vtk_fps = 10  # FramesPerSecond (PU) for vtk-output\n",
    "cuda_device = args[\"device\"]\n",
    "nan_reporter = args[\"nan_reporter\"]\n",
    "\n",
    "gridpoints = gridpoints_per_diameter ** 3 * domain_length_in_D * domain_height_in_D * domain_width_in_D  # calc. total number of gridpoints\n",
    "\n",
    "##################################################\n",
    "# DATA OUTPUT SETTINGS (observables, stats and vtk)\n",
    "\n",
    "output_data = True  # output/log parameters, observables and vtk or vti (if output_vtk=True)\n",
    "if args[\"output_vtk\"]:\n",
    "    output_vtk = True  # is overwritten by output_data=False (see below)\n",
    "else:\n",
    "    output_vtk = False\n",
    "\n",
    "if output_data:  # only calculate u-profiles if data should be saved\n",
    "    calculate_velocity_profile = args[\"calcUProfiles\"]\n",
    "    if calculate_velocity_profile:  # only output u-profiles, if they are calculated\n",
    "        output_velocity_profile = args[\"outputUProfiles\"]\n",
    "    else:\n",
    "        output_velocity_profile = False\n",
    "else:\n",
    "    calculate_velocity_profile = False\n",
    "    output_velocity_profile = False\n",
    "\n",
    "# naming: specify name/number and parameters to put in directory- and datafile-names\n",
    "name = args[\"name\"]\n",
    "\n",
    "if output_data:  # toggle output of parameters, observables and vti/vtk files\n",
    "    timestamp = datetime.datetime.now()\n",
    "    timestamp = timestamp.strftime(\"%y%m%d\") + \"_\" + timestamp.strftime(\"%H%M%S\")\n",
    "\n",
    "    # specify output directory/path\n",
    "    output_path = \"/mnt/ScratchHDD1/Max_Scratch/lbm_simulations\"  # lokal HBRS\n",
    "    # output_path = \"/home/max/Documents/lbm_simulations\"  # lokal Bonn\n",
    "#    output_path = \"/home/mbille3s/02_lbm_simulations\"  # cluster HBRS\n",
    "    #scratch_dir = \"/scratch/mbille3s/21_LBM/01_data\"  # cluster HBRS for vti-output of big simulations\n",
    "    dir_name = \"/data_\" + str(timestamp) + \"_\" + name  # create directory name for all outputs to be saved in\n",
    "    os.makedirs(output_path + dir_name)\n",
    "\n",
    "    # specify input directory/path for rerefence data\n",
    "    diIlio_path = '/home/mbille/lettuce/myTest/DiIlio_Fig09_data/'  # likal HBRS\n",
    "    #diIlio_path = '/scratch/mbille3s/21_LBM/03_reference_data/DiIlio_2018/'  # cluster HBRS\n",
    "\n",
    "    if calculate_velocity_profile:\n",
    "        os.makedirs(output_path + dir_name + \"/AvgVelocity_Data\")\n",
    "\n",
    "    print(\"dir_name: \" + dir_name)\n",
    "    if output_vtk:\n",
    "        # vtk_path = output_path+dir_name+\"/vtk/out\"  # subdirectory for vtk/vti output\n",
    "        os.makedirs(scratch_dir + dir_name + \"/vtk/\")\n",
    "        vtk_path = scratch_dir + dir_name + \"/vtk/out\"\n",
    "        print(\"vtk_path: \" + vtk_path)\n",
    "else:  # \"no output\" suppresses the vtk output too\n",
    "    output_vtk = False\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "# lattice (parse stencil choice)\n",
    "if args[\"stencil\"] == \"D3Q27\":\n",
    "    stencil = lt.D3Q27\n",
    "    stencil_choice = \"D3Q27\"\n",
    "elif args[\"stencil\"] == \"D3Q19\":\n",
    "    stencil = lt.D3Q19\n",
    "    stencil_choice = \"D3Q19\"\n",
    "else:  # stencil == D3Q15\n",
    "    stencil = lt.D3Q15\n",
    "    stencil_choice = \"D3Q15\"\n",
    "\n",
    "# start log_VRAM-file:\n",
    "if args[\"logVRAM\"]:\n",
    "    vram_history_file = open(output_path+dir_name+\"/\"+timestamp + \"_VRAM_history.txt\", \"a\")\n",
    "    vram_history_file.write(\"DATA FOR: \" + str(timestamp) + \"_\" + name + \"_GPD\" + str(gridpoints_per_diameter) + \"_\" + str(domain_length_in_D) + \"x\" + str(domain_height_in_D) + \"x\" + str(domain_width_in_D) + \"_\" + str(stencil_choice) + \"\\n\\n\")\n",
    "    vram_history_file.write(\"title\".ljust(40) +\";\"+\"timestep_pre\".rjust(22)+\";\"+\"cVRAM [MB]\".rjust(10)+\";\"+\"pVRAM [MB]\".rjust(10)+\";\"+ \"timestep_post\".rjust(22) + \"\\n\")\n",
    "\n",
    "log_VRAM(\"START LOG_VRAM\")\n",
    "\n",
    "##################################################\n",
    "\n",
    "### MODIFIED CLASSES:\n",
    "\n",
    "\n",
    "## Lattice\n",
    "import warnings\n",
    "class Lattice:\n",
    "\n",
    "    def __init__(self, stencil, device, dtype=torch.float):\n",
    "        self.stencil = stencil\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.e = self.convert_to_tensor(stencil.e)\n",
    "        self.w = self.convert_to_tensor(stencil.w)\n",
    "        self.cs = self.convert_to_tensor(stencil.cs)\n",
    "        self.equilibrium = QuadraticEquilibrium(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Lattice (stencil {self.stencil.__name__}; device {self.device}; dtype {self.dtype})\"\n",
    "\n",
    "    @property\n",
    "    def D(self):\n",
    "        return self.stencil.e.shape[1]\n",
    "\n",
    "    @property\n",
    "    def Q(self):\n",
    "        return self.stencil.e.shape[0]\n",
    "\n",
    "    def convert_to_tensor(self, array):\n",
    "\n",
    "        def is_bool_array(it):\n",
    "            return (isinstance(it, torch.BoolTensor) or\n",
    "                    (isinstance(it, np.ndarray) and it.dtype in [bool, np.uint8]))\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            if is_bool_array(array):\n",
    "                return torch.tensor(array, device=self.device, dtype=torch.bool)\n",
    "            else:\n",
    "                return torch.tensor(array, device=self.device, dtype=self.dtype)\n",
    "\n",
    "    @classmethod\n",
    "    def convert_to_numpy(cls, tensor):\n",
    "        return tensor.detach().cpu().numpy()\n",
    "\n",
    "    def rho(self, f):\n",
    "        \"\"\"density\"\"\"\n",
    "        return torch.sum(f, dim=0)[None, ...]\n",
    "\n",
    "    def j(self, f):\n",
    "        \"\"\"momentum\"\"\"\n",
    "        return self.einsum(\"qd,q->d\", [self.e, f])\n",
    "\n",
    "    def u(self, f, rho=None, acceleration=None):\n",
    "        \"\"\"velocity; the `acceleration` is used to compute the correct velocity in the presence of a forcing scheme.\"\"\"\n",
    "        if rho is None:\n",
    "            rho = self.rho(f)\n",
    "        v = self.j(f) / rho\n",
    "        # apply correction due to forcing, which effectively averages the pre- and post-collision velocity\n",
    "        correction = 0.0\n",
    "        if acceleration is not None:\n",
    "            if len(acceleration.shape) == 1:\n",
    "                index = [Ellipsis] + [None]*self.D\n",
    "                acceleration = acceleration[index]\n",
    "            correction = acceleration / (2 * rho)\n",
    "        return v + correction\n",
    "\n",
    "    def incompressible_energy(self, f):\n",
    "        \"\"\"incompressible kinetic energy\"\"\"\n",
    "        return 0.5 * self.einsum(\"d,d->\", [self.u(f), self.u(f)])\n",
    "\n",
    "    def entropy(self, f):\n",
    "        \"\"\"entropy according to the H-theorem\"\"\"\n",
    "        f_log = -torch.log(self.einsum(\"q,q->q\", [f, 1 / self.w]))\n",
    "        return self.einsum(\"q,q->\", [f, f_log])\n",
    "\n",
    "    def pseudo_entropy_global(self, f):\n",
    "        \"\"\"pseudo_entropy derived by a Taylor expansion around the weights\"\"\"\n",
    "        f_w = self.einsum(\"q,q->q\", [f, 1 / self.w])\n",
    "        return self.rho(f) - self.einsum(\"q,q->\", [f, f_w])\n",
    "\n",
    "    def pseudo_entropy_local(self, f):\n",
    "        \"\"\"pseudo_entropy derived by a Taylor expansion around the local equilibrium\"\"\"\n",
    "        f_feq = f / self.equilibrium(self.rho(f), self.u(f))\n",
    "        return self.rho(f) - self.einsum(\"q,q->\", [f, f_feq])\n",
    "\n",
    "    def shear_tensor(self, f):\n",
    "        \"\"\"computes the shear tensor of a given f in the sense Pi_{\\alpha \\beta} = f_i * e_{i \\alpha} * e_{i \\beta}\"\"\"\n",
    "        shear = self.einsum(\"qa,qb->qab\", [self.e, self.e])\n",
    "        shear = self.einsum(\"q,qab->ab\", [f, shear])\n",
    "        return shear\n",
    "\n",
    "    def mv(self, m, v):\n",
    "        \"\"\"matrix-vector multiplication\"\"\"\n",
    "        return self.einsum(\"ij,j->i\", [m, v])\n",
    "\n",
    "    def einsum(self, equation, fields, **kwargs):\n",
    "        \"\"\"Einstein summation on local fields.\"\"\"\n",
    "        input, output = equation.split(\"->\")\n",
    "        inputs = input.split(\",\")\n",
    "        for i, inp in enumerate(inputs):\n",
    "            if len(inp) == len(fields[i].shape):\n",
    "                pass\n",
    "            elif len(inp) == len(fields[i].shape) - self.D:\n",
    "                inputs[i] += \"...\"\n",
    "                if not output.endswith(\"...\"):\n",
    "                    output += \"...\"\n",
    "            else:\n",
    "                raise LettuceException(\"Bad dimension.\")\n",
    "        equation = \",\".join(inputs) + \"->\" + output\n",
    "        return torch.einsum(equation, fields, **kwargs)\n",
    "\n",
    "## Equilibrium\n",
    "class Equilibrium:\n",
    "    pass\n",
    "\n",
    "\n",
    "class QuadraticEquilibrium(Equilibrium):\n",
    "    def __init__(self, lattice):\n",
    "        self.lattice = lattice\n",
    "\n",
    "    def __call__(self, rho, u, *args):\n",
    "        log_VRAM(\"EQ_call (start)\")\n",
    "        exu = torch.tensordot(self.lattice.e, u, dims=1)\n",
    "        uxu = self.lattice.einsum(\"d,d->\", [u, u])\n",
    "        feq = self.lattice.einsum(\n",
    "            \"q,q->q\",\n",
    "            [self.lattice.w,\n",
    "             rho * ((2 * exu - uxu) / (2 * self.lattice.cs ** 2) + 0.5 * (exu / (self.lattice.cs ** 2)) ** 2 + 1)]\n",
    "        )\n",
    "        log_VRAM(\"EQ_call (end)\")\n",
    "        return feq\n",
    "\n",
    "\n",
    "class QuadraticEquilibrium_LessMemory(QuadraticEquilibrium):\n",
    "    \"\"\"does the same as the normal equilibrium, how ever it uses somewhere around 20% less RAM,\n",
    "    but runs about 2% slower on GPU and 11% on CPU\n",
    "\n",
    "    Use this by setting\n",
    "    lattice.equilibrium = QuadraticEquilibrium_LessMemory(lattice)\n",
    "    before starting your simulation\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, rho, u, *args):\n",
    "        log_VRAM(\"EQ_LM_call (start, no end)\")\n",
    "        log_VRAM(\"EQ_LM_call (PLACEHOLDER)\")\n",
    "        return self.lattice.einsum(\n",
    "            \"q,q->q\",\n",
    "            [self.lattice.w,\n",
    "             rho * ((2 * torch.tensordot(self.lattice.e, u, dims=1) - self.lattice.einsum(\"d,d->\", [u, u]))\n",
    "                    / (2 * self.lattice.cs ** 2)\n",
    "                    + 0.5 * (torch.tensordot(self.lattice.e, u, dims=1) / (self.lattice.cs ** 2)) ** 2 + 1)]\n",
    "        )\n",
    "\n",
    "class BGKCollision:\n",
    "    def __init__(self, lattice, tau, force=None):\n",
    "        self.force = force\n",
    "        self.lattice = lattice\n",
    "        self.tau = tau\n",
    "\n",
    "    def __call__(self, f):\n",
    "        log_VRAM(\"BGK_call (start)\")\n",
    "        rho = self.lattice.rho(f)\n",
    "        u_eq = 0 if self.force is None else self.force.u_eq(f)\n",
    "        u = self.lattice.u(f, rho=rho) + u_eq\n",
    "        feq = self.lattice.equilibrium(rho, u)\n",
    "        Si = 0 if self.force is None else self.force.source_term(u)\n",
    "        log_VRAM(\"BGK_call (end, before 'return')\")\n",
    "        return f - 1.0 / self.tau * (f - feq) + Si\n",
    "\n",
    "class StandardStreaming:\n",
    "\n",
    "    def __init__(self, lattice):\n",
    "        self.lattice = lattice\n",
    "        self._no_stream_mask = None\n",
    "\n",
    "    @property\n",
    "    def no_stream_mask(self):\n",
    "        return self._no_stream_mask\n",
    "\n",
    "    @no_stream_mask.setter\n",
    "    def no_stream_mask(self, mask):\n",
    "        self._no_stream_mask = mask\n",
    "\n",
    "    def __call__(self, f):\n",
    "        log_VRAM(\"Streaming_call (start)\")\n",
    "        for i in range(1, self.lattice.Q):\n",
    "            if self.no_stream_mask is None:\n",
    "                f[i] = self._stream(f, i)\n",
    "            else:\n",
    "                new_fi = self._stream(f, i)\n",
    "                f[i] = torch.where(self.no_stream_mask[i], f[i], new_fi)\n",
    "        log_VRAM(\"Streaming_call (end)\")\n",
    "        return f\n",
    "\n",
    "    def _stream(self, f, i):\n",
    "        return torch.roll(f[i], shifts=tuple(self.lattice.stencil.e[i]), dims=tuple(np.arange(self.lattice.D)))\n",
    "\n",
    "###################################################\n",
    "\n",
    "### IBB1 and SIMULATION:\n",
    "\n",
    "if variant == \"ref\":\n",
    "    print(\"using IBB1 from ref\")\n",
    "    class InterpolatedBounceBackBoundary:\n",
    "\n",
    "        def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "            log_VRAM(\"IBB1_init (start)\")\n",
    "            t_init_start = time.time()\n",
    "            self.interpolation_order = interpolation_order\n",
    "            self.mask = mask  # location of solid-nodes\n",
    "            self.lattice = lattice\n",
    "            self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(\n",
    "                self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "            ### create f_mask, needed for force-calculation\n",
    "            # ...(marks all fs which point from fluid to solid (boundary) and considered for momentum exchange)\n",
    "            if self.lattice.D == 2:\n",
    "                nx, ny = mask.shape  # domain size in x and y\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny), dtype=bool)\n",
    "                # f_mask: [q, nx, ny], marks all fs which point from fluid to solid (boundary)\n",
    "                #            self.force = np.zeros((nx, ny, 2))  # force in x and y on all individual nodes\n",
    "                self.d = np.zeros_like(self.f_mask, dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b = np.where(mask)\n",
    "                # np.arrays: list of (a) x-coordinates and (b) y-coordinates in the boundary.mask\n",
    "                # ...to enable iteration over all boundary/wall/object-nodes\n",
    "                for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                    for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                        # check for boundary-nodes neighboring the domain-border.\n",
    "                        # ...they have to take the periodicity into account...\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                                # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                                # ...the direction pointing from the fluid neighbour to solid p is marked on the neighbour\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = 1\n",
    "                                # f_mask[q,x,y]\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                cx = self.lattice.stencil.e[self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                #print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p],i,d1,d2,px,py,cx,cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1,\"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],b[p],self.lattice.stencil.e[i, 0],self.lattice.stencil.e[i, 1])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "                nx, ny, nz = mask.shape\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny, nz), dtype=bool)\n",
    "                #            self.force = np.zeros((nx, ny, nz, 3))\n",
    "                self.d = np.zeros_like(self.f_mask, dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b, c = np.where(mask)\n",
    "                for p in range(0, len(a)):\n",
    "                    for i in range(0, self.lattice.Q):\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                            border[2] = -1\n",
    "                        elif c[p] == nz - 1 and self.lattice.e[i, 2] == 1:  # searching border on right\n",
    "                            border[2] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                            c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = 1\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                # Z-coodinate not needed for cylinder ! #pz = c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz  # fluid node z-coordinate\n",
    "\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                                # Z-coodinate not needed for cylinder ! #cz = self.lattice.stencil.e[\n",
    "                                #    self.lattice.stencil.opposite[i], 2]  # link-direction z to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                #print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1,\"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],b[p],c[p],self.lattice.stencil.e[i, 0],self.lattice.stencil.e[i, 1],self.lattice.stencil.e[i, 2])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            self.f_mask = self.lattice.convert_to_tensor(self.f_mask)\n",
    "            self.d = self.lattice.convert_to_tensor(self.d)\n",
    "            print(\"IBB initialization took \"+str(time.time()-t_init_start)+\"seconds\")\n",
    "\n",
    "            # count number of boundary nodes:\n",
    "            x,y,z = np.where(self.mask)\n",
    "            print(\"No. of Boundary-Nodes: \", x.shape[0], \" this is:\", x.shape[0]/self.mask.size, \"%\")\n",
    "\n",
    "            # count (total) number of nodes:\n",
    "            print(\"total No. of nodes: \", self.mask.size)\n",
    "\n",
    "            # count number of relevant boundary populations:\n",
    "            q,x,y,z = torch.where(self.f_mask)\n",
    "            print(\"No. of relevant populations: \", q.shape[0], \" this is:\", q.shape[0]/torch.numel(self.f_mask), \"%\")\n",
    "\n",
    "            # count (total) number of populations:\n",
    "            print(\"total No. of populations: \", torch.numel(self.f_mask))\n",
    "\n",
    "            log_VRAM(\"IBB1_init (end)\")\n",
    "\n",
    "        def __call__(self, f, f_collided):\n",
    "            log_VRAM(\"IBB1_call (start)\")\n",
    "            if self.interpolation_order == 2:\n",
    "                print(\"warning: not implemented\")\n",
    "            else:  #interpolation_order==1:\n",
    "                # f_tmp = f_collided[i,x_b]_interpolation before bounce\n",
    "                f_tmp = torch.where(self.d <= 0.5,  # if d<=1/2\n",
    "                                    2*self.d*f_collided+(1-2*self.d)*f,  # interpolate from second fluid node\n",
    "                                    (1/(2*self.d))*f_collided+(1-1/(2*self.d))*f_collided[self.lattice.stencil.opposite])  # else: interpolate from opposing populations on x_b\n",
    "                log_VRAM(\"IBB1_call (f_tmp created)\")\n",
    "                f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_tmp[self.lattice.stencil.opposite], f)\n",
    "                #HWBB: f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_collided[self.lattice.stencil.opposite], f)\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER lt)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER gt)\")\n",
    "            log_VRAM(\"IBB1_call (after_bounce)\")\n",
    "            self.calc_force_on_boundary(f, f_collided)\n",
    "            log_VRAM(\"IBB1_call (end, after calcForce, before 'return')\")\n",
    "            return f\n",
    "\n",
    "        def make_no_stream_mask(self, f_shape):\n",
    "            assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "            # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "            # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def make_no_collision_mask(self, f_shape):\n",
    "            # INFO: for the halfway bounce back boundary, a no_collision_mask ist not necessary, because the no_streaming_mask\n",
    "            # ...prevents interaction between nodes inside and outside of the boundary region.\n",
    "            # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "            # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "            # ...in the whole domain (including the boundary region)!\n",
    "            assert self.mask.shape == f_shape[1:]\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def calc_force_on_boundary(self, f_bounced, f_collided):\n",
    "            log_VRAM(\"IBB1_force (start)\")\n",
    "            tmp = torch.where(self.f_mask, f_collided + f_bounced[self.lattice.stencil.opposite], torch.zeros_like(f_bounced))  #RIGHT\n",
    "            log_VRAM(\"IBB1_force (tmp_created)\")\n",
    "            self.force_sum = torch.einsum('i..., id -> d', tmp, self.lattice.e)  # CALCULATE FORCE / v3.0 - M.Bille: dx_lu = dt_lu is allways 1 (!)\n",
    "            log_VRAM(\"IBB1_force (end)\")\n",
    "\n",
    "    class Simulation:\n",
    "\n",
    "        def __init__(self, flow, lattice, collision, streaming):\n",
    "            log_VRAM(\"SIM_init (start)\")\n",
    "            self.flow = flow\n",
    "            self.lattice = lattice\n",
    "            self.collision = collision\n",
    "            self.streaming = streaming\n",
    "            self.i = 0  # index of the current timestep\n",
    "\n",
    "            # M.Bille:\n",
    "            self.store_f_collided = False  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "            # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "            # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "            self.times = [[], [], [],\n",
    "                          []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "            self.time_avg = dict()\n",
    "\n",
    "            # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "            grid = flow.grid\n",
    "            p, u = flow.initial_solution(grid)\n",
    "            assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "                LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                                 f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(p.shape)}.\")\n",
    "            assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "                LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                                 f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(u.shape)}.\")\n",
    "\n",
    "            # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "            log_VRAM(\"SIM_init (flow.initial_solution)\")\n",
    "            u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "            rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "            log_VRAM(\"SIM_init (u,rho to tensor)\")\n",
    "            self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "            log_VRAM(\"SIM_init (f created)\")\n",
    "\n",
    "            # list of reporters\n",
    "            self.reporters = []\n",
    "\n",
    "            # Define masks, where collision or streaming are not applied\n",
    "            # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "            x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "            self.no_collision_mask = lattice.convert_to_tensor(\n",
    "                np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "            log_VRAM(\"SIM_init (no_collision_mask)\")\n",
    "            no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            log_VRAM(\"SIM_init (no_streaming_mask)\")\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "            # retrieve no-streaming and no-collision markings from all boundaries\n",
    "            self._boundaries = deepcopy(\n",
    "                self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "            log_VRAM(\"SIM_init (flow.boundaries)\")\n",
    "            for boundary in self._boundaries:\n",
    "                if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                    # get no-collision markings from boundaries\n",
    "                    self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "                if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                    # get no-streaming markings from boundaries\n",
    "                    no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "            if no_stream_mask.any():\n",
    "                # write no_streaming_mask to streaming-object\n",
    "                self.streaming.no_stream_mask = no_stream_mask\n",
    "            log_VRAM(\"SIM_init (NS_mask to streaming)\")\n",
    "\n",
    "            # define f_collided (post-collision, pre-streaming f), if HalfwayBounceBackBoundary is used\n",
    "            for boundary in self._boundaries:\n",
    "                if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary, InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided = True  # mark if a boundary is present which needs f_collided to be stored\n",
    "            if self.store_f_collided:\n",
    "                self.f_collided = deepcopy(self.f)\n",
    "            log_VRAM(\"SIM_init (PLACEHOLDER where f_mask)\")\n",
    "            log_VRAM(\"SIM_init (f_collided stored)\")\n",
    "\n",
    "        def step(self, num_steps):\n",
    "            \"\"\" Take num_steps stream-and-collision steps and return performance in MLUPS.\n",
    "            M.Bille: added force_calculation on object/boundaries\n",
    "            M.Bille: added halfway bounce back boundary\n",
    "            \"\"\"\n",
    "            start = timer()\n",
    "            log_VRAM(\"SIM_step (start)\")\n",
    "            if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "                # reporters are called before the first timestep\n",
    "                self._report()\n",
    "            for _ in range(num_steps):  # simulate num_step timesteps\n",
    "                time1 = timer()\n",
    "                ### COLLISION\n",
    "                # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "                # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "                log_VRAM(\"SIM_step (for loop)\")\n",
    "                self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "                log_VRAM(\"SIM_step (after collision)\")\n",
    "                if self.store_f_collided:\n",
    "                    self.f_collided = deepcopy(self.f)\n",
    "                log_VRAM(\"SIM_step (after deepcopy(f_collided))\")\n",
    "                log_VRAM(\"SIM_step (PLACEHOLDER f_collided.to_sparse())\")\n",
    "\n",
    "                time2 = timer()\n",
    "                ### STREAMING\n",
    "                self.f = self.streaming(self.f)\n",
    "                log_VRAM(\"SIM_step (after streaming)\")\n",
    "\n",
    "                time3 = timer()\n",
    "                ### BOUNDARY\n",
    "                # apply boundary conditions\n",
    "                for boundary in self._boundaries:\n",
    "                    if boundary is not None:\n",
    "                        if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                         InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f,\n",
    "                                              self.f_collided)  # HalfwayBounceBackBoundary needs post-collision_pre-streaming f on boundary nodes to perform reflection of populations within the same timestep\n",
    "                        else:\n",
    "                            self.f = boundary(self.f)  # all non-HalfwayBounceBackBoundary-BoundaryConditions\n",
    "                    log_VRAM(\"SIM_step (boundary loop...)\")\n",
    "\n",
    "                # count step\n",
    "                self.i += 1\n",
    "\n",
    "                time4 = timer()\n",
    "                # call reporters\n",
    "                self._report()\n",
    "                log_VRAM(\"SIM_step (after report)\")\n",
    "\n",
    "                time5 = timer()\n",
    "                self.times[0].append(time2 - time1)  # time to collide\n",
    "                self.times[1].append(time3 - time2)  # time to stream\n",
    "                self.times[2].append(time4 - time3)  # time to boundary\n",
    "                self.times[3].append(time5 - time4)  # time to report\n",
    "            end = timer()\n",
    "\n",
    "            # calculate individual runtimes (M.Bille)\n",
    "            if num_steps > 0:\n",
    "                self.time_avg = dict(time_collision=sum(self.times[0]) / len(self.times[0]),\n",
    "                                     time_streaming=sum(self.times[1]) / len(self.times[1]),\n",
    "                                     time_boundary=sum(self.times[2]) / len(self.times[2]),\n",
    "                                     time_reporter=sum(self.times[3]) / len(self.times[3]))\n",
    "            else:\n",
    "                self.time_avg = dict(time_collision=-1, time_streaming=-1, time_boundary=-1, time_reporter=-1)\n",
    "\n",
    "            # calculate runtime and performance in MLUPS\n",
    "            seconds = end - start\n",
    "            num_grid_points = self.lattice.rho(self.f).numel()\n",
    "            mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "            log_VRAM(\"SIM_step (end)\")\n",
    "            return mlups\n",
    "\n",
    "        def _report(self):\n",
    "            for reporter in self.reporters:\n",
    "                reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)\n",
    "\n",
    "elif variant == \"dv1\" or variant == \"d3\":\n",
    "    print(\"using IBB1 from dv1, d3\")\n",
    "    class InterpolatedBounceBackBoundary:\n",
    "\n",
    "        def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "            log_VRAM(\"IBB1_init (start)\")\n",
    "            t_init_start = time.time()\n",
    "            self.interpolation_order = interpolation_order\n",
    "            self.mask = mask  # location of solid-nodes\n",
    "            self.lattice = lattice\n",
    "            self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(\n",
    "                self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "            ### create f_mask, needed for force-calculation\n",
    "            # ...(marks all fs which point from fluid to solid (boundary) and considered for momentum exchange)\n",
    "            if self.lattice.D == 2:\n",
    "                nx, ny = mask.shape  # domain size in x and y\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny), dtype=bool)\n",
    "                # f_mask: [q, nx, ny], marks all fs which point from fluid to solid (boundary)\n",
    "                #            self.force = np.zeros((nx, ny, 2))  # force in x and y on all individual nodes\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b = np.where(mask)\n",
    "                # np.arrays: list of (a) x-coordinates and (b) y-coordinates in the boundary.mask\n",
    "                # ...to enable iteration over all boundary/wall/object-nodes\n",
    "                for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                    for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                        # check for boundary-nodes neighboring the domain-border.\n",
    "                        # ...they have to take the periodicity into account...\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                                # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                                # ...the direction pointing from the fluid neighbour to solid p is marked on the neighbour\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = 1\n",
    "                                # f_mask[q,x,y]\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p],i,d1,d2,px,py,cx,cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "                nx, ny, nz = mask.shape\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny, nz), dtype=bool)\n",
    "                #            self.force = np.zeros((nx, ny, nz, 3))\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b, c = np.where(mask)\n",
    "                for p in range(0, len(a)):\n",
    "                    for i in range(0, self.lattice.Q):\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                            border[2] = -1\n",
    "                        elif c[p] == nz - 1 and self.lattice.e[i, 2] == 1:  # searching border on right\n",
    "                            border[2] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                            c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = 1\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                # Z-coodinate not needed for cylinder ! #pz = c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz  # fluid node z-coordinate\n",
    "\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                                # Z-coodinate not needed for cylinder ! #cz = self.lattice.stencil.e[\n",
    "                                #    self.lattice.stencil.opposite[i], 2]  # link-direction z to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                          self.lattice.stencil.e[i, 2])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            self.f_mask = self.lattice.convert_to_tensor(self.f_mask)\n",
    "            self.d = self.lattice.convert_to_tensor(self.d).to_sparse()\n",
    "            print(\"IBB initialization took \" + str(time.time() - t_init_start) + \"seconds\")\n",
    "            log_VRAM(\"IBB1_init (end)\")\n",
    "\n",
    "        def __call__(self, f, f_collided):\n",
    "            log_VRAM(\"IBB1_call (start)\")\n",
    "            if self.interpolation_order == 2:\n",
    "                print(\"warning: not implemented\")\n",
    "            else:  # interpolation_order==1:\n",
    "                # f_tmp = f_collided[i,x_b]_interpolation before bounce\n",
    "                f_tmp = torch.where(self.d.to_dense() <= 0.5,  # if d<=1/2\n",
    "                                    2 * self.d.to_dense() * f_collided + (1 - 2 * self.d.to_dense()) * f,\n",
    "                                    # interpolate from second fluid node\n",
    "                                    (1 / (2 * self.d.to_dense())) * f_collided + (1 - 1 / (2 * self.d.to_dense())) *\n",
    "                                    f_collided[\n",
    "                                        self.lattice.stencil.opposite])  # else: interpolate from opposing populations on x_b\n",
    "                log_VRAM(\"IBB1_call (f_tmp created)\")\n",
    "\n",
    "                f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_tmp[self.lattice.stencil.opposite], f)\n",
    "                # HWBB: f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_collided[self.lattice.stencil.opposite], f)\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER lt)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER gt)\")\n",
    "            log_VRAM(\"IBB1_call (after_bounce)\")\n",
    "            self.calc_force_on_boundary(f, f_collided)\n",
    "            log_VRAM(\"IBB1_call (end, after calcForce, before 'return')\")\n",
    "            return f\n",
    "\n",
    "        def make_no_stream_mask(self, f_shape):\n",
    "            assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "            # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "            # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def make_no_collision_mask(self, f_shape):\n",
    "            # INFO: for the halfway bounce back boundary, a no_collision_mask ist not necessary, because the no_streaming_mask\n",
    "            # ...prevents interaction between nodes inside and outside of the boundary region.\n",
    "            # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "            # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "            # ...in the whole domain (including the boundary region)!\n",
    "            assert self.mask.shape == f_shape[1:]\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def calc_force_on_boundary(self, f_bounced, f_collided):\n",
    "            log_VRAM(\"IBB1_force (start)\")\n",
    "            tmp = torch.where(self.f_mask, f_collided + f_bounced[self.lattice.stencil.opposite], torch.zeros_like(f_bounced))  # RIGHT\n",
    "            log_VRAM(\"IBB1_force (tmp_created)\")\n",
    "            self.force_sum = torch.einsum('i..., id -> d', tmp, self.lattice.e)  # CALCULATE FORCE / v3.0 - M.Bille: dx_lu = dt_lu is allways 1 (!)\n",
    "            log_VRAM(\"IBB1_force (end)\")\n",
    "\n",
    "    class Simulation:\n",
    "\n",
    "        def __init__(self, flow, lattice, collision, streaming):\n",
    "            log_VRAM(\"SIM_init (start)\")\n",
    "            self.flow = flow\n",
    "            self.lattice = lattice\n",
    "            self.collision = collision\n",
    "            self.streaming = streaming\n",
    "            self.i = 0  # index of the current timestep\n",
    "\n",
    "            # M.Bille:\n",
    "            self.store_f_collided = False  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "            # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "            # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "            self.times = [[], [], [],\n",
    "                          []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "            self.time_avg = dict()\n",
    "\n",
    "            # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "            grid = flow.grid\n",
    "            p, u = flow.initial_solution(grid)\n",
    "            assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "                LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                                 f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(p.shape)}.\")\n",
    "            assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "                LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                                 f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(u.shape)}.\")\n",
    "\n",
    "            # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "            log_VRAM(\"SIM_init (flow.initial_solution)\")\n",
    "            u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "            rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "            log_VRAM(\"SIM_init (u,rho to tensor)\")\n",
    "            self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "            log_VRAM(\"SIM_init (f created)\")\n",
    "\n",
    "            # list of reporters\n",
    "            self.reporters = []\n",
    "\n",
    "            # Define masks, where collision or streaming are not applied\n",
    "            # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "            x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "            self.no_collision_mask = lattice.convert_to_tensor(\n",
    "                np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "            log_VRAM(\"SIM_init (no_collision_mask)\")\n",
    "            no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            log_VRAM(\"SIM_init (no_streaming_mask)\")\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "            # retrieve no-streaming and no-collision markings from all boundaries\n",
    "            self._boundaries = deepcopy(\n",
    "                self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "            log_VRAM(\"SIM_init (flow.boundaries)\")\n",
    "            for boundary in self._boundaries:\n",
    "                if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                    # get no-collision markings from boundaries\n",
    "                    self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "                if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                    # get no-streaming markings from boundaries\n",
    "                    no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "            if no_stream_mask.any():\n",
    "                # write no_streaming_mask to streaming-object\n",
    "                self.streaming.no_stream_mask = no_stream_mask\n",
    "            log_VRAM(\"SIM_init (NS_mask to streaming)\")\n",
    "\n",
    "            # define f_collided (post-collision, pre-streaming f), if HalfwayBounceBackBoundary is used\n",
    "            for boundary in self._boundaries:\n",
    "                if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                 InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided = True  # mark if a boundary is present which needs f_collided to be stored\n",
    "            if self.store_f_collided:\n",
    "                self.f_collided = deepcopy(self.f)\n",
    "                log_VRAM(\"SIM_init (PLACEHOLDER where f_mask)\")\n",
    "            log_VRAM(\"SIM_init (f_collided stored)\")\n",
    "\n",
    "        def step(self, num_steps):\n",
    "            start = timer()\n",
    "            log_VRAM(\"SIM_step (start)\")\n",
    "            if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "                # reporters are called before the first timestep\n",
    "                self._report()\n",
    "            for _ in range(num_steps):  # simulate num_step timesteps\n",
    "                time1 = timer()\n",
    "                ### COLLISION\n",
    "                # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "                # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "                log_VRAM(\"SIM_step (for loop)\")\n",
    "                self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "                log_VRAM(\"SIM_step (after collision)\")\n",
    "                if self.store_f_collided:\n",
    "                    self.f_collided = deepcopy(self.f)\n",
    "                log_VRAM(\"SIM_step (after deepcopy(f_collided))\")\n",
    "                log_VRAM(\"SIM_step (PLACEHOLDER f_collided.to_sparse())\")\n",
    "\n",
    "                time2 = timer()\n",
    "                ### STREAMING\n",
    "                self.f = self.streaming(self.f)\n",
    "                log_VRAM(\"SIM_step (after streaming)\")\n",
    "\n",
    "                time3 = timer()\n",
    "                ### BOUNDARY\n",
    "                # apply boundary conditions\n",
    "                for boundary in self._boundaries:\n",
    "                    if boundary is not None:\n",
    "                        if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                         InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f,\n",
    "                                              self.f_collided)  # HalfwayBounceBackBoundary needs post-collision_pre-streaming f on boundary nodes to perform reflection of populations within the same timestep\n",
    "                        else:\n",
    "                            self.f = boundary(self.f)  # all non-HalfwayBounceBackBoundary-BoundaryConditions\n",
    "                    log_VRAM(\"SIM_step (boundary loop...)\")\n",
    "\n",
    "                # count step\n",
    "                self.i += 1\n",
    "\n",
    "                time4 = timer()\n",
    "                # call reporters\n",
    "                self._report()\n",
    "                log_VRAM(\"SIM_step (after report)\")\n",
    "\n",
    "                time5 = timer()\n",
    "                self.times[0].append(time2 - time1)  # time to collide\n",
    "                self.times[1].append(time3 - time2)  # time to stream\n",
    "                self.times[2].append(time4 - time3)  # time to boundary\n",
    "                self.times[3].append(time5 - time4)  # time to report\n",
    "            end = timer()\n",
    "\n",
    "            # calculate individual runtimes (M.Bille)\n",
    "            if num_steps > 0:\n",
    "                self.time_avg = dict(time_collision=sum(self.times[0]) / len(self.times[0]),\n",
    "                                     time_streaming=sum(self.times[1]) / len(self.times[1]),\n",
    "                                     time_boundary=sum(self.times[2]) / len(self.times[2]),\n",
    "                                     time_reporter=sum(self.times[3]) / len(self.times[3]))\n",
    "            else:\n",
    "                self.time_avg = dict(time_collision=-1, time_streaming=-1, time_boundary=-1, time_reporter=-1)\n",
    "\n",
    "            # calculate runtime and performance in MLUPS\n",
    "            seconds = end - start\n",
    "            num_grid_points = self.lattice.rho(self.f).numel()\n",
    "            mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "            log_VRAM(\"SIM_step (end)\")\n",
    "            return mlups\n",
    "\n",
    "        def _report(self):\n",
    "            for reporter in self.reporters:\n",
    "                reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)\n",
    "\n",
    "elif variant == \"dv2\" or variant == \"d4\":\n",
    "    print(\"using IBB1 from dv2,d4\")\n",
    "    class InterpolatedBounceBackBoundary:\n",
    "\n",
    "        def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "            log_VRAM(\"IBB1_init (start)\")\n",
    "            t_init_start = time.time()\n",
    "            self.interpolation_order = interpolation_order\n",
    "            self.mask = mask  # location of solid-nodes\n",
    "            self.lattice = lattice\n",
    "            self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(\n",
    "                self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "            ### create f_mask, needed for force-calculation\n",
    "            # ...(marks all fs which point from fluid to solid (boundary) and considered for momentum exchange)\n",
    "            if self.lattice.D == 2:\n",
    "                nx, ny = mask.shape  # domain size in x and y\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny), dtype=bool)\n",
    "                # f_mask: [q, nx, ny], marks all fs which point from fluid to solid (boundary)\n",
    "                #            self.force = np.zeros((nx, ny, 2))  # force in x and y on all individual nodes\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b = np.where(mask)\n",
    "                # np.arrays: list of (a) x-coordinates and (b) y-coordinates in the boundary.mask\n",
    "                # ...to enable iteration over all boundary/wall/object-nodes\n",
    "                for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                    for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                        # check for boundary-nodes neighboring the domain-border.\n",
    "                        # ...they have to take the periodicity into account...\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                                # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                                # ...the direction pointing from the fluid neighbour to solid p is marked on the neighbour\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = 1\n",
    "                                # f_mask[q,x,y]\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p],i,d1,d2,px,py,cx,cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "                nx, ny, nz = mask.shape\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny, nz), dtype=bool)\n",
    "                #            self.force = np.zeros((nx, ny, nz, 3))\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b, c = np.where(mask)\n",
    "                for p in range(0, len(a)):\n",
    "                    for i in range(0, self.lattice.Q):\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                            border[2] = -1\n",
    "                        elif c[p] == nz - 1 and self.lattice.e[i, 2] == 1:  # searching border on right\n",
    "                            border[2] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                            c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = 1\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                # Z-coodinate not needed for cylinder ! #pz = c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz  # fluid node z-coordinate\n",
    "\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                                # Z-coodinate not needed for cylinder ! #cz = self.lattice.stencil.e[\n",
    "                                #    self.lattice.stencil.opposite[i], 2]  # link-direction z to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d1\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d2\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                          self.lattice.stencil.e[i, 2])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            self.f_mask = self.lattice.convert_to_tensor(self.f_mask)\n",
    "            self.d = self.lattice.convert_to_tensor(self.d).to_sparse()\n",
    "            print(\"IBB initialization took \" + str(time.time() - t_init_start) + \"seconds\")\n",
    "            log_VRAM(\"IBB1_init (end)\")\n",
    "\n",
    "        def __call__(self, f, f_collided):\n",
    "            log_VRAM(\"IBB1_call (start)\")\n",
    "            if self.interpolation_order == 2:\n",
    "                print(\"warning: not implemented\")\n",
    "            else:  # interpolation_order==1:\n",
    "                # f_tmp = f_collided[i,x_b]_interpolation before bounce\n",
    "                f_tmp = torch.where(self.d.to_dense() <= 0.5,  # if d<=1/2\n",
    "                                    2 * self.d.to_dense() * f_collided.to_dense() + (1 - 2 * self.d.to_dense()) * f,\n",
    "                                    # interpolate from second fluid node\n",
    "                                    (1 / (2 * self.d.to_dense())) * f_collided.to_dense() + (\n",
    "                                                1 - 1 / (2 * self.d.to_dense())) * f_collided.to_dense()[\n",
    "                                        self.lattice.stencil.opposite])  # else: interpolate from opposing populations on x_b\n",
    "                log_VRAM(\"IBB1_call (f_tmp created)\")\n",
    "\n",
    "                f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_tmp[self.lattice.stencil.opposite], f)\n",
    "                # HWBB: f = torch.where(self.f_mask[self.lattice.stencil.opposite], f_collided[self.lattice.stencil.opposite], f)\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER lt)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER lt)\")\n",
    "            log_VRAM(\"IBB1_call (after_bounce)\")\n",
    "            self.calc_force_on_boundary(f, f_collided)\n",
    "            log_VRAM(\"IBB1_call (end, after calcForce, before 'return')\")\n",
    "            return f\n",
    "\n",
    "        def make_no_stream_mask(self, f_shape):\n",
    "            assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "            # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "            # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def make_no_collision_mask(self, f_shape):\n",
    "            # INFO: for the halfway bounce back boundary, a no_collision_mask ist not necessary, because the no_streaming_mask\n",
    "            # ...prevents interaction between nodes inside and outside of the boundary region.\n",
    "            # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "            # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "            # ...in the whole domain (including the boundary region)!\n",
    "            assert self.mask.shape == f_shape[1:]\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def calc_force_on_boundary(self, f_bounced, f_collided):\n",
    "            log_VRAM(\"IBB1_force (start)\")\n",
    "            tmp = torch.where(self.f_mask, f_collided.to_dense() + f_bounced[self.lattice.stencil.opposite],\n",
    "                              torch.zeros_like(f_bounced))  # RIGHT\n",
    "            log_VRAM(\"IBB1_force (tmp_created)\")\n",
    "            self.force_sum = torch.einsum('i..., id -> d', tmp,\n",
    "                                          self.lattice.e)  # CALCULATE FORCE / v3.0 - M.Bille: dx_lu = dt_lu is allways 1 (!)\n",
    "            log_VRAM(\"IBB1_force (end)\")\n",
    "\n",
    "    class Simulation:\n",
    "\n",
    "        def __init__(self, flow, lattice, collision, streaming):\n",
    "            log_VRAM(\"SIM_init (start)\")\n",
    "            self.flow = flow\n",
    "            self.lattice = lattice\n",
    "            self.collision = collision\n",
    "            self.streaming = streaming\n",
    "            self.i = 0  # index of the current timestep\n",
    "\n",
    "            # M.Bille:\n",
    "            self.store_f_collided = False  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "            # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "            # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "            self.times = [[], [], [],\n",
    "                          []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "            self.time_avg = dict()\n",
    "\n",
    "            # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "            grid = flow.grid\n",
    "            p, u = flow.initial_solution(grid)\n",
    "            assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "                LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                                 f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(p.shape)}.\")\n",
    "            assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "                LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                                 f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(u.shape)}.\")\n",
    "\n",
    "            # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "            log_VRAM(\"SIM_init (flow.initial_solution)\")\n",
    "            u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "            rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "            log_VRAM(\"SIM_init (u,rho to tensor)\")\n",
    "            self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "            log_VRAM(\"SIM_init (f created)\")\n",
    "\n",
    "            # list of reporters\n",
    "            self.reporters = []\n",
    "\n",
    "            # Define masks, where collision or streaming are not applied\n",
    "            # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "            x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "            self.no_collision_mask = lattice.convert_to_tensor(\n",
    "                np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "            log_VRAM(\"SIM_init (no_collision_mask)\")\n",
    "            no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            log_VRAM(\"SIM_init (no_streaming_mask)\")\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "            # retrieve no-streaming and no-collision markings from all boundaries\n",
    "            self._boundaries = deepcopy(\n",
    "                self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "            log_VRAM(\"SIM_init (flow.boundaries)\")\n",
    "            for boundary in self._boundaries:\n",
    "                if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                    # get no-collision markings from boundaries\n",
    "                    self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "                if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                    # get no-streaming markings from boundaries\n",
    "                    no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "            if no_stream_mask.any():\n",
    "                # write no_streaming_mask to streaming-object\n",
    "                self.streaming.no_stream_mask = no_stream_mask\n",
    "            log_VRAM(\"SIM_init (NS_mask to streaming)\")\n",
    "\n",
    "            # define f_collided (post-collision, pre-streaming f), if HalfwayBounceBackBoundary is used\n",
    "            for boundary in self._boundaries:\n",
    "                if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                 InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided = True  # mark if a boundary is present which needs f_collided to be stored\n",
    "            if self.store_f_collided:\n",
    "                # self.f_collided = deepcopy(self.f)\n",
    "                fc_q, fc_x, fc_y, fc_z = torch.where(\n",
    "                    self._boundaries[-1].f_mask + self._boundaries[-1].f_mask[self.lattice.stencil.opposite])\n",
    "                self.fc_index = torch.stack((fc_q, fc_x, fc_y, fc_z))\n",
    "                log_VRAM(\"SIM_init (after fc_index)\")\n",
    "                self.f_collided = deepcopy(torch.sparse_coo_tensor(indices=self.fc_index,\n",
    "                                                                   values=self.f[self.fc_index[0], self.fc_index[1],\n",
    "                                                                                 self.fc_index[2], self.fc_index[3]],\n",
    "                                                                   size=self.f.size()))\n",
    "            log_VRAM(\"SIM_init (f_collided stored, sparse)\")\n",
    "\n",
    "        def step(self, num_steps):\n",
    "            start = timer()\n",
    "            log_VRAM(\"SIM_step (start)\")\n",
    "            if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "                # reporters are called before the first timestep\n",
    "                self._report()\n",
    "            for _ in range(num_steps):  # simulate num_step timesteps\n",
    "                time1 = timer()\n",
    "                ### COLLISION\n",
    "                # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "                # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "                log_VRAM(\"SIM_step (for loop)\")\n",
    "                self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "                log_VRAM(\"SIM_step (after collision)\")\n",
    "                if self.store_f_collided:\n",
    "                    self.f_collided = deepcopy(torch.sparse_coo_tensor(indices=self.fc_index,\n",
    "                                                                       values=self.f[self.fc_index[0], self.fc_index[1],\n",
    "                                                                                     self.fc_index[2], self.fc_index[\n",
    "                                                                                         3]],\n",
    "                                                                       size=self.f.size()))\n",
    "                    log_VRAM(\"SIM_step (after deepcopy(f_collided), sparse)\")\n",
    "                log_VRAM(\"SIM_step (PLACEHOLDER f_collided.to_sparse())\")\n",
    "\n",
    "                time2 = timer()\n",
    "                ### STREAMING\n",
    "                self.f = self.streaming(self.f)\n",
    "                log_VRAM(\"SIM_step (after streaming)\")\n",
    "\n",
    "                time3 = timer()\n",
    "                ### BOUNDARY\n",
    "                # apply boundary conditions\n",
    "                for boundary in self._boundaries:\n",
    "                    if boundary is not None:\n",
    "                        if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                         InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f,\n",
    "                                              self.f_collided)  # HalfwayBounceBackBoundary needs post-collision_pre-streaming f on boundary nodes to perform reflection of populations within the same timestep\n",
    "                        else:\n",
    "                            self.f = boundary(self.f)  # all non-HalfwayBounceBackBoundary-BoundaryConditions\n",
    "                    log_VRAM(\"SIM_step (boundary loop...)\")\n",
    "\n",
    "                # count step\n",
    "                self.i += 1\n",
    "\n",
    "                time4 = timer()\n",
    "                # call reporters\n",
    "                self._report()\n",
    "                log_VRAM(\"SIM_step (after report)\")\n",
    "\n",
    "                time5 = timer()\n",
    "                self.times[0].append(time2 - time1)  # time to collide\n",
    "                self.times[1].append(time3 - time2)  # time to stream\n",
    "                self.times[2].append(time4 - time3)  # time to boundary\n",
    "                self.times[3].append(time5 - time4)  # time to report\n",
    "            end = timer()\n",
    "\n",
    "            # calculate individual runtimes (M.Bille)\n",
    "            if num_steps > 0:\n",
    "                self.time_avg = dict(time_collision=sum(self.times[0]) / len(self.times[0]),\n",
    "                                     time_streaming=sum(self.times[1]) / len(self.times[1]),\n",
    "                                     time_boundary=sum(self.times[2]) / len(self.times[2]),\n",
    "                                     time_reporter=sum(self.times[3]) / len(self.times[3]))\n",
    "            else:\n",
    "                self.time_avg = dict(time_collision=-1, time_streaming=-1, time_boundary=-1, time_reporter=-1)\n",
    "\n",
    "            # calculate runtime and performance in MLUPS\n",
    "            seconds = end - start\n",
    "            num_grid_points = self.lattice.rho(self.f).numel()\n",
    "            mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "            log_VRAM(\"SIM_step (end)\")\n",
    "            return mlups\n",
    "\n",
    "        def _report(self):\n",
    "            for reporter in self.reporters:\n",
    "                reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)\n",
    "\n",
    "elif variant == \"h1\":\n",
    "    print(\"using IBB1 from h1\")\n",
    "    class InterpolatedBounceBackBoundary:\n",
    "\n",
    "        def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "            log_VRAM(\"IBB1_init (start)\")\n",
    "            t_init_start = time.time()\n",
    "            self.interpolation_order = interpolation_order\n",
    "            self.mask = mask  # location of solid-nodes\n",
    "            self.lattice = lattice\n",
    "            self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(\n",
    "                self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "            ### create f_mask, needed for force-calculation\n",
    "            # ...(marks all fs which point from fluid to solid (boundary) and considered for momentum exchange)\n",
    "\n",
    "            self.f_mask_sequential_gt = []\n",
    "            self.f_mask_sequential_lt = []\n",
    "            self.f_mask_sequential = []\n",
    "            self.d_sequential = []\n",
    "            self.d_sequential_lt = []  # implement for 2D\n",
    "            self.d_sequential_gt = []  # implement for 2D\n",
    "\n",
    "            if self.lattice.D == 2:\n",
    "                nx, ny = mask.shape  # domain size in x and y\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny), dtype=bool)\n",
    "                # f_mask: [q, nx, ny], marks all fs which point from fluid to solid (boundary)\n",
    "                #            self.force = np.zeros((nx, ny, 2))  # force in x and y on all individual nodes\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b = np.where(mask)\n",
    "                # np.arrays: list of (a) x-coordinates and (b) y-coordinates in the boundary.mask\n",
    "                # ...to enable iteration over all boundary/wall/object-nodes\n",
    "                for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                    for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                        # check for boundary-nodes neighboring the domain-border.\n",
    "                        # ...they have to take the periodicity into account...\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                                # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                                # ...the direction pointing from the fluid neighbour to solid p is marked on the neighbour\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = 1\n",
    "                                # f_mask[q,x,y]\n",
    "\n",
    "                                self.f_mask_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                                               a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                               b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny])\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p],i,d1,d2,px,py,cx,cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d1\n",
    "                                    self.d_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                                              a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                              b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny, d1])\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = d2\n",
    "                                    self.d_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                                              a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                              b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny, d2])\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "                nx, ny, nz = mask.shape\n",
    "                self.f_mask = np.zeros((self.lattice.Q, nx, ny, nz), dtype=bool)\n",
    "                #            self.force = np.zeros((nx, ny, nz, 3))\n",
    "                self.d = np.zeros_like(self.f_mask,\n",
    "                                       dtype=float)  # d: [q,x,y] store the link-length per boundary-cutting link\n",
    "                a, b, c = np.where(mask)\n",
    "                for p in range(0, len(a)):\n",
    "                    for i in range(0, self.lattice.Q):\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                            border[2] = -1\n",
    "                        elif c[p] == nz - 1 and self.lattice.e[i, 2] == 1:  # searching border on right\n",
    "                            border[2] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "                                self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                            c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = 1\n",
    "\n",
    "                                # self.f_mask_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                #                                a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                #                                b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                #                                c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz])\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                # Z-coodinate not needed for cylinder ! #pz = c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz  # fluid node z-coordinate\n",
    "\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                                # Z-coodinate not needed for cylinder ! #cz = self.lattice.stencil.e[\n",
    "                                #    self.lattice.stencil.opposite[i], 2]  # link-direction z to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d1\n",
    "                                    self.d_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                                              a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                              b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                              c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz, d1])\n",
    "                                    if d1 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d1)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d1)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    self.d[self.lattice.stencil.opposite[i],\n",
    "                                           a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                           b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                           c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = d2\n",
    "                                    self.d_sequential.append([self.lattice.stencil.opposite[i],\n",
    "                                                              a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                              b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                              c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz, d2])\n",
    "                                    if d2 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d2)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d2)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                else:\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                          self.lattice.stencil.e[i, 2])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            self.f_mask = self.lattice.convert_to_tensor(self.f_mask)\n",
    "\n",
    "            self.d_sequential = np.array(self.d_sequential)\n",
    "\n",
    "            self.f_mask_sequential_lt = torch.tensor(np.array(self.f_mask_sequential_lt), device=self.lattice.device,\n",
    "                                                     dtype=torch.int64)  # the index has to be integer\n",
    "            self.f_mask_sequential_gt = torch.tensor(np.array(self.f_mask_sequential_gt), device=self.lattice.device,\n",
    "                                                     dtype=torch.int64)  # the index has to be integer\n",
    "\n",
    "            self.d_sequential_lt = self.lattice.convert_to_tensor(np.array(self.d_sequential_lt))\n",
    "            self.d_sequential_gt = self.lattice.convert_to_tensor(np.array(self.d_sequential_gt))\n",
    "\n",
    "            self.opposite_tensor = torch.tensor(self.lattice.stencil.opposite, device=self.lattice.device,\n",
    "                                                dtype=torch.int64)\n",
    "\n",
    "            print(\"IBB initialization took \" + str(time.time() - t_init_start) + \"seconds\")\n",
    "            log_VRAM(\"IBB1_init (end)\")\n",
    "\n",
    "        def __call__(self, f, f_collided):\n",
    "            log_VRAM(\"IBB1_call (start)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER f_tmp)\")\n",
    "            # if d <= 0.5\n",
    "            f[self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "              self.f_mask_sequential_lt[:, 1],\n",
    "              self.f_mask_sequential_lt[:, 2],\n",
    "              self.f_mask_sequential_lt[:, 3]] = 2 * self.d_sequential_lt * f_collided.to_dense()[\n",
    "                self.f_mask_sequential_lt[:, 0],\n",
    "                self.f_mask_sequential_lt[:, 1],\n",
    "                self.f_mask_sequential_lt[:, 2],\n",
    "                self.f_mask_sequential_lt[:, 3]] \\\n",
    "                                                 + (1 - 2 * self.d_sequential_lt) * f[self.f_mask_sequential_lt[:, 0],\n",
    "                                                                                      self.f_mask_sequential_lt[:, 1],\n",
    "                                                                                      self.f_mask_sequential_lt[:, 2],\n",
    "                                                                                      self.f_mask_sequential_lt[:, 3]]\n",
    "            log_VRAM(\"IBB1_call (after_bounce_lt)\")\n",
    "            # if d > 0.5\n",
    "            f[self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "              self.f_mask_sequential_gt[:, 1],\n",
    "              self.f_mask_sequential_gt[:, 2],\n",
    "              self.f_mask_sequential_gt[:, 3]] = (1 / (2 * self.d_sequential_gt)) * f_collided.to_dense()[\n",
    "                self.f_mask_sequential_gt[:, 0],\n",
    "                self.f_mask_sequential_gt[:, 1],\n",
    "                self.f_mask_sequential_gt[:, 2],\n",
    "                self.f_mask_sequential_gt[:, 3]] \\\n",
    "                                                 + (1 - 1 / (2 * self.d_sequential_gt)) * f_collided.to_dense()[\n",
    "                                                     self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                                                     self.f_mask_sequential_gt[:, 1],\n",
    "                                                     self.f_mask_sequential_gt[:, 2],\n",
    "                                                     self.f_mask_sequential_gt[:, 3]]\n",
    "\n",
    "            log_VRAM(\"IBB1_call (after_bounce_gt)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER after_bounce)\")\n",
    "            self.calc_force_on_boundary(f, f_collided)\n",
    "            log_VRAM(\"IBB1_call (end, after calcForce, before 'return')\")\n",
    "            return f\n",
    "\n",
    "        def make_no_stream_mask(self, f_shape):\n",
    "            assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "            # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "            # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def make_no_collision_mask(self, f_shape):\n",
    "            # INFO: for the halfway bounce back boundary, a no_collision_mask ist not necessary, because the no_streaming_mask\n",
    "            # ...prevents interaction between nodes inside and outside of the boundary region.\n",
    "            # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "            # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "            # ...in the whole domain (including the boundary region)!\n",
    "            assert self.mask.shape == f_shape[1:]\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def calc_force_on_boundary(self, f_bounced, f_collided):\n",
    "            log_VRAM(\"IBB1_force (start)\")\n",
    "            log_VRAM(\"IBB1_force (PLACEHOLDER tmp)\")\n",
    "            ### force = e * (f_c + f_b[opp.])\n",
    "            self.force_sum = torch.einsum('i..., id -> d', f_collided.to_dense()[self.f_mask_sequential_lt[:, 0],\n",
    "                                                                                 self.f_mask_sequential_lt[:, 1],\n",
    "                                                                                 self.f_mask_sequential_lt[:, 2],\n",
    "                                                                                 self.f_mask_sequential_lt[:, 3]] \\\n",
    "                                          + f_bounced[self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "                                                      self.f_mask_sequential_lt[:, 1],\n",
    "                                                      self.f_mask_sequential_lt[:, 2],\n",
    "                                                      self.f_mask_sequential_lt[:, 3]],\n",
    "                                          self.lattice.e[self.f_mask_sequential_lt[:, 0]]) \\\n",
    "                             + torch.einsum('i..., id -> d', f_collided.to_dense()[self.f_mask_sequential_gt[:, 0],\n",
    "                                                                                   self.f_mask_sequential_gt[:, 1],\n",
    "                                                                                   self.f_mask_sequential_gt[:, 2],\n",
    "                                                                                   self.f_mask_sequential_gt[:, 3]] \\\n",
    "                                            + f_bounced[self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                                                        self.f_mask_sequential_gt[:, 1],\n",
    "                                                        self.f_mask_sequential_gt[:, 2],\n",
    "                                                        self.f_mask_sequential_gt[:, 3]],\n",
    "                                            self.lattice.e[self.f_mask_sequential_gt[:, 0]])\n",
    "            log_VRAM(\"IBB1_force (end)\")\n",
    "\n",
    "    class Simulation:\n",
    "\n",
    "        def __init__(self, flow, lattice, collision, streaming):\n",
    "            log_VRAM(\"SIM_init (start)\")\n",
    "            self.flow = flow\n",
    "            self.lattice = lattice\n",
    "            self.collision = collision\n",
    "            self.streaming = streaming\n",
    "            self.i = 0  # index of the current timestep\n",
    "\n",
    "            # M.Bille:\n",
    "            self.store_f_collided = False  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "            # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "            # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "            self.times = [[], [], [],\n",
    "                          []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "            self.time_avg = dict()\n",
    "\n",
    "            # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "            grid = flow.grid\n",
    "            p, u = flow.initial_solution(grid)\n",
    "            assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "                LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                                 f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(p.shape)}.\")\n",
    "            assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "                LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                                 f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(u.shape)}.\")\n",
    "\n",
    "            # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "            log_VRAM(\"SIM_init (flow.initial_solution)\")\n",
    "            u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "            rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "            log_VRAM(\"SIM_init (u,rho to tensor)\")\n",
    "            self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "            log_VRAM(\"SIM_init (f created)\")\n",
    "\n",
    "            # list of reporters\n",
    "            self.reporters = []\n",
    "\n",
    "            # Define masks, where collision or streaming are not applied\n",
    "            # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "            x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "            self.no_collision_mask = lattice.convert_to_tensor(\n",
    "                np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "            log_VRAM(\"SIM_init (no_collision_mask)\")\n",
    "            no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            log_VRAM(\"SIM_init (no_streaming_mask)\")\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "            # retrieve no-streaming and no-collision markings from all boundaries\n",
    "            self._boundaries = deepcopy(\n",
    "                self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "            log_VRAM(\"SIM_init (flow.boundaries)\")\n",
    "            for boundary in self._boundaries:\n",
    "                if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                    # get no-collision markings from boundaries\n",
    "                    self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "                if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                    # get no-streaming markings from boundaries\n",
    "                    no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "            if no_stream_mask.any():\n",
    "                # write no_streaming_mask to streaming-object\n",
    "                self.streaming.no_stream_mask = no_stream_mask\n",
    "            log_VRAM(\"SIM_init (NS_mask to streaming)\")\n",
    "\n",
    "            # define f_collided (post-collision, pre-streaming f), if HalfwayBounceBackBoundary is used\n",
    "            for boundary in self._boundaries:\n",
    "                if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                 InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided = True  # mark if a boundary is present which needs f_collided to be stored\n",
    "            if self.store_f_collided:\n",
    "                # self.f_collided = deepcopy(self.f)\n",
    "                fc_q, fc_x, fc_y, fc_z = torch.where(\n",
    "                    self._boundaries[-1].f_mask + self._boundaries[-1].f_mask[self.lattice.stencil.opposite])\n",
    "                self.fc_index = torch.stack((fc_q, fc_x, fc_y, fc_z))\n",
    "                # f_collided_tmp = torch.where(self._boundaries[-1].f_mask+self._boundaries[-1].f_mask[self.lattice.stencil.opposite], self.f, torch.zeros_like(self.f))\n",
    "                log_VRAM(\"SIM_init (after fc_index)\")\n",
    "                # self.f_collided = deepcopy(f_collided_tmp).to_sparse()  # hier könnte man das torch.where vielleicht auch als EINZEILER einfügen...\n",
    "                ## fc_values = self.f[self.fc_q, self.fc_x, self.fc_y, self.fc_z]\n",
    "                self.f_collided = deepcopy(torch.sparse_coo_tensor(indices=self.fc_index,\n",
    "                                                                   values=self.f[self.fc_index[0], self.fc_index[1],\n",
    "                                                                                 self.fc_index[2], self.fc_index[3]],\n",
    "                                                                   size=self.f.size()))\n",
    "            log_VRAM(\"SIM_init (f_collided stored, sparse)\")\n",
    "\n",
    "        def step(self, num_steps):\n",
    "            \"\"\" Take num_steps stream-and-collision steps and return performance in MLUPS.\n",
    "            M.Bille: added force_calculation on object/boundaries\n",
    "            M.Bille: added halfway bounce back boundary\n",
    "            \"\"\"\n",
    "            start = timer()\n",
    "            log_VRAM(\"SIM_step (start)\")\n",
    "            if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "                # reporters are called before the first timestep\n",
    "                self._report()\n",
    "            for _ in range(num_steps):  # simulate num_step timesteps\n",
    "                time1 = timer()\n",
    "                ### COLLISION\n",
    "                # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "                # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "                log_VRAM(\"SIM_step (for loop)\")\n",
    "                self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "                log_VRAM(\"SIM_step (after collision)\")\n",
    "                if self.store_f_collided:\n",
    "                    self.f_collided = deepcopy(torch.sparse_coo_tensor(indices=self.fc_index,\n",
    "                                                                       values=self.f[self.fc_index[0], self.fc_index[1],\n",
    "                                                                                     self.fc_index[2], self.fc_index[\n",
    "                                                                                         3]],\n",
    "                                                                       size=self.f.size()))\n",
    "                    log_VRAM(\"SIM_step (after deepcopy(f_collided), sparse)\")\n",
    "                log_VRAM(\"SIM_step (PLACEHOLDER f_collided.to_sparse())\")\n",
    "\n",
    "                time2 = timer()\n",
    "                ### STREAMING\n",
    "                self.f = self.streaming(self.f)\n",
    "                log_VRAM(\"SIM_step (after streaming)\")\n",
    "\n",
    "                time3 = timer()\n",
    "                ### BOUNDARY\n",
    "                # apply boundary conditions\n",
    "                for boundary in self._boundaries:\n",
    "                    if boundary is not None:\n",
    "                        if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                         InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f,\n",
    "                                              self.f_collided)  # HalfwayBounceBackBoundary needs post-collision_pre-streaming f on boundary nodes to perform reflection of populations within the same timestep\n",
    "                        else:\n",
    "                            self.f = boundary(self.f)  # all non-HalfwayBounceBackBoundary-BoundaryConditions\n",
    "                    log_VRAM(\"SIM_step (boundary loop...)\")\n",
    "\n",
    "                # count step\n",
    "                self.i += 1\n",
    "\n",
    "                time4 = timer()\n",
    "                # call reporters\n",
    "                self._report()\n",
    "                log_VRAM(\"SIM_step (after report)\")\n",
    "\n",
    "                time5 = timer()\n",
    "                self.times[0].append(time2 - time1)  # time to collide\n",
    "                self.times[1].append(time3 - time2)  # time to stream\n",
    "                self.times[2].append(time4 - time3)  # time to boundary\n",
    "                self.times[3].append(time5 - time4)  # time to report\n",
    "            end = timer()\n",
    "\n",
    "            # calculate individual runtimes (M.Bille)\n",
    "            if num_steps > 0:\n",
    "                self.time_avg = dict(time_collision=sum(self.times[0]) / len(self.times[0]),\n",
    "                                     time_streaming=sum(self.times[1]) / len(self.times[1]),\n",
    "                                     time_boundary=sum(self.times[2]) / len(self.times[2]),\n",
    "                                     time_reporter=sum(self.times[3]) / len(self.times[3]))\n",
    "            else:\n",
    "                self.time_avg = dict(time_collision=-1, time_streaming=-1, time_boundary=-1, time_reporter=-1)\n",
    "\n",
    "            # calculate runtime and performance in MLUPS\n",
    "            seconds = end - start\n",
    "            num_grid_points = self.lattice.rho(self.f).numel()\n",
    "            mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "            log_VRAM(\"SIM_step (end)\")\n",
    "            return mlups\n",
    "\n",
    "        def _report(self):\n",
    "            for reporter in self.reporters:\n",
    "                reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)\n",
    "\n",
    "elif variant == \"h2\":\n",
    "    print(\"using IBB1 from h2\")\n",
    "    class InterpolatedBounceBackBoundary:\n",
    "\n",
    "        def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "            log_VRAM(\"IBB1_init (start)\")\n",
    "            t_init_start = time.time()\n",
    "            self.interpolation_order = interpolation_order\n",
    "            self.mask = mask  # location of solid-nodes\n",
    "            self.lattice = lattice\n",
    "            self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(\n",
    "                self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "            ### create f_mask, needed for force-calculation\n",
    "            # ...(marks all fs which point from fluid to solid (boundary) and considered for momentum exchange)\n",
    "\n",
    "            self.f_mask_sequential_gt = []  # coordinates (q,x,y,[z]) for all force- and bounce-relevant populations with d<=0.5\n",
    "            self.f_mask_sequential_lt = []  # coordinates (q,x,y,[z]) for all force- and bounce-relevant populations with d>0.5\n",
    "            self.d_sequential_lt = []  # relative \"d\"istance between the solid node and the ideal boundary location for d<=0.5\n",
    "            self.d_sequential_gt = []  # relative \"d\"istance between the solid node and the ideal boundary location for d>0.5\n",
    "\n",
    "            if self.lattice.D == 2:\n",
    "                nx, ny = mask.shape  # domain size in x and y\n",
    "                a, b = np.where(mask)\n",
    "                # np.arrays: list of (a) x-coordinates and (b) y-coordinates in the boundary.mask\n",
    "                # ...to enable iteration over all boundary/wall/object-nodes\n",
    "                for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                    for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                        # check for boundary-nodes neighboring the domain-border.\n",
    "                        # ...they have to take the periodicity into account...\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                                # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                                # ...the direction pointing from the fluid neighbour to solid p is marked on the (fluid) neighbour,\n",
    "                                # ...(needed for bounce-back (hwbb and ibb1) and force-calculation)\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p],i,d1,d2,px,py,cx,cy)\n",
    "\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    if d1 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d1)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d1)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny])\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    if d2 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d2)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d2)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny])\n",
    "                                else:  # if both distances d1, d2 are not between 0 and 1\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "            if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "                nx, ny, nz = mask.shape\n",
    "                a, b, c = np.where(mask)\n",
    "                for p in range(0, len(a)):\n",
    "                    for i in range(0, self.lattice.Q):\n",
    "                        border = np.zeros(self.lattice.D, dtype=int)\n",
    "                        if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                            border[0] = -1\n",
    "                        elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right\n",
    "                            border[0] = 1\n",
    "                        if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                            border[1] = -1\n",
    "                        elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right\n",
    "                            border[1] = 1\n",
    "                        if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                            border[2] = -1\n",
    "                        elif c[p] == nz - 1 and self.lattice.e[i, 2] == 1:  # searching border on right\n",
    "                            border[2] = 1\n",
    "                        try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                            if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "\n",
    "                                # calculate intersection point of boundary surface and link ->\n",
    "                                # ...calculate distance between fluid node and boundary surface on the link\n",
    "                                px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                                py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                                # Z-coodinate not needed for cylinder ! #pz = c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz  # fluid node z-coordinate\n",
    "\n",
    "                                cx = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                                cy = self.lattice.stencil.e[\n",
    "                                    self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                                # Z-coodinate not needed for cylinder ! #cz = self.lattice.stencil.e[\n",
    "                                #    self.lattice.stencil.opposite[i], 2]  # link-direction z to solid node\n",
    "\n",
    "                                # pq-formula\n",
    "                                h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                                h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                      - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                                 cx * cx + cy * cy)  # q\n",
    "\n",
    "                                d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                                d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                                # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "                                # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                                if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "                                    if d1 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d1)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d1)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                elif d2 <= 1 and np.isreal(d2):\n",
    "                                    if d2 <= 0.5:\n",
    "                                        self.d_sequential_lt.append(d2)\n",
    "                                        self.f_mask_sequential_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                    else:\n",
    "                                        self.d_sequential_gt.append(d2)\n",
    "                                        self.f_mask_sequential_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                          a[p] + self.lattice.stencil.e[i, 0] - border[\n",
    "                                                                              0] * nx,\n",
    "                                                                          b[p] + self.lattice.stencil.e[i, 1] - border[\n",
    "                                                                              1] * ny,\n",
    "                                                                          c[p] + self.lattice.stencil.e[i, 2] - border[\n",
    "                                                                              2] * nz])\n",
    "                                else:  # if both distances d1, d2 are not between 0 and 1\n",
    "                                    print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                          b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                          self.lattice.stencil.e[i, 2])\n",
    "                        except IndexError:\n",
    "                            pass  # just ignore this iteration since there is no neighbor there\n",
    "\n",
    "            self.f_mask_sequential_lt = torch.tensor(np.array(self.f_mask_sequential_lt), device=self.lattice.device,\n",
    "                                                     dtype=torch.int64)  # the index has has to be integer\n",
    "            self.f_mask_sequential_gt = torch.tensor(np.array(self.f_mask_sequential_gt), device=self.lattice.device,\n",
    "                                                     dtype=torch.int64)  # the index has has to be integer\n",
    "\n",
    "            self.d_sequential_lt = self.lattice.convert_to_tensor(np.array(self.d_sequential_lt))\n",
    "            self.d_sequential_gt = self.lattice.convert_to_tensor(np.array(self.d_sequential_gt))\n",
    "\n",
    "            self.opposite_tensor = torch.tensor(self.lattice.stencil.opposite, device=self.lattice.device,\n",
    "                                                dtype=torch.int64)\n",
    "\n",
    "            print(\"IBB initialization took \" + str(time.time() - t_init_start) + \"seconds\")\n",
    "            log_VRAM(\"IBB1_init (end)\")\n",
    "\n",
    "        def __call__(self, f, f_collided_lt, f_collided_gt):\n",
    "            log_VRAM(\"IBB1_call (start)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER f_tmp)\")\n",
    "            ## f_collided_lt = [f_collided_lt, f_collided_lt.opposite] (!) in compact storage-layout\n",
    "\n",
    "            if self.lattice.D == 2:\n",
    "                # BOUNCE\n",
    "                # if d <= 0.5\n",
    "                f[self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "                  self.f_mask_sequential_lt[:, 1],\n",
    "                  self.f_mask_sequential_lt[:, 2]] = 2 * self.d_sequential_lt * f_collided_lt[:, 0] \\\n",
    "                                                     + (1 - 2 * self.d_sequential_lt) * f[\n",
    "                                                         self.f_mask_sequential_lt[:, 0],\n",
    "                                                         self.f_mask_sequential_lt[:, 1],\n",
    "                                                         self.f_mask_sequential_lt[:, 2]]\n",
    "                log_VRAM(\"IBB1_call (after_bounce_lt)\")\n",
    "                # if d > 0.5\n",
    "                f[self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                  self.f_mask_sequential_gt[:, 1],\n",
    "                  self.f_mask_sequential_gt[:, 2]] = (1 / (2 * self.d_sequential_gt)) * f_collided_gt[:, 0] \\\n",
    "                                                     + (1 - 1 / (2 * self.d_sequential_gt)) * f_collided_gt[:, 1]\n",
    "\n",
    "                log_VRAM(\"IBB1_call (after_bounce_gt)\")\n",
    "            if self.lattice.D == 3:\n",
    "                # BOUNCE\n",
    "                # if d <= 0.5\n",
    "                f[self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "                  self.f_mask_sequential_lt[:, 1],\n",
    "                  self.f_mask_sequential_lt[:, 2],\n",
    "                  self.f_mask_sequential_lt[:, 3]] = 2 * self.d_sequential_lt * f_collided_lt[:, 0] \\\n",
    "                                                     + (1 - 2 * self.d_sequential_lt) * f[\n",
    "                                                         self.f_mask_sequential_lt[:, 0],\n",
    "                                                         self.f_mask_sequential_lt[:, 1],\n",
    "                                                         self.f_mask_sequential_lt[:, 2],\n",
    "                                                         self.f_mask_sequential_lt[:, 3]]\n",
    "                log_VRAM(\"IBB1_call (after_bounce_lt)\")\n",
    "                # if d > 0.5\n",
    "                f[self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                  self.f_mask_sequential_gt[:, 1],\n",
    "                  self.f_mask_sequential_gt[:, 2],\n",
    "                  self.f_mask_sequential_gt[:, 3]] = (1 / (2 * self.d_sequential_gt)) * f_collided_gt[:, 0] \\\n",
    "                                                     + (1 - 1 / (2 * self.d_sequential_gt)) * f_collided_gt[:, 1]\n",
    "\n",
    "                log_VRAM(\"IBB1_call (after_bounce_gt)\")\n",
    "            log_VRAM(\"IBB1_call (PLACEHOLDER after_bounce)\")\n",
    "            # CALC. FORCE on boundary (MEM, MEA)\n",
    "            self.calc_force_on_boundary(f, f_collided_lt, f_collided_gt)\n",
    "\n",
    "            log_VRAM(\"IBB1_call (end, after calcForce, before 'return')\")\n",
    "            return f\n",
    "\n",
    "        def make_no_stream_mask(self, f_shape):\n",
    "            assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "            # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "            # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def make_no_collision_mask(self, f_shape):\n",
    "            # INFO: for the halfway bounce back boundary, a no_collision_mask ist not necessary, because the no_streaming_mask\n",
    "            # ...prevents interaction between nodes inside and outside of the boundary region.\n",
    "            # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "            # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "            # ...in the whole domain (including the boundary region)!\n",
    "            assert self.mask.shape == f_shape[1:]\n",
    "            return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "        def calc_force_on_boundary(self, f_bounced, f_collided_lt, f_collided_gt):\n",
    "            log_VRAM(\"IBB1_force (start)\")\n",
    "            log_VRAM(\"IBB1_force (PLACEHOLDER tmp)\")\n",
    "            ### force = e * (f_c + f_b[opp.])\n",
    "            if self.lattice.D == 2:\n",
    "                self.force_sum = torch.einsum('i..., id -> d',\n",
    "                                              f_collided_lt[:, 0] + f_bounced[\n",
    "                                                  self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "                                                  self.f_mask_sequential_lt[:, 1],\n",
    "                                                  self.f_mask_sequential_lt[:, 2]],\n",
    "                                              self.lattice.e[self.f_mask_sequential_lt[:, 0]]) \\\n",
    "                                 + torch.einsum('i..., id -> d',\n",
    "                                                f_collided_gt[:, 0] + f_bounced[\n",
    "                                                    self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                                                    self.f_mask_sequential_gt[:, 1],\n",
    "                                                    self.f_mask_sequential_gt[:, 2]],\n",
    "                                                self.lattice.e[self.f_mask_sequential_gt[:, 0]])\n",
    "            if self.lattice.D == 3:\n",
    "                self.force_sum = torch.einsum('i..., id -> d',\n",
    "                                              f_collided_lt[:, 0] + f_bounced[\n",
    "                                                  self.opposite_tensor[self.f_mask_sequential_lt[:, 0]],\n",
    "                                                  self.f_mask_sequential_lt[:, 1],\n",
    "                                                  self.f_mask_sequential_lt[:, 2],\n",
    "                                                  self.f_mask_sequential_lt[:, 3]],\n",
    "                                              self.lattice.e[self.f_mask_sequential_lt[:, 0]]) \\\n",
    "                                 + torch.einsum('i..., id -> d',\n",
    "                                                f_collided_gt[:, 0] + f_bounced[\n",
    "                                                    self.opposite_tensor[self.f_mask_sequential_gt[:, 0]],\n",
    "                                                    self.f_mask_sequential_gt[:, 1],\n",
    "                                                    self.f_mask_sequential_gt[:, 2],\n",
    "                                                    self.f_mask_sequential_gt[:, 3]],\n",
    "                                                self.lattice.e[self.f_mask_sequential_gt[:, 0]])\n",
    "\n",
    "            log_VRAM(\"IBB1_force (end)\")\n",
    "\n",
    "    class Simulation:\n",
    "\n",
    "        def __init__(self, flow, lattice, collision, streaming):\n",
    "            log_VRAM(\"SIM_init (start)\")\n",
    "            self.flow = flow\n",
    "            self.lattice = lattice\n",
    "            self.collision = collision\n",
    "            self.streaming = streaming\n",
    "            self.i = 0  # index of the current timestep\n",
    "\n",
    "            # M.Bille:\n",
    "            self.store_f_collided = False  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "            # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "            # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "            self.store_f_collided_compact = False  # toggle compact storage of f_collided for interpolated_bounce_back boundary\n",
    "            self.times = [[], [], [],\n",
    "                          []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "            self.time_avg = dict()\n",
    "\n",
    "            # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "            grid = flow.grid\n",
    "            p, u = flow.initial_solution(grid)\n",
    "            assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "                LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                                 f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(p.shape)}.\")\n",
    "            assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "                LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                                 f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                                 f\"but got {list(u.shape)}.\")\n",
    "\n",
    "            # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "            log_VRAM(\"SIM_init (flow.initial_solution)\")\n",
    "            u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "            rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "            log_VRAM(\"SIM_init (u,rho to tensor)\")\n",
    "            self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "            log_VRAM(\"SIM_init (f created)\")\n",
    "\n",
    "            # list of reporters\n",
    "            self.reporters = []\n",
    "\n",
    "            # Define masks, where collision or streaming are not applied\n",
    "            # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "            x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "            self.no_collision_mask = lattice.convert_to_tensor(\n",
    "                np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "            log_VRAM(\"SIM_init (no_collision_mask)\")\n",
    "            no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            log_VRAM(\"SIM_init (no_streaming_mask)\")\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "            # retrieve no-streaming and no-collision markings from all boundaries\n",
    "            self._boundaries = deepcopy(\n",
    "                self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "            log_VRAM(\"SIM_init (flow.boundaries)\")\n",
    "            for boundary in self._boundaries:\n",
    "                if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                    # get no-collision markings from boundaries\n",
    "                    self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "                if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                    # get no-streaming markings from boundaries\n",
    "                    no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "            if no_stream_mask.any():\n",
    "                # write no_streaming_mask to streaming-object\n",
    "                self.streaming.no_stream_mask = no_stream_mask\n",
    "            log_VRAM(\"SIM_init (NS_mask to streaming)\")\n",
    "\n",
    "            # define f_collided (post-collision, pre-streaming f), if HalfwayBounceBackBoundary is used\n",
    "            for boundary in self._boundaries:\n",
    "                if isinstance(boundary, HalfwayBounceBackBoundary) or isinstance(boundary,\n",
    "                                                                                 InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided = True  # mark if a boundary is present which needs f_collided to be stored\n",
    "                    # self.f_collided = deepcopy(self.f)\n",
    "                if isinstance(boundary, InterpolatedBounceBackBoundary):\n",
    "                    self.store_f_collided_compact = True\n",
    "            if self.store_f_collided:\n",
    "                if self.store_f_collided_compact:\n",
    "                    f_collided_lt = torch.zeros_like(self._boundaries[\n",
    "                                                         -1].d_sequential_lt)  # float-tensor with number of (x_b nodes with d<=0.5) values\n",
    "                    f_collided_gt = torch.zeros_like(self._boundaries[\n",
    "                                                         -1].d_sequential_gt)  # float-tensor with number of (x_b nodes with d>0.5) values\n",
    "                    f_collided_lt_opposite = torch.zeros_like(self._boundaries[-1].d_sequential_lt)\n",
    "                    f_collided_gt_opposite = torch.zeros_like(self._boundaries[-1].d_sequential_gt)\n",
    "                    log_VRAM(\"SIM_init (f_collided subtensors created)\")\n",
    "\n",
    "                    if self.lattice.D == 2:\n",
    "                        f_collided_lt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_lt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 2]])  # y\n",
    "                        f_collided_lt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_lt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 2]])  # y\n",
    "\n",
    "                        f_collided_gt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_gt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 2]])  # y\n",
    "                        f_collided_gt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_gt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 2]])  # y\n",
    "                    if self.lattice.D == 3:\n",
    "                        f_collided_lt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_lt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 2],  # y\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 3]])  # z\n",
    "                        f_collided_lt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_lt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 2],  # y\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 3]])  # z\n",
    "\n",
    "                        f_collided_gt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_gt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 2],  # y\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 3]])  # z\n",
    "                        f_collided_gt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_gt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 2],  # y\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 3]])  # z\n",
    "\n",
    "                    # f_collided in compact storage-format (because torch.to_sparse() doesn't allow value-assignment and/or batch-indexing)\n",
    "                    self.f_collided_lt = torch.stack((f_collided_lt, f_collided_lt_opposite), dim=1)\n",
    "                    self.f_collided_gt = torch.stack((f_collided_gt, f_collided_gt_opposite), dim=1)\n",
    "                    # print(\"f_collided_lt.shape:\", self.f_collided_lt.shape)\n",
    "                    # print(\"f_mask_sequential_lt.shape\", self._boundaries[-1].f_mask_sequential_lt.shape)\n",
    "            log_VRAM(\"SIM_init (f_collided subtensors assigned/stacked)\")\n",
    "\n",
    "        def step(self, num_steps):\n",
    "            \"\"\" Take num_steps stream-and-collision steps and return performance in MLUPS.\n",
    "            M.Bille: added force_calculation on object/boundaries\n",
    "            M.Bille: added halfway bounce back boundary\n",
    "            \"\"\"\n",
    "            start = timer()\n",
    "            log_VRAM(\"SIM_step (start)\")\n",
    "            if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "                # reporters are called before the first timestep\n",
    "                self._report()\n",
    "            for _ in range(num_steps):  # simulate num_step timesteps\n",
    "                time1 = timer()\n",
    "                ### COLLISION\n",
    "                # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "                # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "                log_VRAM(\"SIM_step (for loop)\")\n",
    "                self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "                log_VRAM(\"SIM_step (after collision)\")\n",
    "                if self.store_f_collided:\n",
    "                    if self.lattice.D == 2:\n",
    "                        f_collided_lt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_lt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 2]])  # y\n",
    "                        f_collided_lt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_lt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 2]])  # y\n",
    "\n",
    "                        f_collided_gt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_gt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 2]])  # y\n",
    "                        f_collided_gt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_gt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 2]])  # y\n",
    "                    if self.lattice.D == 3:\n",
    "                        f_collided_lt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_lt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 2],  # y\n",
    "                                                        self._boundaries[-1].f_mask_sequential_lt[:, 3]])  # z\n",
    "                        f_collided_lt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_lt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 2],  # y\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_lt[:, 3]])  # z\n",
    "\n",
    "                        f_collided_gt = deepcopy(self.f[self._boundaries[-1].f_mask_sequential_gt[:, 0],  # q\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 2],  # y\n",
    "                                                        self._boundaries[-1].f_mask_sequential_gt[:, 3]])  # z\n",
    "                        f_collided_gt_opposite = deepcopy(self.f[self._boundaries[-1].opposite_tensor[\n",
    "                                                                     self._boundaries[-1].f_mask_sequential_gt[:,\n",
    "                                                                     0]],  # q\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 1],  # x\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 2],  # y\n",
    "                                                                 self._boundaries[-1].f_mask_sequential_gt[:, 3]])  # z\n",
    "\n",
    "                    #log_VRAM(\"SIM_step (f_collided subtensors assigned)\")\n",
    "                    # f_collided in compact storage-format (because torch.to_sparse() doesn't allow value-assignment and/or batch-indexing)\n",
    "                    self.f_collided_lt = torch.stack((f_collided_lt, f_collided_lt_opposite), dim=1)\n",
    "                    self.f_collided_gt = torch.stack((f_collided_gt, f_collided_gt_opposite), dim=1)\n",
    "\n",
    "                log_VRAM(\"SIM_step (f_collided subtensors assigned/stacked)\")\n",
    "\n",
    "                time2 = timer()\n",
    "                ### STREAMING\n",
    "                self.f = self.streaming(self.f)\n",
    "                log_VRAM(\"SIM_step (after streaming)\")\n",
    "\n",
    "                time3 = timer()\n",
    "                ### BOUNDARY\n",
    "                # apply boundary conditions\n",
    "                for boundary in self._boundaries:\n",
    "                    if boundary is not None:\n",
    "                        if isinstance(boundary,\n",
    "                                      HalfwayBounceBackBoundary):  # or isinstance(boundary, InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f,\n",
    "                                              self.f_collided)  # HalfwayBounceBackBoundary needs post-collision_pre-streaming f on boundary nodes to perform reflection of populations within the same timestep\n",
    "                        elif isinstance(boundary, InterpolatedBounceBackBoundary):\n",
    "                            self.f = boundary(self.f, self.f_collided_lt, self.f_collided_gt)\n",
    "                        else:\n",
    "                            self.f = boundary(self.f)  # all non-HalfwayBounceBackBoundary-BoundaryConditions\n",
    "                    log_VRAM(\"SIM_step (boundary loop...)\")\n",
    "\n",
    "                # count step\n",
    "                self.i += 1\n",
    "\n",
    "                time4 = timer()\n",
    "                # call reporters\n",
    "                self._report()\n",
    "                log_VRAM(\"SIM_step (after report)\")\n",
    "\n",
    "                time5 = timer()\n",
    "                self.times[0].append(time2 - time1)  # time to collide\n",
    "                self.times[1].append(time3 - time2)  # time to stream\n",
    "                self.times[2].append(time4 - time3)  # time to boundary\n",
    "                self.times[3].append(time5 - time4)  # time to report\n",
    "            end = timer()\n",
    "\n",
    "            # calculate individual runtimes (M.Bille)\n",
    "            if num_steps > 0:\n",
    "                self.time_avg = dict(time_collision=sum(self.times[0]) / len(self.times[0]),\n",
    "                                     time_streaming=sum(self.times[1]) / len(self.times[1]),\n",
    "                                     time_boundary=sum(self.times[2]) / len(self.times[2]),\n",
    "                                     time_reporter=sum(self.times[3]) / len(self.times[3]))\n",
    "            else:\n",
    "                self.time_avg = dict(time_collision=-1, time_streaming=-1, time_boundary=-1, time_reporter=-1)\n",
    "\n",
    "            # calculate runtime and performance in MLUPS\n",
    "            seconds = end - start\n",
    "            num_grid_points = self.lattice.rho(self.f).numel()\n",
    "            mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "            log_VRAM(\"SIM_step (end)\")\n",
    "            return mlups\n",
    "\n",
    "        def _report(self):\n",
    "            for reporter in self.reporters:\n",
    "                reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)\n",
    "\n",
    "else:\n",
    "    print(\"variant not reccognized! Got: '\" + str(variant) + \"', expected 'ref, d1, d2, h1, h2\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# OBSTACLE CLASS\n",
    "class ObstacleCylinder:\n",
    "\n",
    "    def __init__(self, shape, reynolds_number, mach_number, lattice, char_length_pu, char_length_lu, char_velocity_pu=1,\n",
    "                 lateral_walls='periodic', bc_type='fwbb', perturb_init=True, u_init=0,\n",
    "                 x_offset=0, y_offset=0):\n",
    "        # shape of the domain (2D or 3D):\n",
    "        if len(shape) != lattice.D:\n",
    "            raise ValueError(f\"{lattice.D}-dimensional lattice requires {lattice.D}-dimensional `shape`\")\n",
    "        if len(shape) == 2:\n",
    "            self.shape = (int(shape[0]), int(shape[1]))\n",
    "        elif len(shape) == 3:\n",
    "            self.shape = (int(shape[0]), int(shape[1]), int(shape[2]))\n",
    "        else:\n",
    "            print(\"WARNING: shape is not 2- or 3-dimensional...(!)\")\n",
    "        #self.shape = shape\n",
    "\n",
    "        self.char_length_pu = char_length_pu  # characteristic length\n",
    "\n",
    "        self.units = UnitConversion(\n",
    "            lattice,\n",
    "            reynolds_number=reynolds_number,\n",
    "            mach_number=mach_number,\n",
    "            characteristic_length_lu=char_length_lu,\n",
    "            characteristic_length_pu=char_length_pu,\n",
    "            characteristic_velocity_pu=char_velocity_pu  # reminder: u_char_lu = Ma * cs_lu = Ma * 1/sqrt(3)\n",
    "        )\n",
    "\n",
    "        # flow and boundary settings\n",
    "        self.perturb_init = perturb_init  # toggle: introduce asymmetry in initial solution to trigger v'Karman Vortex Street\n",
    "        self.u_init = u_init  # toggle: initial solution velocity profile type\n",
    "        self.lateral_walls = lateral_walls  # toggle: lateral walls to be bounce back (bounceback), slip wall (slip) or periodic (periodic)\n",
    "        self.bc_type = bc_type  # toggle: bounce back algorithm: halfway (hwbb) or fullway (fwbb)\n",
    "\n",
    "        # initialize masks (init with zeros)\n",
    "        self.solid_mask = np.zeros(shape=self.shape, dtype=bool)  # marks all solid nodes (obstacle, walls, ...)\n",
    "        self.in_mask = np.zeros(self.grid[0].shape, dtype=bool)  # marks all inlet nodes\n",
    "        self.wall_mask = np.zeros_like(self.solid_mask)  # marks lateral (top+bottom) walls\n",
    "        self._obstacle_mask = np.zeros_like(self.solid_mask)  # marks all obstacle nodes (for fluid-solid-force_calc.)\n",
    "\n",
    "        # cylinder geometry in LU (1-based indexing!)\n",
    "        self.x_offset = x_offset\n",
    "        self.y_offset = y_offset\n",
    "        self.radius = char_length_lu / 2\n",
    "        self.y_pos = self.shape[1] / 2 + 0.5 + self.y_offset  # y_position of cylinder-center in 1-based indexing\n",
    "        self.x_pos = self.y_pos + self.x_offset  # keep symmetry of cylinder in x and y direction\n",
    "\n",
    "        xyz = tuple(np.linspace(1, n, n) for n in self.shape)  # Tupel of index-lists (1-n (one-based!))\n",
    "        if self.units.lattice.D == 2:\n",
    "            x_lu, y_lu = np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y-index\n",
    "        elif self.units.lattice.D == 3:\n",
    "            x_lu, y_lu, z_lu = np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y- and z-index\n",
    "        else:\n",
    "            print(\"WARNING: something went wrong in LU-gird-index generation, lattice.D must be 2 or 3!\")\n",
    "\n",
    "        condition = np.sqrt((x_lu - self.x_pos) ** 2 + (y_lu - self.y_pos) ** 2) < self.radius\n",
    "        self.obstacle_mask[np.where(condition)] = 1\n",
    "        self.solid_mask[np.where(condition)] = 1\n",
    "\n",
    "        # indexing doesn't need z-Index for 3D, everything is broadcasted along z!\n",
    "        if self.lateral_walls == 'bounceback' or self.lateral_walls == 'slip':  # if top and bottom are link-based BC\n",
    "            self.wall_mask[:, [0, -1]] = True  # don't mark wall nodes as inlet\n",
    "            self.solid_mask[np.where(self.wall_mask)] = 1  # mark solid walls\n",
    "            self.in_mask[0, 1:-1] = True  # inlet on the left, except for top and bottom wall (y=0, y=y_max)\n",
    "        else:  # if lateral_wals == 'periodic', no walls\n",
    "            self.in_mask[0, :] = True  # inlet on the left (x=0)\n",
    "\n",
    "        # generate parabolic velocity profile for inlet BC if lateral_walls (top and bottom) are bounce back walls (== channel-flow)\n",
    "        self.u_inlet = self.units.characteristic_velocity_pu * self._unit_vector()  # u = [ux,uy,uz] = [1,0,0] in PU // uniform cahracteristic velocity in x-direction\n",
    "        if self.lateral_walls == 'bounceback':\n",
    "            ## parabolic velocity profile, zeroing on the edges\n",
    "            ## How to parabola:\n",
    "            ## 1.parabola in factoriezed form (GER: \"Nullstellenform\"): y = (x-x1)*(x-x2)\n",
    "            ## 2.parabola with a maximum and zero at x1=0 und x2=x0: y=-x*(x-x0)\n",
    "            ## 3.scale parabola, to make y_s(x_s)=1 the maximum: y=-x*(x-x0)*(1/(x0/2)²)\n",
    "            ## (4. optional) scale amplitude with 1.5 to have a mean velocity of 1, also making the integral of a homogeneous velocity profile with u=1 and the parabolic profile being equal\n",
    "            (nx, ny, nz) = self.shape  # number of gridpoints in y direction\n",
    "            parabola_y = np.zeros((1, ny))\n",
    "            y_coordinates = np.linspace(0, ny,\n",
    "                                        ny)  # linspace() creates n points between 0 and ny, including 0 and ny:\n",
    "            # top and bottom velocity values will be zero to agree with wall-boundary-condition\n",
    "            parabola_y[:, 1:-1] = - 1.5 * np.array(self.u_inlet).max() * y_coordinates[1:-1] * (\n",
    "                        y_coordinates[1:-1] - ny) * 1 / (ny / 2) ** 2  # parabolic velocity profile\n",
    "            # scale with 1.5 to achieve a mean velocity of u_char! -> DIFFERENT FROM cylinder2D and cylinder3D (!)\n",
    "            if self.units.lattice.D == 2:\n",
    "                # in 2D u1 needs Dimension 1 x ny (!)\n",
    "                velocity_y = np.zeros_like(parabola_y)  # y-velocities = 0\n",
    "                self.u_inlet = np.stack([parabola_y, velocity_y], axis=0)  # stack/pack u-field\n",
    "            elif self.units.lattice.D == 3:\n",
    "                ones_z = np.ones(nz)\n",
    "                parabola_yz = parabola_y[:, :, np.newaxis] * ones_z\n",
    "                parabola_yz_zeros = np.zeros_like(parabola_yz)\n",
    "                # create u_xyz inlet yz-plane:\n",
    "                self.u_inlet = np.stack([parabola_yz, parabola_yz_zeros, parabola_yz_zeros], axis=0)  # stack/pack u-field\n",
    "\n",
    "    @property\n",
    "    def obstacle_mask(self):\n",
    "        return self._obstacle_mask\n",
    "\n",
    "    @obstacle_mask.setter\n",
    "    def obstacle_mask(self, m):\n",
    "        assert isinstance(m, np.ndarray) and m.shape == self.shape\n",
    "        self._obstacle_mask = m.astype(bool)\n",
    "        # self.solid_mask[np.where(self._obstacle_mask)] = 1  # (!) this line is not doing what it should! solid_mask is now defined in the initial solution (see below)!\n",
    "\n",
    "    def initial_solution(self, x):\n",
    "        p = np.zeros_like(x[0], dtype=float)[None, ...]\n",
    "        u_max_pu = self.units.characteristic_velocity_pu * self._unit_vector()\n",
    "        u_max_pu = append_axes(u_max_pu, self.units.lattice.D)\n",
    "        self.solid_mask[np.where(self.obstacle_mask)] = 1  # This line is needed, because the obstacle_mask.setter does not define the solid_mask properly (see above) #OLD\n",
    "        ### initial velocity field: \"u_init\"-parameter\n",
    "        # 0: uniform u=0\n",
    "        # 1: uniform u=1 or parabolic (depends on lateral_walls -> bounceback => parabolic; slip, periodic => uniform)\n",
    "        u = (1 - self.solid_mask) * u_max_pu\n",
    "        if self.u_init == 0:\n",
    "            u = u * 0  # uniform u=0\n",
    "        else:\n",
    "            if self.lateral_walls == 'bounceback':  # parabolic along y, uniform along x and z (similar to poiseuille-flow)\n",
    "                ny = self.shape[1]  # number of gridpoints in y direction\n",
    "                ux_factor = np.zeros(ny)  # vector for one column (u(x=0))\n",
    "                # multiply parabolic profile with every column of the velocity field:\n",
    "                y_coordinates = np.linspace(0, ny, ny)\n",
    "                ux_factor[1:-1] = - y_coordinates[1:-1] * (y_coordinates[1:-1] - ny) * 1 / (ny / 2) ** 2\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u = np.einsum('k,ijk->ijk', ux_factor, u)\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    u = np.einsum('k,ijkl->ijkl', ux_factor, u)\n",
    "            else:  # lateral_walls == periodic or slip\n",
    "                # initiale velocity u_PU=1 on every fluid node\n",
    "                u = (1 - self.solid_mask) * u_max_pu\n",
    "\n",
    "        ### perturb initial velocity field-symmetry (in y and z) to trigger 'von Karman' vortex street\n",
    "        if self.perturb_init:  # perturb initial solution in y\n",
    "            # overlays a sine-wave on the second column of nodes x_lu=1 (index 1)\n",
    "            ny = x[1].shape[1]\n",
    "            if u.max() < 0.5 * self.units.characteristic_velocity_pu:\n",
    "                # add perturbation for small velocities\n",
    "                #OLD 2D: u[0][1] += np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * self.units.characteristic_velocity_pu * 1.0\n",
    "                amplitude_y = np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * self.units.characteristic_velocity_pu * 0.1\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u[0][1] += amplitude_y\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    nz = x[2].shape[2]\n",
    "                    plane_yz = np.ones_like(u[0, 1])  # plane of ones\n",
    "                    u[0][1] = np.einsum('y,yz->yz', amplitude_y, plane_yz)  # plane of amplitude in y\n",
    "                    amplitude_z = np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * self.units.characteristic_velocity_pu * 0.1  # amplitude in z\n",
    "                   # print(\"amplitude y:\", amplitude_y.shape)\n",
    "                   # print(\"u[0][1]:\", u[0][1].shape)\n",
    "                   # print(\"amplitude z:\", amplitude_z.shape)\n",
    "                    # factor = 1 + np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * 0.3  # pertubation in z-direction\n",
    "                    u[0][1] += np.einsum('z,yz->yz', amplitude_z, plane_yz)\n",
    "            else:\n",
    "                # multiply scaled down perturbation if velocity field is already near u_char\n",
    "                #OLD 2D: u[0][1] *= 1 + np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * 0.3\n",
    "                factor = 1 + np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * 0.1\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u[0][1] *= factor\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    nz = x[2].shape[1]\n",
    "                    plane_yz = np.ones_like(u[0, 1, :, :])\n",
    "                    u[0][1] = np.einsum('y,yz->yz', factor, u[0][1])\n",
    "                    factor = 1 + np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * 0.1  # pertubation in z-direction\n",
    "                    u[0][1] = np.einsum('z,yz->yz', factor, u[0][1])\n",
    "        return p, u\n",
    "\n",
    "    @property\n",
    "    def grid(self):\n",
    "        # THIS IS NOT USED AT THE MOMENT. QUESTION: SHOULD THIS BE ONE- OR ZERO-BASED? Indexing or \"node-number\"?\n",
    "        xyz = tuple(self.units.convert_length_to_pu(np.linspace(0, n, n)) for n in self.shape)  # tuple of lists of x,y,(z)-values/indices\n",
    "        return np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y- (und z-)values/indices\n",
    "\n",
    "    @property\n",
    "    def boundaries(self):\n",
    "        # inlet (\"left side\", x[0],y[1:-1], z[:])\n",
    "        inlet_boundary = EquilibriumBoundaryPU(\n",
    "            self.in_mask,\n",
    "            self.units.lattice, self.units,\n",
    "            # self.units.characteristic_velocity_pu * self._unit_vector())\n",
    "            self.u_inlet)  # works with a 1 x D vector or an ny x D vector thanks to einsum-magic in EquilibriumBoundaryPU\n",
    "\n",
    "        # lateral walls (\"top and bottom walls\", x[:], y[0,-1], z[:])\n",
    "        lateral_boundary = None  # stays None if lateral_walls == 'periodic'\n",
    "        if self.lateral_walls == 'bounceback':\n",
    "            if self.bc_type == 'hwbb' or self.bc_type == 'HWBB':  # use halfway bounce back\n",
    "                lateral_boundary = HalfwayBounceBackBoundary(self.wall_mask, self.units.lattice)\n",
    "            else:  # else use fullway bounce back\n",
    "                lateral_boundary = FullwayBounceBackBoundary(self.wall_mask, self.units.lattice)\n",
    "        elif self.lateral_walls == 'slip' or self.bc_type == 'SLIP':  # use slip-walöl (symmetry boundary)\n",
    "            lateral_boundary = SlipBoundary(self.wall_mask, self.units.lattice, 1)  # slip on x(z)-plane\n",
    "\n",
    "        # outlet (\"right side\", x[-1],y[:], (z[:]))\n",
    "        if self.units.lattice.D == 2:\n",
    "            outlet_boundary = EquilibriumOutletP(self.units.lattice, [1, 0])  # outlet in positive x-direction\n",
    "        else: # self.units.lattice.D == 3:\n",
    "            outlet_boundary = EquilibriumOutletP(self.units.lattice, [1, 0, 0])  # outlet in positive x-direction\n",
    "\n",
    "        # obstacle (for example: obstacle \"cylinder\" with radius centered at position x_pos, y_pos) -> to be set via obstacle_mask.setter\n",
    "        obstacle_boundary = None\n",
    "        # (!) the obstacle_boundary should alway be the last boundary in the list of boundaries to correctly calculate forces on the obstacle\n",
    "        if self.bc_type == 'hwbb' or self.bc_type == 'HWBB':\n",
    "            obstacle_boundary = HalfwayBounceBackBoundary(self.obstacle_mask, self.units.lattice)\n",
    "        elif self.bc_type == 'ibb1' or self.bc_type == 'IBB1':\n",
    "            obstacle_boundary = InterpolatedBounceBackBoundary(self.obstacle_mask, self.units.lattice,\n",
    "                                                               x_center=(self.shape[1] / 2 - 0.5),\n",
    "                                                               y_center=(self.shape[1] / 2 - 0.5), radius=self.radius)\n",
    "        else:  # use Fullway Bounce Back\n",
    "            obstacle_boundary = FullwayBounceBackBoundary(self.obstacle_mask, self.units.lattice)\n",
    "\n",
    "        if lateral_boundary is None:  # if lateral boundary is periodic...don't return a boundary-object\n",
    "            return [\n",
    "                inlet_boundary,\n",
    "                outlet_boundary,\n",
    "                obstacle_boundary\n",
    "            ]\n",
    "        else:\n",
    "            return [\n",
    "                inlet_boundary,\n",
    "                outlet_boundary,\n",
    "                lateral_boundary,\n",
    "                obstacle_boundary\n",
    "            ]\n",
    "\n",
    "    def _unit_vector(self, i=0):\n",
    "        return np.eye(self.units.lattice.D)[i]\n",
    "\n",
    "##########################################################\n",
    "# SIM SETUP (instatiate objects, calculate&place obstacle, append reporters)\n",
    "\n",
    "lattice = Lattice(stencil, cuda_device, dtype=torch.float64)\n",
    "\n",
    "# flow\n",
    "flow = ObstacleCylinder(shape=(domain_length_in_D * gridpoints_per_diameter,\n",
    "                               domain_height_in_D * gridpoints_per_diameter,\n",
    "                               domain_width_in_D * gridpoints_per_diameter),\n",
    "                        reynolds_number=re, mach_number=Ma,\n",
    "                        lattice=lattice,\n",
    "                        char_length_pu=setup_diameter,\n",
    "                        char_length_lu=gridpoints_per_diameter,\n",
    "                        char_velocity_pu=flow_velocity,\n",
    "                        lateral_walls=args[\"lateral_walls\"],\n",
    "                        bc_type=args[\"bc_type\"],\n",
    "                        perturb_init=perturb_init,\n",
    "                        u_init=u_init\n",
    "                        )\n",
    "\n",
    "### Simulation-Object (Simulator/solver) and additional settings (tau, collision operator)\n",
    "tau = flow.units.relaxation_parameter_lu\n",
    "re_g = flow.units.characteristic_velocity_lu / (\n",
    "            lattice.stencil.cs ** 2 * (tau - 0.5))  # grid reynolds number (should be O(10))\n",
    "print(\"Re_g = \", re_g)\n",
    "\n",
    "# collision operator\n",
    "if args[\"collision\"] == \"kbc\":\n",
    "    collision = lt.KBCCollision3D(lattice, tau)\n",
    "    collision_choice = \"kbc\"\n",
    "elif args[\"collision\"] == \"reg\":\n",
    "    collision = lt.RegularizedCollision(lattice, tau)\n",
    "    collision_choice = \"reg\"\n",
    "else:\n",
    "    collision = BGKCollision(lattice, tau)\n",
    "    collision_choice = \"bgk\"\n",
    "\n",
    "# solver\n",
    "sim = Simulation(flow, lattice,\n",
    "                    collision,\n",
    "                    # lt.BGKCollision(lattice, tau),\n",
    "                    # lt.RegularizedCollision(lattice, tau),\n",
    "                    # lt.KBCCollision2D(lattice,tau),\n",
    "                    StandardStreaming(lattice)\n",
    "                    )\n",
    "### Reporter\n",
    "\n",
    "# VTK Reporter -> visualization\n",
    "if output_vtk == True:\n",
    "    VTKreport = lt.VTKReporter(lattice, flow, interval=int(flow.units.convert_time_to_lu(1 / vtk_fps)),\n",
    "                               filename_base=vtk_path)\n",
    "    sim.reporters.append(VTKreport)\n",
    "    # export obstacle\n",
    "    mask_dict = dict()\n",
    "    mask_dict[\"mask\"] = flow.obstacle_mask.astype(int)\n",
    "    imageToVTK(\n",
    "        path=scratch_dir + dir_name + \"/vtk/obstacle_point\",\n",
    "        pointData=mask_dict\n",
    "    )\n",
    "    imageToVTK(\n",
    "        path=scratch_dir + dir_name + \"/vtk/obstacle_cell\",\n",
    "        cellData=mask_dict\n",
    "    )\n",
    "\n",
    "class ObservableReporter:\n",
    "\n",
    "    def __init__(self, observable, interval=1, out=sys.stdout):\n",
    "        self.observable = observable\n",
    "        self.interval = interval\n",
    "        self.out = [] if out is None else out\n",
    "        self._parameter_name = observable.__class__.__name__\n",
    "        if out is not None:\n",
    "            print('steps    ', 'time    ', self._parameter_name)\n",
    "\n",
    "    def __call__(self, i, t, f):\n",
    "        t1 = timer()\n",
    "        if i % self.interval == 0:\n",
    "            t11 = timer()\n",
    "            observed = self.observable.lattice.convert_to_numpy(self.observable(f))\n",
    "            t22 = timer()\n",
    "            assert len(observed.shape) < 2\n",
    "            if len(observed.shape) == 0:\n",
    "                observed = [observed.item()]\n",
    "            else:\n",
    "                observed = observed.tolist()\n",
    "            entry = [i, t] + observed\n",
    "            if isinstance(self.out, list):\n",
    "                self.out.append(entry)\n",
    "            else:\n",
    "                print(*entry, file=self.out)\n",
    "        t2 = timer()\n",
    "        print(\" - O.R. i, time:\", i, t2-t1)\n",
    "        print(\" - O.R.observable() i, time:\", i, t22-t11)\n",
    "        #print(\"observable_reporter 'observed'\", observed)\n",
    "\n",
    "class Observable:\n",
    "    def __init__(self, lattice, flow):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "\n",
    "    def __call__(self, f):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class DragCoefficient(Observable):\n",
    "\n",
    "    def __init__(self, lattice, flow, obstacle_boundary, area):\n",
    "        super().__init__(lattice, flow)\n",
    "        self.obstacle_boundary = obstacle_boundary\n",
    "        self.area_lu = area * (self.flow.units.characteristic_length_lu/self.flow.units.characteristic_length_pu) ** (self.lattice.D-1)\n",
    "\n",
    "    def __call__(self, f):\n",
    "        #rho = torch.mean(self.lattice.rho(f[:, 0, ...]))  # simple rho_mean, including the boundary region\n",
    "        # rho_mean (excluding boundary region):\n",
    "        t1 = timer()\n",
    "        #rho_tmp = torch.where(self.fluid_mask, self.lattice.rho(f), self.nan_tensor)\n",
    "        #rho = torch.nanmean(rho_tmp)\n",
    "        #rho = 1#self.lattice.convert_to_tensor(np.array([1]))\n",
    "        t2 = timer()\n",
    "        force_x_lu = self.obstacle_boundary.force_sum[0]  # get current force on obstacle in x direction\n",
    "        t3 = timer()\n",
    "        drag_coefficient = force_x_lu / (0.5 * 1 * self.flow.units.characteristic_velocity_lu ** 2 * self.area_lu)  # calculate drag_coefficient in LU\n",
    "        t4 = timer()\n",
    "        print(\"(!) Drag times: rho, force_sum, FCoeff: \", t2-t1, t3-t2, t4-t3)\n",
    "        return drag_coefficient\n",
    "\n",
    "class LiftCoefficient(Observable):\n",
    "\n",
    "    def __init__(self, lattice, flow, obstacle_boundary, area):\n",
    "        super().__init__(lattice, flow)\n",
    "        self.obstacle_boundary = obstacle_boundary\n",
    "        self.area_lu = area * (self.flow.units.characteristic_length_lu / self.flow.units.characteristic_length_pu) ** (self.lattice.D - 1)\n",
    "\n",
    "    def __call__(self, f):\n",
    "        #rho = torch.mean(self.lattice.rho(f[:, 0, ...]))  # simple rho_mean, including the boundary region\n",
    "        # rho_mean (excluding boundary region):\n",
    "        t1 = timer()\n",
    "        # rho_tmp = torch.where(self.lattice.convert_to_tensor(self.flow.solid_mask), self.lattice.convert_to_tensor(torch.nan), self.lattice.rho(f))\n",
    "        # rho = torch.nanmean(rho_tmp)\n",
    "        t2 = timer()\n",
    "        force_y_lu = self.obstacle_boundary.force_sum[1] # get current force on obstacle in y direction\n",
    "        t3 = timer()\n",
    "        lift_coefficient = force_y_lu / (0.5 * 1 * self.flow.units.characteristic_velocity_lu ** 2 * self.area_lu)  # calculate lift_coefficient in LU\n",
    "        t4 = timer()\n",
    "        print(\"(!) Lift times rho, force_sum, FCoeff: \", t2-t1, t3-t2, t4-t3)\n",
    "        return lift_coefficient\n",
    "\n",
    "# class DragCoefficient(Observable):\n",
    "#\n",
    "#     def __init__(self, lattice, flow, obstacle_boundary, area):\n",
    "#         super().__init__(lattice, flow)\n",
    "#         self.obstacle_boundary = obstacle_boundary\n",
    "#         self.area_lu = area * (self.flow.units.characteristic_length_lu / self.flow.units.characteristic_length_pu) ** (self.lattice.D - 1)\n",
    "#\n",
    "#     def __call__(self, f):\n",
    "#         #rho = torch.mean(self.lattice.rho(f[:, 0, ...]))  # simple rho_mean, including the boundary region\n",
    "#         # rho_mean (excluding boundary region):\n",
    "#         t1 = timer()\n",
    "#         # rho_tmp = torch.where(self.lattice.convert_to_tensor(self.flow.solid_mask), self.lattice.convert_to_tensor(torch.nan), self.lattice.rho(f))\n",
    "#         # rho = torch.nanmean(rho_tmp)\n",
    "#         t2 = timer()\n",
    "#         force_y_lu = self.obstacle_boundary.force_sum[1] # get current force on obstacle in y direction\n",
    "#         t3 = timer()\n",
    "#         lift_coefficient = force_y_lu / (0.5 * 1 * self.flow.units.characteristic_velocity_lu ** 2 * self.area_lu)  # calculate lift_coefficient in LU\n",
    "#         t4 = timer()\n",
    "#         print(\"(!) Lift times rho, force_sum, FCoeff: \", t2-t1, t3-t2, t4-t3)\n",
    "#         return lift_coefficient\n",
    "\n",
    "if calculate_force_coefficients:\n",
    "    # Observable reporter: drag coefficient\n",
    "    DragObservable = DragCoefficient(lattice, flow, sim._boundaries[-1],\n",
    "                                        area=setup_diameter * flow.units.convert_length_to_pu(\n",
    "                                            gridpoints_per_diameter * domain_width_in_D))  # create observable // ! area A=2*r is in PU\n",
    "    Dragreport = ObservableReporter(DragObservable, out=None)  # create reporter and link to created observable\n",
    "\n",
    "\n",
    "    # Observable reporter: lift coefficient\n",
    "    LiftObservable = LiftCoefficient(lattice, flow, sim._boundaries[-1],\n",
    "                                        area=setup_diameter * flow.units.convert_length_to_pu(\n",
    "                                            gridpoints_per_diameter * domain_width_in_D))\n",
    "    Liftreport = ObservableReporter(LiftObservable, out=None)\n",
    "    sim.reporters.append(Liftreport)\n",
    "    sim.reporters.append(Dragreport)  # append reporter to reporter-list of simulator/solver\n",
    "\n",
    "# AvgVelocityReporter\n",
    "if calculate_velocity_profile:\n",
    "    # define positions\n",
    "    position_1 = flow.x_pos - 0.5 + 1.06 * flow.radius * 2  # int(round(flow.x_pos + 1.06 * flow.radius * 2 , 0))\n",
    "    position_2 = flow.x_pos - 0.5 + 1.54 * flow.radius * 2  # int(round(flow.x_pos + 1.54 * flow.radius * 2 , 0))\n",
    "    position_3 = flow.x_pos - 0.5 + 2.02 * flow.radius * 2  # int(round(flow.x_pos + 2.02 * flow.radius * 2 , 0))\n",
    "    print(\"V_avg positions:\" + \" p1: \" + str(position_1) + \" p2:  \" + str(position_2) + \" p3:  \" + str(position_3))\n",
    "\n",
    "    # create and append AvgVelocity-reporter\n",
    "    AvgVelocity1 = lt.AverageVelocityReporter(lattice, flow, position_1)\n",
    "    sim.reporters.append(AvgVelocity1)\n",
    "    AvgVelocity2 = lt.AverageVelocityReporter(lattice, flow, position_2)\n",
    "    sim.reporters.append(AvgVelocity2)\n",
    "    AvgVelocity3 = lt.AverageVelocityReporter(lattice, flow, position_3)\n",
    "    sim.reporters.append(AvgVelocity3)\n",
    "\n",
    "# NaN STOP\n",
    "if nan_reporter:\n",
    "    NaNReporter = lt.NaNReporter(flow, lattice, n_steps, T_target)\n",
    "    sim.reporters.append(NaNReporter)\n",
    "\n",
    "##################################################\n",
    "# PRINT PARAMETERS prior to simulation:\n",
    "print(\"shape_LU:\", gridpoints_per_diameter * domain_length_in_D, \"x\", gridpoints_per_diameter * domain_height_in_D, \"x\",\n",
    "      gridpoints_per_diameter * domain_width_in_D)\n",
    "print(\"T with\", n_steps, \"steps:\",\n",
    "      round(n_steps * (setup_diameter / (gridpoints_per_diameter)) * (Ma * 1 / np.sqrt(3) / flow_velocity), 2),\n",
    "      \"seconds\")\n",
    "print(\"n_steps to simulate 1 second:\",\n",
    "      round(((gridpoints_per_diameter) / setup_diameter) * (flow_velocity / (Ma * 1 / np.sqrt(3))), 2), \"steps\")\n",
    "print(\"n_steps to simulate\", T_target, \"seconds:\",\n",
    "      T_target * round(((gridpoints_per_diameter) / setup_diameter) * (flow_velocity / (Ma * 1 / np.sqrt(3))), 2),\n",
    "      \"steps\")\n",
    "if output_vtk:\n",
    "    print(\"generates approx.\", int(vtk_fps * (\n",
    "                n_steps * (setup_diameter / (gridpoints_per_diameter)) * (Ma * 1 / np.sqrt(3) / flow_velocity))) + 1,\n",
    "          \".vti/.vtk-frames\")\n",
    "\n",
    "##################################################\n",
    "### export parameters to file\n",
    "\n",
    "if output_data:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_parameters.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \" + timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-Parameters   ###\")\n",
    "    output_file.write(\"\\nRe = \" + str(re))\n",
    "    output_file.write(\"\\nn_steps = \" + str(n_steps))\n",
    "    output_file.write(\"\\nT_target = \" + str(flow.units.convert_time_to_pu(n_steps)) + \" seconds\")\n",
    "    output_file.write(\"\\ngridpoints_per_diameter (gpd) = \" + str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \" + str(gpd_setup) + \" to \" + str(\n",
    "            gridpoints_per_diameter) + \" because D/Y is even\")\n",
    "    output_file.write(\"\\nDpX (D/X) = \" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\nDpY (D/Y) = \" + str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\nDpZ (D/Z) = \" + str(domain_width_in_D))\n",
    "    output_file.write(\"\\nshape_LU: \" + str(flow.shape))\n",
    "    output_file.write((\"\\ntotal_number_of_gridpoints: \" + str(lattice.rho(sim.f).numel())))\n",
    "    output_file.write(\"\\nbc_type = \" + str(bc_type))\n",
    "    output_file.write(\"\\nlateral_walls = \" + str(lateral_walls))\n",
    "    output_file.write(\"\\nstencil = \" + str(stencil_choice))\n",
    "    output_file.write(\"\\ncollision = \" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nMa = \" + str(Ma))\n",
    "    output_file.write(\"\\ntau = \" + str(tau))\n",
    "    output_file.write(\"\\ngrid_reynolds_number (Re_g) = \" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nsetup_diameter_PU = \" + str(setup_diameter))\n",
    "    output_file.write(\"\\nflow_velocity_PU = \" + str(flow_velocity))\n",
    "    output_file.write(\"\\nu_init = \" + str(u_init))\n",
    "    output_file.write(\"\\nperturb_init = \" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\noutput_vtk = \" + str(output_vtk))\n",
    "    output_file.write(\"\\nvtk_fps = \" + str(vtk_fps))\n",
    "    output_file.close()\n",
    "\n",
    "### calculate and export 2D obstacle_mask as .png\n",
    "grid_x = gridpoints_per_diameter + 2\n",
    "if output_data:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_obstacle_mask_info.txt\", \"a\")\n",
    "    output_file.write(\"GPD = \" + str(gridpoints_per_diameter) + \"\\n\")\n",
    "    print(\"GPD = \" + str(gridpoints_per_diameter))\n",
    "    # define radius and position for a symetrical circular Cylinder-Obstacle\n",
    "    radius_LU = 0.5 * gridpoints_per_diameter\n",
    "    y_pos_LU = 0.5 * grid_x + 0.5\n",
    "    x_pos_LU = y_pos_LU\n",
    "\n",
    "    # get x,y,z meshgrid of the domain (LU)\n",
    "    xyz = tuple(np.linspace(1, n, n) for n in (grid_x, grid_x))  # Tupel aus Listen indizes (1-n (nicht 0-based!))\n",
    "    xLU, yLU = np.meshgrid(*xyz,\n",
    "                           indexing='ij')  # meshgrid aus den x-, y- (und z-)Indizes -> * damit man die einzelnen Einträge des Tupels übergibt, und nicht das eine Tupel\n",
    "\n",
    "    # define cylinder (LU)\n",
    "    obstacle_mast_for_visualization = np.sqrt((xLU - x_pos_LU) ** 2 + (yLU - y_pos_LU) ** 2) < radius_LU\n",
    "\n",
    "    nx, ny = obstacle_mast_for_visualization.shape  # Anzahl x-Punkte, Anzahl y-Punkte (Skalar), (der gesamten Domain)\n",
    "\n",
    "    rand_mask = np.zeros((nx, ny), dtype=bool)  # für Randpunkte, die es gibt\n",
    "    rand_mask_f = np.zeros((lattice.Q, nx, ny), dtype=bool)  # für Randpunkte (inkl. Q-Dimension)\n",
    "    rand_xq = []  # Liste aller x Werte (inkl. q-multiplizität)\n",
    "    rand_yq = []  # Liste aller y Werte (inkl. q-multiplizität)\n",
    "\n",
    "    a, b = np.where(\n",
    "        obstacle_mast_for_visualization)  # np.array: Liste der (a) x-Koordinaten  und (b) y-Koordinaten der obstacle_mast_for_visualization\n",
    "    # ...um über alle Boundary/Objekt/Wand-Knoten iterieren zu können\n",
    "    for p in range(0, len(a)):  # für alle TRUE-Punkte der obstacle_mast_for_visualization\n",
    "        for i in range(0, lattice.Q):  # für alle stencil-Richtungen c_i (hier lattice.stencil.e)\n",
    "            try:  # try in case the neighboring cell does not exist (an f pointing out of the simulation domain)\n",
    "                if not obstacle_mast_for_visualization[a[p] + lattice.stencil.e[i, 0], b[p] + lattice.stencil.e[i, 1]]:\n",
    "                    # falls in einer Richtung Punkt+(e_x, e_y; e ist c_i) False ist, ist das also ein Oberflächenpunkt des Objekts (selbst True mit Nachbar False)\n",
    "                    rand_mask[a[p], b[p]] = 1\n",
    "                    rand_mask_f[lattice.stencil.opposite[i], a[p], b[p]] = 1\n",
    "                    rand_xq.append(a[p])\n",
    "                    rand_yq.append(b[p])\n",
    "            except IndexError:\n",
    "                pass  # just ignore this iteration since there is no neighbor there\n",
    "    rand_x, rand_y = np.where(rand_mask)  # Liste aller Rand-x- und y-Koordinaten\n",
    "    x_pos = sum(rand_x) / len(rand_x)  # x_Koordinate des Kreis-Zentrums\n",
    "    y_pos = sum(rand_y) / len(rand_y)  # y-Koordinate des Kreis-Zentrums\n",
    "\n",
    "    # calculate all radii and r_max and r_min\n",
    "    r_max = 0\n",
    "    r_min = gridpoints_per_diameter\n",
    "    radii = np.zeros_like(rand_x, dtype=float)  # Liste aller Radien (ohne q) in LU\n",
    "    for p in range(0, len(rand_x)):  # für alle Punkte\n",
    "        radii[p] = np.sqrt(\n",
    "            (rand_x[p] - x_pos) ** 2 + (rand_y[p] - y_pos) ** 2)  # berechne Abstand des Punktes zum Zentrum\n",
    "        if radii[p] > r_max:\n",
    "            r_max = radii[p]\n",
    "        if radii[p] < r_min:\n",
    "            r_min = radii[p]\n",
    "\n",
    "    # calculate all radii (with q-multiplicity)\n",
    "    radii_q = np.zeros_like(rand_xq, dtype=float)\n",
    "    for p in range(0, len(rand_xq)):\n",
    "        radii_q[p] = np.sqrt((rand_xq[p] - x_pos) ** 2 + (rand_yq[p] - y_pos) ** 2)\n",
    "\n",
    "    ### all relative radii in relation to gpd/2\n",
    "    radii_relative = radii / (\n",
    "                radius_LU - 0.5)  # (substract 0.5 because \"true\" boundary location is 0.5LU further out than node-coordinates)\n",
    "    radii_q_relative = radii_q / (radius_LU - 0.5)\n",
    "\n",
    "    # calc. mean rel_radius\n",
    "    r_rel_mean = sum(radii_relative) / len(radii_relative)\n",
    "    rq_rel_mean = sum(radii_q_relative) / len(radii_q_relative)\n",
    "\n",
    "    ## AREA calculation\n",
    "    area_theory = np.pi * (gridpoints_per_diameter / 2) ** 2  # area = pi*r² in LU²\n",
    "    area = len(a)  # area in LU = number of nodes, because every node has a cell of 1LU x 1LU around it\n",
    "\n",
    "    output_file.write(\"\\nr_rel_mean: \" + str(sum(radii_relative) / len(radii_relative)))\n",
    "    output_file.write(\"\\nrq_rel_mean: \" + str(sum(radii_q_relative) / len(radii_q_relative)))\n",
    "    output_file.write(\"\\nr_rel_min: \" + str(r_max / (radius_LU - 0.5)))\n",
    "    output_file.write(\"\\nr_rel_max: \" + str(r_min / (radius_LU - 0.5)))\n",
    "    output_file.write(\"\\n\\narea_rel: \" + str(area / area_theory))\n",
    "    print(\"area_rel: \" + str(area / area_theory))\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    output_file.write(\"\\n\\nradii: \" + str(Counter(radii)))\n",
    "    output_file.write(\"\\nradii_q: \" + str(Counter(radii_q)) + \"\\n\\n\")\n",
    "    output_file.close()\n",
    "\n",
    "    ### PLOT Mask\n",
    "    plt.figure()\n",
    "    plt.imshow(obstacle_mast_for_visualization)\n",
    "    # plt.xticks(np.arange(gridpoints_per_diameter + 2), minor=True)\n",
    "    # plt.yticks(np.arange(gridpoints_per_diameter + 2), minor=True)\n",
    "    ax = plt.gca()\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymax, ymin = ax.get_ylim()\n",
    "    if gridpoints_per_diameter >= 10:\n",
    "        plt.xticks(np.arange(0, xmax, int(xmax / 10)))\n",
    "        plt.yticks(np.arange(0, ymax, int(ymax / 10)))\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, xmax, 1))\n",
    "        plt.yticks(np.arange(0, ymax, 1))\n",
    "    plt.title(\"GPD = \" + str(gridpoints_per_diameter))\n",
    "    ax.set_xticks(np.arange(-.5, xmax, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, ymax, 1), minor=True)\n",
    "    if gridpoints_per_diameter < 30:\n",
    "        ax.grid(which=\"minor\", color=\"k\", axis='both', linestyle='-', linewidth=2)\n",
    "    elif gridpoints_per_diameter < 70:\n",
    "        ax.grid(which=\"minor\", color=\"k\", axis='both', linestyle='-', linewidth=1)\n",
    "    elif gridpoints_per_diameter < 100:\n",
    "        ax.grid(which=\"minor\", color=\"k\", axis='both', linestyle='-', linewidth=0.5)\n",
    "    elif gridpoints_per_diameter < 150:\n",
    "        ax.grid(which=\"minor\", color=\"k\", axis='both', linestyle='-', linewidth=0.25)\n",
    "    plt.savefig(output_path + dir_name + \"/\" + timestamp + \"obtacle_mask_GPD\" + str(gridpoints_per_diameter) + \".png\")\n",
    "    plt.close()\n",
    "\n",
    "##################################################\n",
    "# RUN SIMULATION\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "mlups = sim.step(int(n_steps))  # Simulation with n_steps steps\n",
    "\n",
    "t_end = time.time()\n",
    "runtime = t_end - t_start\n",
    "# output stats\n",
    "print(\"MLUPS:\", mlups)\n",
    "print(\"PU-Time: \", flow.units.convert_time_to_pu(n_steps), \" seconds\")\n",
    "print(\"number of steps:\", n_steps)\n",
    "print(\"runtime: \", runtime, \"seconds (\", round(runtime / 60, 2), \"minutes )\")\n",
    "\n",
    "c_time = sim.time_avg[\"time_collision\"]\n",
    "s_time = sim.time_avg[\"time_streaming\"]\n",
    "b_time = sim.time_avg[\"time_boundary\"]\n",
    "r_time = sim.time_avg[\"time_reporter\"]\n",
    "sum_time = sim.time_avg[\"time_collision\"] + sim.time_avg[\"time_streaming\"] + sim.time_avg[\"time_boundary\"] + \\\n",
    "           sim.time_avg[\"time_reporter\"]\n",
    "\n",
    "print(\"collision avg. time:\", sim.time_avg[\"time_collision\"],\n",
    "      \"seconds (\" + str(round(100 * c_time / sum_time, 2)) + \" %)\")\n",
    "print(\"streaming avg. time:\", sim.time_avg[\"time_streaming\"],\n",
    "      \"seconds (\" + str(round(100 * s_time / sum_time, 2)) + \" %)\")\n",
    "print(\"boundary avg. time:\", sim.time_avg[\"time_boundary\"],\n",
    "      \"seconds (\" + str(round(100 * b_time / sum_time, 2)) + \" %)\")\n",
    "print(\"reporter avg. time:\", sim.time_avg[\"time_reporter\"],\n",
    "      \"seconds (\" + str(round(100 * r_time / sum_time, 2)) + \" %)\")\n",
    "\n",
    "print(\"current VRAM (MB): \", torch.cuda.memory_allocated(lattice.device) / 1024 / 1024)\n",
    "print(\"max. VRAM (MB): \", torch.cuda.max_memory_allocated(lattice.device) / 1024 / 1024)\n",
    "\n",
    "[cpuLoad1, cpuLoad5, cpuLoad15] = [x / psutil.cpu_count() * 100 for x in psutil.getloadavg()]\n",
    "print(\"CPU % avg. over last 1 min, 5 min, 15 min; \", round(cpuLoad1, 2), round(cpuLoad5, 2), round(cpuLoad15, 2))\n",
    "\n",
    "ram = psutil.virtual_memory()\n",
    "print(\"current total RAM usage [MB]: \" + str(round(ram.used / (1024 * 1024), 2)) + \" of \" + str(\n",
    "    round(ram.total / (1024 * 1024), 2)) + \" MB\")\n",
    "\n",
    "# end log_VRAM\n",
    "if args[\"logVRAM\"]:\n",
    "    log_VRAM(\"END log_VRAM\")\n",
    "    vram_history_file.write(\"\\n\\n\" + \"GP: \" + str(gridpoints) + \"\\nD: \" + str(lattice.D) + \"\\nQ: \" + str(lattice.Q) + \"\\n\")\n",
    "    vram_history_file.write(\"\\nTENSORS: \\nDimensions x GP; Size [MB]; Candidates:\"\n",
    "                            + \"\\n\"+\"Qd: \".rjust(4) + str(round(gridpoints*lattice.Q*8/(1024*1024),2)).rjust(10) + \"; f, f_collided, d, f_tmp, tmp\"\n",
    "                            + \"\\n\"+\"Qb: \".rjust(4) + str(round(gridpoints*lattice.Q*1/(1024*1024),2)).rjust(10) + \"; f_mask, no_streaming_mask\"\n",
    "                            + \"\\n\"+\"d: \".rjust(4) + str(round(gridpoints*8/(1024*1024),2)).rjust(10) + \"; rho, p\"\n",
    "                            + \"\\n\"+\"b: \".rjust(4) + str(round(gridpoints*1/(1024*1024),2)).rjust(10) + \"; no_collision_mask\"\n",
    "                            + \"\\n\"+\"Dd: \".rjust(4) + str(round(gridpoints*lattice.D*8/(1024*1024),2)).rjust(10)  + \"; u\"\n",
    "                            + \"\\n\")\n",
    "    vram_history_file.close()\n",
    "\n",
    "\n",
    "### export stats\n",
    "if output_data:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_stats.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \" + timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-STATS  ###\")\n",
    "    output_file.write(\"\\nruntime = \" + str(runtime) + \" seconds (=\" + str(runtime / 60) + \" minutes)\")\n",
    "    output_file.write(\"\\nMLUPS = \" + str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Collision-Time [s] = \" + str(c_time) + \" (\" + str(round(100 * c_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Streaming-Time [s] = \" + str(s_time) + \" (\" + str(round(100 * s_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Boundary-Time  [s] = \" + str(b_time) + \" (\" + str(round(100 * b_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Reporter-Time  [s] = \" + str(r_time) + \" (\" + str(round(100 * r_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nVRAM_current [MB] = \" + str(torch.cuda.memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\nVRAM_peak [MB] = \" + str(torch.cuda.max_memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nCPU load % avg. over last 1, 5, 15 min: \" + str(round(cpuLoad1, 2)) + \" %, \" + str(\n",
    "        round(cpuLoad5, 2)) + \" %, \" + str(round(cpuLoad15, 2)) + \" %\")\n",
    "    output_file.write(\"\\ntotal current RAM usage [MB]: \" + str(round(ram.used / (1024 * 1024), 2)) + \" of \" + str(\n",
    "        round(ram.total / (1024 * 1024), 2)) + \" MB\")\n",
    "    output_file.close()\n",
    "\n",
    "##################################################\n",
    "# CREATE OBSERVABLE-PLOTS & SAVE OBSERVABLE-timeseries\n",
    "\n",
    "# Avg VELOCITY\n",
    "if calculate_velocity_profile:\n",
    "    avg_u_start = 0.5\n",
    "\n",
    "    # import reference data: (data is: first collumn Y/D, second column u_d/u_char)\n",
    "    # ux\n",
    "    p1_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_LS1993.csv', delimiter=';')\n",
    "    p2_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p3_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_LS1993.csv', delimiter=';')\n",
    "\n",
    "    p1_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p2_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p3_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_KM2000.csv', delimiter=';')\n",
    "\n",
    "    p1_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_WR2008.csv', delimiter=';')\n",
    "    p2_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_WR2008.csv', delimiter=';')\n",
    "    p3_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_WR2008.csv', delimiter=';')\n",
    "\n",
    "    p1_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p2_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p3_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_DI2018.csv', delimiter=';')\n",
    "\n",
    "    # uy\n",
    "    p1_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_LS1993.csv', delimiter=';')\n",
    "    p2_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p3_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_LS1993.csv', delimiter=';')\n",
    "\n",
    "    p1_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p2_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p3_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_KM2000.csv', delimiter=';')\n",
    "\n",
    "    p1_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_WR2008.csv', delimiter=';')\n",
    "    p2_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_WR2008.csv', delimiter=';')\n",
    "    p3_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_WR2008.csv', delimiter=';')\n",
    "\n",
    "    p1_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p2_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p3_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "\n",
    "    # uxux\n",
    "    p1_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p1_R2016_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p2_LS1993_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_KM2000.csv', delimiter=';')\n",
    "    p3_R2016_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # uyuy\n",
    "    p1_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_LS1993_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # uxuy\n",
    "    p1_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_BM1994.csv', delimiter=';')\n",
    "    p1_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_LS1993_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_BM1994.csv', delimiter=';')\n",
    "    p3_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # output sim data to files (not averaged over time)\n",
    "    if output_data and output_velocity_profile:\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_1_timeseries.npy\",\n",
    "                np.array(AvgVelocity1.out))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_2_timeseries.npy\",\n",
    "                np.array(AvgVelocity2.out))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_3_timeseries.npy\",\n",
    "                np.array(AvgVelocity3.out))\n",
    "\n",
    "    u1 = np.array(AvgVelocity1.out)[int(avg_u_start * np.array(AvgVelocity1.out).shape[0] - 1):]\n",
    "    u2 = np.array(AvgVelocity2.out)[int(avg_u_start * np.array(AvgVelocity2.out).shape[0] - 1):]\n",
    "    u3 = np.array(AvgVelocity3.out)[int(avg_u_start * np.array(AvgVelocity3.out).shape[0] - 1):]\n",
    "\n",
    "    avg_u1 = np.mean(u1, axis=0)  # time average\n",
    "    avg_u2 = np.mean(u2, axis=0)  # time average\n",
    "    avg_u3 = np.mean(u3, axis=0)  # time average\n",
    "\n",
    "    if output_data:  # output (time-mean) velocity profiles\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_1_t-avg.npy\", avg_u1)\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_2_t-avg.npy\", avg_u2)\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_3_t-avg.npy\", avg_u3)\n",
    "\n",
    "    avg_u1_x = avg_u1[0]  # u_x component over y at pos 1\n",
    "    avg_u2_x = avg_u2[0]  # u_x component over y at pos 2\n",
    "    avg_u3_x = avg_u3[0]  # u_x component over y at pos 3\n",
    "\n",
    "    avg_u1_y = avg_u1[1]  # u_y component over y at pos 1\n",
    "    avg_u2_y = avg_u2[1]  # u_y component over y at pos 2\n",
    "    avg_u3_y = avg_u3[1]  # u_y component over y at pos 3\n",
    "\n",
    "    y_in_D = (np.arange(avg_u1_x.shape[0]) + 1 - flow.y_pos) / flow.units.characteristic_length_lu  # y/D for figure\n",
    "    if output_data:\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_YinD.npy\", y_in_D)\n",
    "    cm = 1 / 2.54\n",
    "    # PLOT ux\n",
    "    fig, (ax_ux, ax_uy) = plt.subplots(1, 2, constrained_layout=True, figsize=(30 * cm, 10 * cm))\n",
    "    ax_ux.plot(y_in_D, avg_u1_x, y_in_D, avg_u2_x, y_in_D, avg_u3_x)\n",
    "    ax_ux.set_xlabel(\"y/D\")\n",
    "    ax_ux.set_ylabel(r\"$\\bar{u}_{x}$/$u_{char}$\")\n",
    "    ax_ux.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    # OPT. TO DO: add secondary axis for LU-grid\n",
    "    # ...needs 'function' to convert from y/D in LU and LU in y/D\n",
    "\n",
    "    # OPT. TO DO: make folder for AvgVelocity-stuff\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_x.png\")\n",
    "    # plt.close()\n",
    "\n",
    "    # PLOT uy\n",
    "    # fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_uy.plot(y_in_D, avg_u1_y, y_in_D, avg_u2_y, y_in_D, avg_u3_y)\n",
    "    ax_uy.set_xlabel(\"y/D\")\n",
    "    ax_uy.set_ylabel(r\"$\\bar{u}_{y}$/$u_{char}$\")\n",
    "    ax_uy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    # OPT. TO DO: add secondary axis for LU-grid\n",
    "    # ...needs 'function' to convert from y/D in LU and LU in y/D\n",
    "    # OPT. TO DO: make folder for AvgVelocity-stuff\n",
    "    # !!! QUESTION: is x/D the position measured FROM the cylinder (x_pos), or measured from x=0 ?\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_velocity_noReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # PLOT ux against references\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D, avg_u1_x, y_in_D, avg_u2_x - 1, y_in_D, avg_u3_x - 2)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p1_LS1993_ux[:, 0], p1_LS1993_ux[:, 1], p2_LS1993_ux[:, 0], p2_LS1993_ux[:, 1], p3_LS1993_ux[:, 0],\n",
    "                     p3_LS1993_ux[:, 1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_ux[:, 0], p1_KM2000_ux[:, 1], p2_KM2000_ux[:, 0], p2_KM2000_ux[:, 1], p3_KM2000_ux[:, 0],\n",
    "                     p3_KM2000_ux[:, 1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_WR = ax.plot(p1_WR2008_ux[:, 0], p1_WR2008_ux[:, 1], p2_WR2008_ux[:, 0], p2_WR2008_ux[:, 1], p3_WR2008_ux[:, 0],\n",
    "                     p3_WR2008_ux[:, 1])\n",
    "    plt.setp(ref_WR, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Wissink & Rodi (2008)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_ux[:, 0], p1_DI2018_ux[:, 1], p2_DI2018_ux[:, 0], p2_DI2018_ux[:, 1], p3_DI2018_ux[:, 0],\n",
    "                     p3_DI2018_ux[:, 1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\bar{u}_{x}$/$u_{char}$\")\n",
    "    ax.set_ylim([-2.5, +2])\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_KM[0], ref_WR[0], ref_DI[0]], loc='best')\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_ux_withReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # PLOT uy against references\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D, avg_u1_y, y_in_D, avg_u2_y - 1, y_in_D, avg_u3_y - 2)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p1_LS1993_uy[:, 0], p1_LS1993_uy[:, 1], p2_LS1993_uy[:, 0], p2_LS1993_uy[:, 1], p3_LS1993_uy[:, 0],\n",
    "                     p3_LS1993_uy[:, 1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_uy[:, 0], p1_KM2000_uy[:, 1], p2_KM2000_uy[:, 0], p2_KM2000_uy[:, 1], p3_KM2000_uy[:, 0],\n",
    "                     p3_KM2000_uy[:, 1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_WR = ax.plot(p1_WR2008_uy[:, 0], p1_WR2008_uy[:, 1], p2_WR2008_uy[:, 0], p2_WR2008_uy[:, 1], p3_WR2008_uy[:, 0],\n",
    "                     p3_WR2008_uy[:, 1])\n",
    "    plt.setp(ref_WR, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Wissink & Rodi (2008)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uy[:, 0], p1_DI2018_uy[:, 1], p2_DI2018_uy[:, 0], p2_DI2018_uy[:, 1], p3_DI2018_uy[:, 0],\n",
    "                     p3_DI2018_uy[:, 1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\bar{u}_{y}$/$u_{char}$\")\n",
    "    ax.set_ylim([-2.5, +1.5])\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_KM[0], ref_WR[0], ref_DI[0]], loc='best')\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_uy_withReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ## turbulent Reynolds stresses\n",
    "\n",
    "    # diff between timeseries and time_average -> u'\n",
    "    u1_diff = u1 - avg_u1\n",
    "    u2_diff = u2 - avg_u2\n",
    "    u3_diff = u3 - avg_u3\n",
    "\n",
    "    # square of diff -> u'^2\n",
    "    u1_diff_sq = u1_diff ** 2\n",
    "    u2_diff_sq = u2_diff ** 2\n",
    "    u3_diff_sq = u3_diff ** 2\n",
    "\n",
    "    # ux'*uy'\n",
    "    u1_diff_xy = u1_diff[:, 0, :] * u1_diff[:, 1, :]\n",
    "    u2_diff_xy = u2_diff[:, 0, :] * u2_diff[:, 1, :]\n",
    "    u3_diff_xy = u3_diff[:, 0, :] * u3_diff[:, 1, :]\n",
    "\n",
    "    # time_average of u'² and ux'uy'\n",
    "    u1_diff_sq_mean = np.mean(u1_diff_sq, axis=0)  # time average\n",
    "    u2_diff_sq_mean = np.mean(u2_diff_sq, axis=0)  # time average\n",
    "    u3_diff_sq_mean = np.mean(u3_diff_sq, axis=0)  # time average\n",
    "    u1_diff_xy_mean = np.mean(u1_diff_xy, axis=0)  # time average\n",
    "    u2_diff_xy_mean = np.mean(u2_diff_xy, axis=0)  # time average\n",
    "    u3_diff_xy_mean = np.mean(u3_diff_xy, axis=0)  # time average\n",
    "\n",
    "    if output_data:  # save reynolds stresses\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_1_ReStress_x.npy\",\n",
    "                np.array([y_in_D, u1_diff_sq_mean[0]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_2_ReStress_x.npy\",\n",
    "                np.array([y_in_D, u2_diff_sq_mean[0]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_3_ReStress_x.npy\",\n",
    "                np.array([y_in_D, u3_diff_sq_mean[0]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_1_ReStress_y.npy\",\n",
    "                np.array([y_in_D, u1_diff_sq_mean[1]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_2_ReStress_y.npy\",\n",
    "                np.array([y_in_D, u2_diff_sq_mean[1]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_3_ReStress_y.npy\",\n",
    "                np.array([y_in_D, u3_diff_sq_mean[1]]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_1_ReShearStress.npy\",\n",
    "                np.array([y_in_D, u1_diff_xy_mean]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_2_ReShearStress.npy\",\n",
    "                np.array([y_in_D, u2_diff_xy_mean]))\n",
    "        np.save(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_3_ReShearStress.npy\",\n",
    "                np.array([y_in_D, u3_diff_xy_mean]))\n",
    "\n",
    "    fig, (ax_xx, ax_yy, ax_xy) = plt.subplots(1, 3, figsize=(40 * cm, 10 * cm), constrained_layout=True)\n",
    "    ax_xx.plot(y_in_D, u1_diff_sq_mean[0], y_in_D, u2_diff_sq_mean[0], y_in_D, u3_diff_sq_mean[0])\n",
    "    ax_xx.set_xlabel(\"y/D\")\n",
    "    ax_xx.set_ylabel(r\"$\\overline{u_{x}'u_{x}'}$/$u_{char}^2$\")\n",
    "    ax_xx.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_uxux.png\")\n",
    "    # plt.close()\n",
    "\n",
    "    # fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_yy.plot(y_in_D, u1_diff_sq_mean[1], y_in_D, u2_diff_sq_mean[1], y_in_D, u3_diff_sq_mean[1])\n",
    "    ax_yy.set_xlabel(\"y/D\")\n",
    "    ax_yy.set_ylabel(r\"$\\overline{u_{y}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax_yy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_uyuy.png\")\n",
    "    # plt.close()\n",
    "\n",
    "    # fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_xy.plot(y_in_D, u1_diff_xy_mean, y_in_D, u2_diff_xy_mean, y_in_D, u3_diff_xy_mean)\n",
    "    ax_xy.set_xlabel(\"y/D\")\n",
    "    ax_xy.set_ylabel(r\"$\\overline{u_{x}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax_xy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_reynoldsStresses_noReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # plot reynolds stresses against reference\n",
    "    # uxux - streamwise\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D, u1_diff_sq_mean[0], y_in_D, u2_diff_sq_mean[0] - 0.5, y_in_D, u3_diff_sq_mean[0] - 1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uxux[:, 0], p2_LS1993_uxux[:, 1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uxux[:, 0], p1_R2016_uxux[:, 1], p3_R2016_uxux[:, 0], p3_R2016_uxux[:, 1],\n",
    "                    p3_R2016_uxux[:, 0], p3_R2016_uxux[:, 1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_uxux[:, 0], p1_KM2000_uxux[:, 1], p2_KM2000_uxux[:, 0], p2_KM2000_uxux[:, 1],\n",
    "                     p3_KM2000_uxux[:, 0], p3_KM2000_uxux[:, 1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uxux[:, 0], p2_BM1994_uxux[:, 1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uxux[:, 0], p1_DI2018_uxux[:, 1], p2_DI2018_uxux[:, 0], p2_DI2018_uxux[:, 1],\n",
    "                     p3_DI2018_uxux[:, 0], p3_DI2018_uxux[:, 1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{x}'u_{x}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2, 0.8])\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_R[0], ref_KM[0], ref_BM[0], ref_DI[0]], loc='best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_uxux_withReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # uyuy - cross-stream\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D, u1_diff_sq_mean[1], y_in_D, u2_diff_sq_mean[1] - 0.5, y_in_D, u3_diff_sq_mean[1] - 1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uyuy[:, 0], p2_BM1994_uyuy[:, 1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uyuy[:, 0], p2_LS1993_uyuy[:, 1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uyuy[:, 0], p1_R2016_uyuy[:, 1], p3_R2016_uyuy[:, 0], p3_R2016_uyuy[:, 1],\n",
    "                    p3_R2016_uyuy[:, 0], p3_R2016_uyuy[:, 1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uyuy[:, 0], p1_DI2018_uyuy[:, 1], p2_DI2018_uyuy[:, 0], p2_DI2018_uyuy[:, 1],\n",
    "                     p3_DI2018_uyuy[:, 0], p3_DI2018_uyuy[:, 1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{y}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2, 0.8])\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.legend(handles=[my_data[0], ref_BM[0], ref_LS[0], ref_R[0], ref_DI[0]], loc='best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_uyuy_withReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # uxuy - Reynolds shear stress\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D, u1_diff_xy_mean, y_in_D, u2_diff_xy_mean - 0.5, y_in_D, u3_diff_xy_mean - 1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uxuy[:, 0], p2_BM1994_uxuy[:, 1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uxuy[:, 0], p2_LS1993_uxuy[:, 1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uxuy[:, 0], p1_R2016_uxuy[:, 1], p3_R2016_uxuy[:, 0], p3_R2016_uxuy[:, 1],\n",
    "                    p3_R2016_uxuy[:, 0], p3_R2016_uxuy[:, 1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uxuy[:, 0], p1_DI2018_uxuy[:, 1], p2_DI2018_uxuy[:, 0], p2_DI2018_uxuy[:, 1],\n",
    "                     p3_DI2018_uxuy[:, 0], p3_DI2018_uxuy[:, 1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{x}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2, 0.8])\n",
    "    ax.set_xlim([-3, 3])\n",
    "    ax.legend(handles=[my_data[0], ref_BM[0], ref_LS[0], ref_R[0], ref_DI[0]], loc='best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path + dir_name + \"/AvgVelocity_Data\" + \"/AvgVelocity_uxuy_withReference.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # (!) standard plot/figure size in python is 6.4 x 4.8 inches\n",
    "\n",
    "# Drag, Lift, Strouhal calculation:\n",
    "if calculate_force_coefficients:\n",
    "    # DRAG COEFFICIENT\n",
    "    try:\n",
    "        try:\n",
    "            drag_coefficient = np.array(Dragreport.out)\n",
    "            fig, ax = plt.subplots(constrained_layout=True)\n",
    "            ax.plot(drag_coefficient[:, 1], drag_coefficient[:, 2])\n",
    "            ax.set_xlabel(\"physical time / s\")\n",
    "            ax.set_ylabel(\"Coefficient of Drag Cd\")\n",
    "            ax.set_ylim([0.5, 1.6])  # change y-limits\n",
    "            secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "            secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "        except:\n",
    "            print(\"(!) drag_plotting didn't work...'\")\n",
    "\n",
    "        if output_data:\n",
    "            try:\n",
    "                plt.savefig(output_path + dir_name + \"/drag_coefficient.png\")\n",
    "            except:\n",
    "                print(\"(!) saving 'drag_coefficient.png' failed!\")\n",
    "            try:\n",
    "                np.savetxt(output_path + dir_name + \"/drag_coefficient.txt\", drag_coefficient,\n",
    "                           header=\"stepLU  |  timePU  |  Cd  FROM str(timestamp)\")\n",
    "            except:\n",
    "                print(\"(!) saving drag_timeseries failed!\")\n",
    "        ax.set_ylim([drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].min() * 0.5,\n",
    "                     drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].max() * 1.2])\n",
    "        if output_data:\n",
    "            try:\n",
    "                plt.savefig(output_path + dir_name + \"/drag_coefficient_adjusted.png\")\n",
    "            except:\n",
    "                print(\"(!) saving drag_coefficient_adjusted.png failed!\")\n",
    "        plt.close()\n",
    "    except:\n",
    "        print(\"(!) analysing drag_coefficient didn't work'\")\n",
    "\n",
    "    # peak finder: try calculating the mean drag coefficient from an integer number of periods, if a clear periodic signal is found\n",
    "    try:\n",
    "        values = drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2]\n",
    "\n",
    "        peaks_max = find_peaks(values, prominence=((values.max() - values.min()) / 2))\n",
    "        peaks_min = find_peaks(-values, prominence=((values.max() - values.min()) / 2))\n",
    "        if peaks_min[0].shape[0] - peaks_max[0].shape[0] > 0:\n",
    "            peak_number = peaks_max[0].shape[0]\n",
    "        else:\n",
    "            peak_number = peaks_min[0].shape[0]\n",
    "\n",
    "        if peaks_min[0][0] < peaks_max[0][0]:\n",
    "            first_peak = peaks_min[0][0]\n",
    "            last_peak = peaks_max[0][peak_number - 1]\n",
    "        else:\n",
    "            first_peak = peaks_max[0][0]\n",
    "            last_peak = peaks_min[0][peak_number - 1]\n",
    "\n",
    "        drag_mean = values[first_peak:last_peak].mean()\n",
    "        drag_mean_simple = values.mean()\n",
    "\n",
    "        print(\"Cd, simple mean:     \", drag_mean_simple)\n",
    "        print(\"Cd, peak_finder mean:\", drag_mean)\n",
    "\n",
    "        drag_stepsLU = drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 0]\n",
    "        peak_max_y = values[peaks_max[0]]\n",
    "        peak_max_x = drag_stepsLU[peaks_max[0]]\n",
    "        peak_min_y = values[peaks_min[0]]\n",
    "        peak_min_x = drag_stepsLU[peaks_min[0]]\n",
    "\n",
    "        plt.plot(drag_stepsLU, values)\n",
    "        plt.scatter(peak_max_x[:peak_number], peak_max_y[:peak_number])\n",
    "        plt.scatter(peak_min_x[:peak_number], peak_min_y[:peak_number])\n",
    "        plt.scatter(drag_stepsLU[first_peak], values[first_peak])\n",
    "        plt.scatter(drag_stepsLU[last_peak], values[last_peak])\n",
    "        plt.savefig(output_path + dir_name + \"/drag_coefficient_peakfinder.png\")\n",
    "        peakfinder = True\n",
    "    except:  # if signal is not sinusoidal enough, calculate only simple mean value\n",
    "        print(\n",
    "            \"peak-finding didn't work... probably no significant peaks visible (Re<46?), or periodic region not reached (T too small)\")\n",
    "        values = drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2]\n",
    "        drag_mean_simple = values.mean()\n",
    "        peakfinder = False\n",
    "        print(\"Cd, simple mean:\", drag_mean_simple)\n",
    "    try:\n",
    "        plt.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # LIFT COEFFICIENT\n",
    "    try:\n",
    "        lift_coefficient = np.array(Liftreport.out)\n",
    "        fig, ax = plt.subplots(constrained_layout=True)\n",
    "        ax.plot(lift_coefficient[:, 1], lift_coefficient[:, 2])\n",
    "        ax.set_xlabel(\"physical time / s\")\n",
    "        ax.set_ylabel(\"Coefficient of Lift Cl\")\n",
    "        ax.set_ylim([-1.1, 1.1])\n",
    "\n",
    "        secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "        secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "        if output_data:\n",
    "            try:\n",
    "                plt.savefig(output_path + dir_name + \"/lift_coefficient.png\")\n",
    "            except:\n",
    "                print(\"(!) saving lift_coefficient.png didn't work!\")\n",
    "            try:\n",
    "                np.savetxt(output_path + dir_name + \"/lift_coefficient.txt\", lift_coefficient,\n",
    "                           header=\"stepLU  |  timePU  |  Cl  FROM str(timestamp)\")\n",
    "            except:\n",
    "                print(\"(!) saving lift_timeline didn't work!\")\n",
    "        Cl_min = lift_coefficient[int(lift_coefficient[:, 2].shape[0] * 0.5):, 2].min()\n",
    "        Cl_max = lift_coefficient[int(lift_coefficient[:, 2].shape[0] * 0.5):, 2].max()\n",
    "        print(\"Cl_peaks: \\nmin\", Cl_min, \"\\nmax\", Cl_max)\n",
    "        plt.close()\n",
    "    except:\n",
    "        print(\"(!) analysing lift_coefficient didn't work!\")\n",
    "\n",
    "    # plot DRAG and LIFT together:\n",
    "    try:\n",
    "        fig, ax = plt.subplots(layout=\"constrained\")\n",
    "        drag_ax = ax.plot(drag_coefficient[:, 1], drag_coefficient[:, 2], color=\"tab:blue\", label=\"Drag\")\n",
    "        ax.set_xlabel(\"physical time / s\")\n",
    "        ax.set_ylabel(\"Coefficient of Drag Cd\")\n",
    "        ax.set_ylim([0.5, 1.6])\n",
    "\n",
    "        secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "        secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        lift_ax = ax2.plot(lift_coefficient[:, 1], lift_coefficient[:, 2], color=\"tab:orange\", label=\"Lift\")\n",
    "        ax2.set_ylabel(\"Coefficient of Lift Cl\")\n",
    "        ax2.set_ylim([-1.1, 1.1])\n",
    "\n",
    "        fig.legend(loc=\"upper left\", bbox_to_anchor=(0, 1), bbox_transform=ax.transAxes)\n",
    "\n",
    "        if output_data:\n",
    "            try:\n",
    "                plt.savefig(output_path + dir_name + \"/dragAndLift_coefficient.png\")\n",
    "            except:\n",
    "                print(\"(!) saving dragAndLift_coefficient.png didn't work!\")\n",
    "                plt.close()\n",
    "    except:\n",
    "        print(\"(!) plotting drag and lift together didn't work!\")\n",
    "\n",
    "    # STROUHAL number: (only makes sense for Re>46 and if periodic state is reached)\n",
    "    try:\n",
    "        ### prototyped fft for frequency detection and calculation of strouhal-number\n",
    "        # ! Drag_frequency is 2* Strouhal-Freq. Lift-freq. is Strouhal-Freq.\n",
    "\n",
    "        X = np.fft.fft(lift_coefficient[:, 2])  # fft result (amplitudes)\n",
    "        N = len(X)  # number of freqs\n",
    "        n = np.arange(N)  # freq index\n",
    "        T = N * flow.units.convert_time_to_pu(1)  # total time measured (T_PU)\n",
    "        freq = n / T  # frequencies (x-axis of spectrum)\n",
    "\n",
    "        plt.figure\n",
    "        plt.stem(freq, np.abs(X), 'b', markerfmt=\" \", basefmt=\"-b\")  # plot spectrum |X|(f)\n",
    "        plt.xlabel(\"Freq (Hz)\")\n",
    "        plt.ylabel(\"FFT Amplitude |X(freq)|\")\n",
    "        plt.xlim(0, 1)\n",
    "        # print(\"max. Amplitude np.abx(X).max():\", np.abs(X).max())   # for debugging\n",
    "        plt.ylim(0, np.abs(X[:int(X.shape[0] * 0.5)]).max())  # ylim, where highes peak is on left half of full spectrum\n",
    "\n",
    "        if output_data:\n",
    "            plt.savefig(output_path + dir_name + \"/fft_Cl.png\")\n",
    "\n",
    "        freq_res = freq[1] - freq[0]  # frequency-resolution\n",
    "        X_abs = np.abs(X[:int(X.shape[0] * 0.4)])  # get |X| Amplitude for left half of full spectrum\n",
    "        freq_peak = freq[np.argmax(X_abs)]  # find frequency with highest amplitude\n",
    "        print(\"Frequency Peak:\", freq_peak, \"+-\", freq_res, \"Hz\")\n",
    "        # f = Strouhal for St=f*D/U and D=U=1 in PU\n",
    "    except:\n",
    "        print(\"fft for Strouhal didn't work\")\n",
    "        freq_res = 0\n",
    "        freq_peak = 0\n",
    "    plt.close()\n",
    "\n",
    "##################################################\n",
    "# OUTPUT DATA and stats to directory\n",
    "\n",
    "### export VRAM info:\n",
    "if output_data:\n",
    "    ### CUDA-VRAM-summary:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_GPU_memory_summary.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \" + timestamp + \"\\n\\n\")\n",
    "    output_file.write(torch.cuda.memory_summary(lattice.device))\n",
    "    output_file.close()\n",
    "\n",
    "    try:\n",
    "        ### list present torch tensors:\n",
    "        output_file = open(output_path + dir_name + \"/\" + timestamp + \"_GPU_list_of_tensors.txt\", \"a\")\n",
    "        total_bytes = 0\n",
    "        import gc\n",
    "\n",
    "        for obj in gc.get_objects():\n",
    "            try:\n",
    "                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                    output_file.write(\"\\n\" + str(obj.size()) + \", \" + str(obj.nelement() * obj.element_size()))\n",
    "                    total_bytes = total_bytes + obj.nelement() * obj.element_size()\n",
    "            except:\n",
    "                pass\n",
    "        # output_file.write(\"\\n\\ntotal bytes for tensors:\"+str(total_bytes))\n",
    "        output_file.close()\n",
    "\n",
    "        ### count occurence of tensors in list of tensors:\n",
    "        from collections import Counter\n",
    "\n",
    "        my_file = open(output_path + dir_name + \"/\" + timestamp + \"_GPU_list_of_tensors.txt\", \"r\")\n",
    "        data = my_file.read()\n",
    "        my_file.close()\n",
    "        data_into_list = data.split(\"\\n\")\n",
    "        c = Counter(data_into_list)\n",
    "        output_file = open(output_path + dir_name + \"/\" + timestamp + \"_GPU_counted_tensors.txt\", \"a\")\n",
    "        for k, v in c.items():\n",
    "            output_file.write(\"type,size,bytes: {}, number: {}\\n\".format(k, v))\n",
    "        output_file.write(\"\\ntotal bytes for tensors:\" + str(total_bytes))\n",
    "        output_file.close()\n",
    "    except:\n",
    "        print(\"(!) counting tensors didn't work!\")\n",
    "\n",
    "# output parameters, stats and observables\n",
    "if output_data:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_parms_stats_obs.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \" + timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-Parameters   ###\")\n",
    "    output_file.write(\"\\nRe = \" + str(re))\n",
    "    output_file.write(\"\\nn_steps = \" + str(n_steps))\n",
    "    output_file.write(\"\\nT_target = \" + str(flow.units.convert_time_to_pu(n_steps)) + \" seconds\")\n",
    "    output_file.write(\"\\ngridpoints_per_diameter (gpd) = \" + str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \" + str(gpd_setup) + \" to \" + str(\n",
    "            gridpoints_per_diameter) + \" because D/Y is even\")\n",
    "    output_file.write(\"\\nDpX (D/X) = \" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\nDpY (D/Y) = \" + str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\nDpZ (D/Z) = \" + str(domain_width_in_D))\n",
    "    output_file.write(\"\\nshape_LU: \" + str(flow.shape))\n",
    "    output_file.write((\"\\ntotal_number_of_gridpoints: \" + str(lattice.rho(sim.f).numel())))\n",
    "    output_file.write(\"\\nbc_type = \" + str(bc_type))\n",
    "    output_file.write(\"\\nlateral_walls = \" + str(lateral_walls))\n",
    "    output_file.write(\"\\nstencil = \" + str(stencil_choice))\n",
    "    output_file.write(\"\\ncollision = \" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nMa = \" + str(Ma))\n",
    "    output_file.write(\"\\ntau = \" + str(tau))\n",
    "    output_file.write(\"\\ngrid_reynolds_number (Re_g) = \" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nsetup_diameter_PU = \" + str(setup_diameter))\n",
    "    output_file.write(\"\\nflow_velocity_PU = \" + str(flow_velocity))\n",
    "    output_file.write(\"\\nu_init = \" + str(u_init))\n",
    "    output_file.write(\"\\nperturb_init = \" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\noutput_vtk = \" + str(output_vtk))\n",
    "    output_file.write(\"\\nvtk_fps = \" + str(vtk_fps))\n",
    "\n",
    "    output_file.write(\"\\n\\n###   SIM-STATS  ###\")\n",
    "    output_file.write(\"\\nruntime = \" + str(runtime) + \" seconds (=\" + str(runtime / 60) + \" minutes)\")\n",
    "    output_file.write(\"\\nMLUPS = \" + str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Collision-Time [s] = \" + str(c_time) + \" (\" + str(round(100 * c_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Streaming-Time [s] = \" + str(s_time) + \" (\" + str(round(100 * s_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Boundary-Time  [s] = \" + str(b_time) + \" (\" + str(round(100 * b_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\n",
    "        \"\\navg. Reporter-Time  [s] = \" + str(r_time) + \" (\" + str(round(100 * r_time / sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nVRAM_current [MB] = \" + str(torch.cuda.memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\nVRAM_peak [MB] = \" + str(torch.cuda.max_memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nCPU load % avg. over last 1, 5, 15 min: \" + str(round(cpuLoad1, 2)) + \" %, \" + str(\n",
    "        round(cpuLoad5, 2)) + \" %, \" + str(round(cpuLoad15, 2)) + \" %\")\n",
    "    output_file.write(\"\\ntotal current RAM usage [MB]: \" + str(round(ram.used / (1024 * 1024), 2)) + \" of \" + str(\n",
    "        round(ram.total / (1024 * 1024), 2)) + \" MB\")\n",
    "\n",
    "    if calculate_force_coefficients:\n",
    "        output_file.write(\"\\n\\n###   OBSERVABLES   ###\")\n",
    "        output_file.write(\"\\nCoefficient of drag between \" + str(\n",
    "            round(drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1), 1], 2)) + \" s and \" + str(\n",
    "            round(drag_coefficient[int(drag_coefficient.shape[0] - 1), 1], 2)) + \" s:\")\n",
    "        output_file.write(\"\\nCd_mean, simple      = \" + str(drag_mean_simple))\n",
    "        if peakfinder:\n",
    "            output_file.write(\"\\nCd_mean, peak_finder = \" + str(drag_mean))\n",
    "        else:\n",
    "            output_file.write(\"\\nnoPeaksFound\")\n",
    "        output_file.write(\n",
    "            \"\\nCd_min = \" + str(drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].min()))\n",
    "        output_file.write(\n",
    "            \"\\nCd_max = \" + str(drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].max()))\n",
    "        output_file.write(\"\\n\")\n",
    "        output_file.write(\"\\nCoefficient of lift:\")\n",
    "        output_file.write(\"\\nCl_min = \" + str(Cl_min))\n",
    "        output_file.write(\"\\nCl_max = \" + str(Cl_max))\n",
    "        output_file.write(\"\\n\")\n",
    "        output_file.write(\"\\nStrouhal number:\")\n",
    "        output_file.write(\"\\nSt +- df = \" + str(freq_peak) + \" +- \" + str(freq_res) + \" Hz\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.close()\n",
    "\n",
    "# output copyable numbers for EXCEL etc.\n",
    "if output_data:\n",
    "    output_file = open(output_path + dir_name + \"/\" + timestamp + \"_parms_stats_obs_copyable.txt\", \"a\")\n",
    "\n",
    "    output_file.write(\"DATA for \" + timestamp)\n",
    "    output_file.write(\"\\n\\n###   Data:   ###\")\n",
    "    output_file.write(\n",
    "        \"\\nRe, n_steps, t_target(PU), GPD, DpX, DpY, (DpZ), shape_LU, gridpoints, bc_type, lateral_walls, stencil, collision, Ma, tau, Re_grid, setup_diameter_PU, flow_velocity_PU, u_init, perturb_init, output_vtk, vtk_fps, runtime, MLUPS, c_time, s_time, b_time, r_time, VRAM_current_MB, VRAM_peak_MB, periodic_start, Cd_mean, Cd_mean_pf, Cd_min, Cd_max, Cl_min, Cl_max, St, df\\n\")\n",
    "    output_file.write(\"\\n\" + str(re))\n",
    "    output_file.write(\"\\n\" + str(n_steps))\n",
    "    output_file.write(\"\\n\" + str(flow.units.convert_time_to_pu(n_steps)))\n",
    "    output_file.write(\"\\n\" + str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \" + str(gpd_setup) + \" to \" + str(\n",
    "            gridpoints_per_diameter) + \" because D/Y is even\")\n",
    "    output_file.write(\"\\n\" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\n\" + str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\n\" + str(domain_width_in_D))\n",
    "    output_file.write(\"\\n\" + str(flow.shape))\n",
    "    output_file.write(\"\\n\" + str(lattice.rho(sim.f).numel()))\n",
    "    output_file.write(\"\\n\" + str(bc_type))\n",
    "    output_file.write(\"\\n\" + str(lateral_walls))\n",
    "    output_file.write(\"\\n\" + str(stencil_choice))\n",
    "    output_file.write(\"\\n\" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(Ma))\n",
    "    output_file.write(\"\\n\" + str(tau))\n",
    "    output_file.write(\"\\n\" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(setup_diameter))\n",
    "    output_file.write(\"\\n\" + str(flow_velocity))\n",
    "    output_file.write(\"\\n\" + str(u_init))\n",
    "    output_file.write(\"\\n\" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(output_vtk))\n",
    "    output_file.write(\"\\n\" + str(vtk_fps))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "    output_file.write(\"\\n\" + str(runtime))\n",
    "    output_file.write(\"\\n\" + str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(c_time))\n",
    "    output_file.write(\"\\n\" + str(s_time))\n",
    "    output_file.write(\"\\n\" + str(b_time))\n",
    "    output_file.write(\"\\n\" + str(r_time))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(torch.cuda.memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\n\" + str(torch.cuda.max_memory_allocated(lattice.device) / 1024 / 1024))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "    output_file.write(\"\\n\" + str(periodic_start))\n",
    "    if calculate_force_coefficients:\n",
    "        output_file.write(\"\\n\" + str(drag_mean_simple))\n",
    "        if peakfinder:\n",
    "            output_file.write(\"\\n\" + str(drag_mean))\n",
    "        else:\n",
    "            output_file.write(\"\\nnoPeaksFound\")\n",
    "        output_file.write(\"\\n\" + str(drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].min()))\n",
    "        output_file.write(\"\\n\" + str(drag_coefficient[int(drag_coefficient.shape[0] * periodic_start - 1):, 2].max()))\n",
    "        output_file.write(\"\\n\")\n",
    "        output_file.write(\"\\n\" + str(Cl_min))\n",
    "        output_file.write(\"\\n\" + str(Cl_max))\n",
    "        output_file.write(\"\\n\")\n",
    "        output_file.write(\"\\n\" + str(freq_peak))\n",
    "        output_file.write(\"\\n\" + str(freq_res))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([8.0075e-15, 9.0206e-16, 1.3878e-17], device='cuda:0',\n       dtype=torch.float64)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim._boundaries[-1].force_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[<lettuce.reporters.ObservableReporter at 0x7ff9fdd06bc0>,\n <lettuce.reporters.ObservableReporter at 0x7ff9fdd06560>]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.reporters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959],\n          [0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959],\n          [0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959],\n          ...,\n          [0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959],\n          [0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959],\n          [0.2959, 0.2959, 0.2959,  ..., 0.2959, 0.2959, 0.2959]],\n\n         [[0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          ...,\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963]],\n\n         [[0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          ...,\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963]],\n\n         ...,\n\n         [[0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          ...,\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963]],\n\n         [[0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          ...,\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963]],\n\n         [[0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          ...,\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963],\n          [0.2963, 0.2963, 0.2963,  ..., 0.2963, 0.2963, 0.2963]]],\n\n\n        [[[0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807],\n          [0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807],\n          [0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807],\n          ...,\n          [0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807],\n          [0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807],\n          [0.0807, 0.0807, 0.0807,  ..., 0.0807, 0.0807, 0.0807]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0742,  ..., 0.0739, 0.0740, 0.0741],\n          [0.0741, 0.0742, 0.0742,  ..., 0.0740, 0.0740, 0.0741],\n          [0.0741, 0.0742, 0.0743,  ..., 0.0740, 0.0740, 0.0741],\n          ...,\n          [0.0740, 0.0741, 0.0742,  ..., 0.0739, 0.0740, 0.0740],\n          [0.0741, 0.0741, 0.0742,  ..., 0.0739, 0.0740, 0.0741],\n          [0.0741, 0.0741, 0.0742,  ..., 0.0739, 0.0740, 0.0741]],\n\n         ...,\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]]],\n\n\n        [[[0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678],\n          [0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678],\n          [0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678],\n          ...,\n          [0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678],\n          [0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678],\n          [0.0678, 0.0678, 0.0678,  ..., 0.0678, 0.0678, 0.0678]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         ...,\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]],\n\n         [[0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          ...,\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741],\n          [0.0741, 0.0741, 0.0741,  ..., 0.0741, 0.0741, 0.0741]]],\n\n\n        ...,\n\n\n        [[[0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          ...,\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         ...,\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]]],\n\n\n        [[[0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n          ...,\n          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n          [0.0050, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         ...,\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]]],\n\n\n        [[[0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          ...,\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         ...,\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]],\n\n         [[0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          ...,\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046],\n          [0.0046, 0.0046, 0.0046,  ..., 0.0046, 0.0046, 0.0046]]]],\n       device='cuda:0', dtype=torch.float64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drag times rho, force_sum, FCoeff:  1.6999911167658865e-07 3.5740000384976156e-05 0.00029678600003535394\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(6.4060e-14, device='cuda:0', dtype=torch.float64)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DragObservable(sim.f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(9.0206e-16, device='cuda:0', dtype=torch.float64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim._boundaries[-1].force_sum[1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.tensor(torch.nan)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
