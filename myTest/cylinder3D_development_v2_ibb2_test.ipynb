{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lettuce as lt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "from lettuce.boundary import EquilibriumBoundaryPU, EquilibriumOutletP, AntiBounceBackOutlet\n",
    "from lettuce.observables import Observable\n",
    "from lettuce.unit import UnitConversion\n",
    "from lettuce.util import append_axes\n",
    "#from lettuce import ObstacleMax3D\n",
    "#from lettuce.flows.obstacleCylinder import ObstacleCylinder\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import psutil\n",
    "import shutil\n",
    "from pyevtk.hl import imageToVTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "### OUTPUT SETTINGS\n",
    "output_data = False\n",
    "output_vtk = False # is overwritten with False if output_data=False (see below)\n",
    "vtk_fps = 10\n",
    "calculate_velocity_profile = False  # outputs plots and time-averaged data for plots\n",
    "output_velocity_profile = False  # outputs the full time series (!)\n",
    "\n",
    "# IMPORTANT: set correct output_path, for example \"/home/YourUserName/simulation_output\"\n",
    "output_path = \"/mnt/ScratchHDD1/Max_Scratch/lbm_simulations\"  # lokal HBRS\n",
    "#output_path = \"/home/max/Documents/lbm_simulations\"  # lokal Bonn\n",
    "#output_path = \"/home/mbille3s/02_lbm_simulations\"  # cluster HBRS\n",
    "\n",
    "# IMPORTANT: set correct input_path for reference data:\n",
    "diIlio_path = '/home/mbille/lettuce/myTest/DiIlio_data/'  # lokal HBRS\n",
    "#diIlio_path = \"/home/max/lettuce/myTest/DiIlio_data/\" # lokal Bonn\n",
    "# diIlio_path = '/scratch/mbille3s/21_LBM/03_reference_data/DiIlio_2018/'  # cluster HBRS\n",
    "\n",
    "# name: if you want something specific in the dir-name\n",
    "name = \"cyl3D_test_ibb2\"\n",
    "\n",
    "# choose stencil: \"D3Q9\" dor 2D, \"D3Q15\", \"D3Q19\", \"D3Q27\" for 3D\n",
    "stencil_choice = \"D3Q27\"\n",
    "# choose collision operator: \"bgk, \"kbc\", \"reg\"\n",
    "collision_choice = \"bgk\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_LU: 10 x 5 x 5\n",
      "T with 34642 steps: 1000.03 seconds\n",
      "n_steps to simulate 1 second: 34.64 steps\n",
      "n_steps to simulate 200 seconds: 6928.0 steps\n",
      "No. of gridpoints: 250\n"
     ]
    }
   ],
   "source": [
    "### SIMULATION PARAMETERS (and estimation of timesteps needed to reach T_target)\n",
    "re = 200   # Reynoldsnumber\n",
    "Ma = 0.05     # Machnumber\n",
    "n_steps = 34642 #145492 # number of steps\n",
    "setup_diameter = 1  # D_PU = char_length_pu -> this defines the PU-Reference\n",
    "flow_velocity = 1  # U_PU = char_velocity_pu -> this defines the PU-Reference velocity (u_max of inflow)\n",
    "\n",
    "# relative starting point for drag-measurement (make sure periodic state is reached)\n",
    "periodic_start = 0.9  # relative start of peak_finding for Cd_mean Measurement to cut of any transients\n",
    "\n",
    "# GEOMETRY\n",
    "gridpoints_per_diameter = 1  # gp_per_D = GPD -> this defines the resolution ( D_LU = GPD)\n",
    "domain_height_in_D = 5  # D/Y = DpY = diameters per domain width in Y-direction -> this defines the domain-size and total number of Lattice-Nodes\n",
    "domain_length_in_D = 2 * domain_height_in_D  # D/X = domain length in X- / flow-direction\n",
    "domain_width_in_D = 5 #domain_height_in_D #1/gridpoints_per_diameter  # D/Z = DpZ = diameters per domain width in Z-direction -> domain size in periodic 3rd dimension\n",
    "\n",
    "# RELATION [GPD to DpY] check\n",
    "# if DpY is even, resulting GPD can't be odd for symmetrical cylinder and channel\n",
    "# ...if DpY is even, GPD will be corrected to even GPD for symmetrical cylinder\n",
    "# ...use odd DpY to use odd GPD\n",
    "gpd_correction=False\n",
    "if domain_height_in_D % 2 == 0 and gridpoints_per_diameter % 2 != 0:\n",
    "    gpd_correction = True   # gpd_was_corrected-flag\n",
    "    gpd_setup = gridpoints_per_diameter   # store old gpd for output\n",
    "    gridpoints_per_diameter = int(gridpoints_per_diameter/2)*2   # make gpd even\n",
    "    print(\"(!) domain_height_in_D is even, gridpoints_per_diameter will be \"+str(gridpoints_per_diameter)+\". Use odd domain_height_in_D to enable use of odd GPD!\")\n",
    "\n",
    "# SIMULATOR settings\n",
    "u_init = 0    # initial velocity field: # 0: uniform u=0, # 1: uniform u=1, # 2: parabolic, amplitude u_char_lu (similar to poiseuille-flow)\n",
    "perturb_init = True   # perturb initial symmetry by small sine-wave in initial velocity field -> triggers Karman-vortex street for Re > 46\n",
    "lateral_walls='periodic'  # type of top/bottom boundary: 'bounceback' = frictious wall, 'periodic' = periodic boundary, 'slip' = non-frictious wall\n",
    "bc_type='ibb1c1'  # choose algorithm for bounceback-boundaries: fullway 'fwbb', halfway 'hwbb', linear interpolated 'ibb1'\n",
    "\n",
    "# T_PU to n_steps estimation: (for example for Re=200 the periodic state is reached for T_PU > 140)\n",
    "T_target=200\n",
    "print(\"shape_LU:\", gridpoints_per_diameter*domain_length_in_D, \"x\", gridpoints_per_diameter*domain_height_in_D, \"x\", gridpoints_per_diameter*domain_width_in_D)\n",
    "print(\"T with\", n_steps, \"steps:\", round(n_steps * (setup_diameter/(gridpoints_per_diameter))*(Ma*1/np.sqrt(3)/flow_velocity),2), \"seconds\")\n",
    "print(\"n_steps to simulate 1 second:\", round(((gridpoints_per_diameter)/setup_diameter)*(flow_velocity/(Ma*1/np.sqrt(3))),2), \"steps\")\n",
    "print(\"n_steps to simulate\",T_target,\"seconds:\",T_target*round(((gridpoints_per_diameter)/setup_diameter)*(flow_velocity/(Ma*1/np.sqrt(3))),2), \"steps\")\n",
    "\n",
    "\n",
    "mlups_2060super = 20\n",
    "mlups_2080ti = 30   # 40 for GPD30,DpY19,nsteps=150000 (steigend mit der Aufl√∂sung)\n",
    "\n",
    "if output_vtk:\n",
    "    print(\"generates approx.\", int(vtk_fps*(n_steps * (setup_diameter/(gridpoints_per_diameter))*(Ma*1/np.sqrt(3)/flow_velocity)))+1, \".vti/.vtk-frames\")\n",
    "\n",
    "gridpoints = gridpoints_per_diameter**3*domain_length_in_D*domain_height_in_D*domain_width_in_D\n",
    "print(\"No. of gridpoints:\", gridpoints)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "### (no user input) CREATE OUTPUT DIRECTORIES\n",
    "if output_data:  # toggle output\n",
    "    timestamp = datetime.datetime.now()\n",
    "    timestamp = timestamp.strftime(\"%y%m%d\")+\"_\"+timestamp.strftime(\"%H%M%S\")\n",
    "\n",
    "    dir_name = \"/data_\" + str(timestamp) + \"_\" + name + \"_\" + bc_type + \"_GPD\" + str(gridpoints_per_diameter) + \"_\" + str(domain_length_in_D) + \"x\" + str(domain_height_in_D) + \"x\" + str(domain_width_in_D) + \"_\" + str(stencil_choice)\n",
    "    os.makedirs(output_path+dir_name)\n",
    "\n",
    "    if output_vtk:\n",
    "        vtk_path = output_path+dir_name+\"/vtk/out\"\n",
    "        print(\"vtk_path: \" + vtk_path)\n",
    "    print(\"dir_name: \"+dir_name)\n",
    "\n",
    "    if calculate_velocity_profile:\n",
    "        os.makedirs(output_path+dir_name+\"/AvgVelocity_Data\")\n",
    "else:\n",
    "    output_vtk = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class InterpolatedBounceBackBoundary_compact_v1:\n",
    "\n",
    "    def __init__(self, mask, lattice, x_center, y_center, radius, interpolation_order=1):\n",
    "        t_init_start = time.time()\n",
    "        self.interpolation_order = interpolation_order\n",
    "        self.mask = mask  # location of solid-nodes\n",
    "        self.lattice = lattice\n",
    "        self.force_sum = torch.zeros_like(self.lattice.convert_to_tensor(self.lattice.stencil.e[0]))  # summed force vector on all boundary nodes, in D dimensions (x,y,(z))\n",
    "\n",
    "        self.f_index_fluid1_lt = []  # indices of relevant populations (for bounce back and force-calculation) with d<=0.5\n",
    "        self.f_index_fluid1_gt = []  # indices of relevant populations (for bounce back and force-calculation) with d>0.5\n",
    "\n",
    "        self.f_index_fluid2_lt = []  # second fluid node for quadratic interpolatin\n",
    "        self.f_index_fluid2_gt = []\n",
    "        \n",
    "        self.d_lt = []  # distances between node and boundary for d<0.5\n",
    "        self.d_gt = []  # distances between node and boundary for d>0.5\n",
    "\n",
    "        # searching boundary-fluid-interface and append indices to f_index, distance to boundary to d\n",
    "        if self.lattice.D == 2:\n",
    "            nx, ny = mask.shape  # domain size in x and y\n",
    "            self.f_mask = np.zeros((self.lattice.Q, nx, ny), dtype=bool)  # f_mask: [q, nx, ny], marks all fs which point from fluid to solid (boundary), needed to collect f_collided in simulation\n",
    "            a, b = np.where(mask)  # x- and y-index of boundaryTRUE nodes for iteration over boundary area\n",
    "\n",
    "            for p in range(0, len(a)):  # for all TRUE-nodes in boundary.mask\n",
    "                for i in range(0, self.lattice.Q):  # for all stencil-directions c_i (lattice.stencil.e in lettuce)\n",
    "                    # check for boundary-nodes neighboring the domain-border.\n",
    "                    # ...they have to take the periodicity into account...\n",
    "                    border = np.zeros(self.lattice.D, dtype=int)\n",
    "                    border2 = np.zeros(self.lattice.D, dtype=int)\n",
    "\n",
    "                    # 1-node search for linear interpolation\n",
    "                    if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left [x]\n",
    "                        border[0] = -1\n",
    "                    elif a[p] == nx - 1 and self.lattice.e[i, 0] == 1:  # searching border on right [x]\n",
    "                        border[0] = 1\n",
    "\n",
    "                    if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left [y]\n",
    "                        border[1] = -1\n",
    "                    elif b[p] == ny - 1 and self.lattice.e[i, 1] == 1:  # searching border on right [y]\n",
    "                        border[1] = 1\n",
    "                        \n",
    "                    # 2-node search for quadratic interpolation\n",
    "                    if a[p] == 1 and self.lattice.stencil.e[i, 0] == -1:\n",
    "                        border2[0] = -1\n",
    "                    elif a[p] == nx - 2 and self.lattice.e[i, 0] == 1:\n",
    "                        border2[0] = 1    \n",
    "                    \n",
    "                    if b[p] == 1 and self.lattice.stencil.e[i, 1] == -1:\n",
    "                        border2[1] = -1\n",
    "                    elif b[p] == ny - 2 and self.lattice.e[i, 1] == 1:\n",
    "                        border2[1] = 1\n",
    "\n",
    "                    try:  # try in case the neighboring cell does not exist (= an f pointing out of the simulation domain)\n",
    "                        if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                    b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny]:\n",
    "                            # if the neighbour of p is False in the boundary.mask, p is a solid node, neighbouring a fluid node:\n",
    "                            # ...the direction pointing from the fluid neighbour to solid p is marked on the neighbour\n",
    "\n",
    "                            self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                        a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny] = 1  # f_mask[q,x,y], marks all fs which point from fluid to solid (boundary)\n",
    "\n",
    "                            # calculate intersection point of boundary surface and link ->\n",
    "                            # ...calculate distance between fluid node and boundary surface on the link\n",
    "                            px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                            py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                            cx = self.lattice.stencil.e[\n",
    "                                self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                            cy = self.lattice.stencil.e[\n",
    "                                self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "\n",
    "                            # pq-formula\n",
    "                            h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                            h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                  - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                         cx * cx + cy * cy)  # q\n",
    "\n",
    "                            d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                            d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                            # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                            # choose correct d and assign d and f_index\n",
    "                            if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "\n",
    "                                if d1 <= 0.5:\n",
    "                                    self.d_lt.append(d1)\n",
    "                                    self.f_index_fluid1_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny])\n",
    "                                    self.f_index_fluid2_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + 2*self.lattice.stencil.e[i, 0] - border[0] * nx - border2[0] * nx,\n",
    "                                                            b[p] + 2*self.lattice.stencil.e[i, 1] - border[1] * ny - border2[1] * ny])\n",
    "                                else:  # d>0.5\n",
    "                                    self.d_gt.append(d1)\n",
    "                                    self.f_index_fluid1_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny])\n",
    "                                    self.f_index_fluid2_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + 2*self.lattice.stencil.e[i, 0] - border[0] * nx - border2[0] * nx,\n",
    "                                                            b[p] + 2*self.lattice.stencil.e[i, 1] - border[1] * ny - border2[1] * ny])\n",
    "\n",
    "                            elif d2 <= 1 and np.isreal(d2):  # d should be between 0 and 1\n",
    "\n",
    "                                if d2 <= 0.5:\n",
    "                                    self.d_lt.append(d2)\n",
    "                                    self.f_index_fluid1_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny])\n",
    "                                    self.f_index_fluid2_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + 2*self.lattice.stencil.e[i, 0] - border[0] * nx - border2[0] * nx,\n",
    "                                                            b[p] + 2*self.lattice.stencil.e[i, 1] - border[1] * ny - border2[1] * ny])\n",
    "                                else:  # d>0.5\n",
    "                                    self.d_gt.append(d2)\n",
    "                                    self.f_index_fluid1_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                            b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny])\n",
    "                                    self.f_index_fluid2_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                            a[p] + 2*self.lattice.stencil.e[i, 0] - border[0] * nx - border2[0] * nx,\n",
    "                                                            b[p] + 2*self.lattice.stencil.e[i, 1] - border[1] * ny - border2[1] * ny])\n",
    "                            else:  # neither d1 or d2 is real and between 0 and 1\n",
    "                                print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,ci\", a[p],\n",
    "                                      b[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                      self.lattice.stencil.e[i, 2])\n",
    "                    except IndexError:\n",
    "                        pass  # just ignore this iteration since there is no neighbor there\n",
    "\n",
    "        if self.lattice.D == 3:  # like 2D, but in 3D...guess what...\n",
    "            nx, ny, nz = mask.shape\n",
    "            self.f_mask = np.zeros((self.lattice.Q, nx, ny, nz), dtype=bool)\n",
    "            a, b, c = np.where(mask)\n",
    "\n",
    "            for p in range(0, len(a)):\n",
    "                for i in range(0, self.lattice.Q):\n",
    "                    border = np.zeros(self.lattice.D, dtype=int)\n",
    "                    border2 = np.zeros(self.lattice.D, dtype=int)\n",
    "                    # x - direction\n",
    "                    if a[p] == 0 and self.lattice.stencil.e[i, 0] == -1:  # searching border on left\n",
    "                        border[0] = -1\n",
    "                    elif a[p] == nx - 1 and self.lattice.stencil.e[i, 0] == 1:  # searching border on right\n",
    "                        border[0] = 1\n",
    "                    # y - direction\n",
    "                    if b[p] == 0 and self.lattice.stencil.e[i, 1] == -1:  # searching border on left\n",
    "                        border[1] = -1\n",
    "                    elif b[p] == ny - 1 and self.lattice.stencil.e[i, 1] == 1:  # searching border on right\n",
    "                        border[1] = 1\n",
    "                    # z - direction\n",
    "                    if c[p] == 0 and self.lattice.stencil.e[i, 2] == -1:  # searching border on left\n",
    "                        border[2] = -1\n",
    "                    elif c[p] == nz - 1 and self.lattice.stencil.e[i, 2] == 1:  # searching border on right\n",
    "                        border[2] = 1\n",
    "\n",
    "                    # 2-node search for quadratic interpolation\n",
    "                    if a[p] == 1 and self.lattice.stencil.e[i, 0] == -1:\n",
    "                        border2[0] = -1\n",
    "                    elif a[p] == nx - 2 and self.lattice.stencil.e[i, 0] == 1:\n",
    "                        border2[0] = 1\n",
    "\n",
    "                    if b[p] == 1 and self.lattice.stencil.e[i, 1] == -1:\n",
    "                        border2[1] = -1\n",
    "                    elif b[p] == ny - 2 and self.lattice.stencil.e[i, 1] == 1:\n",
    "                        border2[1] = 1\n",
    "\n",
    "                    if c[p] == 1 and self.lattice.stencil.e[i, 2] == -1:\n",
    "                        border2[2] = -1\n",
    "                    elif c[p] == nz - 2 and self.lattice.stencil.e[i, 2] == 1:\n",
    "                        border2[2] = 1\n",
    "\n",
    "                    try:  # try in case the neighboring cell does not exist (an f pointing out of simulation domain)\n",
    "                        if not mask[a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                    b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                    c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz]:\n",
    "                            self.f_mask[self.lattice.stencil.opposite[i],\n",
    "                                        a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                        b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                        c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz] = 1\n",
    "\n",
    "                            # calculate intersection point of boundary surface and link ->\n",
    "                            # ...calculate distance between fluid node and boundary surface on the link\n",
    "                            px = a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx  # fluid node x-coordinate\n",
    "                            py = b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny  # fluid node y-coordinate\n",
    "                            # Z-coodinate not needed for cylinder !\n",
    "\n",
    "                            cx = self.lattice.stencil.e[\n",
    "                                self.lattice.stencil.opposite[i], 0]  # link-direction x to solid node\n",
    "                            cy = self.lattice.stencil.e[\n",
    "                                self.lattice.stencil.opposite[i], 1]  # link-direction y to solid node\n",
    "                            # Z-coodinate not needed for cylinder !\n",
    "\n",
    "                            # pq-formula\n",
    "                            h1 = (px * cx + py * cy - cx * x_center - cy * y_center) / (cx * cx + cy * cy)  # p/2\n",
    "                            h2 = (px * px + py * py + x_center * x_center + y_center * y_center\n",
    "                                  - 2 * px * x_center - 2 * py * y_center - radius * radius) / (\n",
    "                                         cx * cx + cy * cy)  # q\n",
    "\n",
    "                            d1 = - h1 + np.sqrt(h1 * h1 - h2)\n",
    "                            d2 = - h1 - np.sqrt(h1 * h1 - h2)\n",
    "\n",
    "                            # print(\"xb,yb,i,d1,d2 xf, yf, cx, cy:\", a[p], b[p], i, d1, d2, px, py, cx, cy)\n",
    "\n",
    "                            # distance (LU) from fluid node to the \"true\" boundary location\n",
    "                            # choose correct d and assign d and f_index\n",
    "                            if d1 <= 1 and np.isreal(d1):  # d should be between 0 and 1\n",
    "\n",
    "                                if d1 <= 0.5:\n",
    "                                    self.d_lt.append(d1)\n",
    "                                    self.f_index_fluid1_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                                   b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                                   c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz])\n",
    "                                    self.f_index_fluid2_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + 2*self.lattice.stencil.e[i, 0] - border2[0] * nx,\n",
    "                                                                   b[p] + 2*self.lattice.stencil.e[i, 1] - border2[1] * ny,\n",
    "                                                                   c[p] + 2*self.lattice.stencil.e[i, 2] - border2[2] * nz])\n",
    "                                else:  # d>0.5\n",
    "                                    self.d_gt.append(d1)\n",
    "                                    self.f_index_fluid1_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                                   b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                                   c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz])\n",
    "                                    self.f_index_fluid2_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + 2*self.lattice.stencil.e[i, 0] - border2[0] * nx,\n",
    "                                                                   b[p] + 2*self.lattice.stencil.e[i, 1] - border2[1] * ny,\n",
    "                                                                   c[p] + 2*self.lattice.stencil.e[i, 2] - border2[2] * nz])\n",
    "\n",
    "                            elif d2 <= 1 and np.isreal(d2): # d should be between 0 and 1\n",
    "\n",
    "                                if d2 <= 0.5:\n",
    "                                    self.d_lt.append(d2)\n",
    "                                    self.f_index_fluid1_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                                   b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                                   c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz])\n",
    "                                    self.f_index_fluid2_lt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + 2*self.lattice.stencil.e[i, 0] - border2[0] * nx,\n",
    "                                                                   b[p] + 2*self.lattice.stencil.e[i, 1] - border2[1] * ny,\n",
    "                                                                   c[p] + 2*self.lattice.stencil.e[i, 2] - border2[2] * nz])\n",
    "                                else:  # d>0.5\n",
    "                                    self.d_gt.append(d2)\n",
    "                                    self.f_index_fluid1_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + self.lattice.stencil.e[i, 0] - border[0] * nx,\n",
    "                                                                   b[p] + self.lattice.stencil.e[i, 1] - border[1] * ny,\n",
    "                                                                   c[p] + self.lattice.stencil.e[i, 2] - border[2] * nz])\n",
    "                                    self.f_index_fluid2_gt.append([self.lattice.stencil.opposite[i],\n",
    "                                                                   a[p] + 2*self.lattice.stencil.e[i, 0] - border2[0] * nx,\n",
    "                                                                   b[p] + 2*self.lattice.stencil.e[i, 1] - border2[1] * ny,\n",
    "                                                                   c[p] + 2*self.lattice.stencil.e[i, 2] - border2[2] * nz])\n",
    "                            else:  # neither d1 or d2 is real and between 0 and 1\n",
    "                                print(\"IBB WARNING: d1 is\", d1, \"; d2 is\", d2, \"for boundaryPoint x,y,z,ci\", a[p],\n",
    "                                      b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                      self.lattice.stencil.e[i, 2])\n",
    "                            print(\"POINT\", p,\", i\",i, \" b1\", border, \"; b2\", border2, \"for boundaryPoint x,y,z,ci\", a[p],\n",
    "                                      b[p], c[p], self.lattice.stencil.e[i, 0], self.lattice.stencil.e[i, 1],\n",
    "                                      self.lattice.stencil.e[i, 2])\n",
    "                    except IndexError:\n",
    "                        pass  # just ignore this iteration since there is no neighbor there\n",
    "\n",
    "\n",
    "        # convert relevant tensors:\n",
    "        # self.f_mask = self.lattice.convert_to_tensor(self.f_mask)\n",
    "        \n",
    "        self.f_index_fluid1_lt = torch.tensor(np.array(self.f_index_fluid1_lt), device=self.lattice.device,\n",
    "                                       dtype=torch.int64)  # the batch-index has to be integer\n",
    "        self.f_index_fluid1_gt = torch.tensor(np.array(self.f_index_fluid1_gt), device=self.lattice.device,\n",
    "                                       dtype=torch.int64)  # the batch-index has to be integer\n",
    "        \n",
    "        self.f_index_fluid2_lt = torch.tensor(np.array(self.f_index_fluid2_lt), device=self.lattice.device,\n",
    "                                       dtype=torch.int64)  # the batch-index has to be integer\n",
    "        self.f_index_fluid2_gt = torch.tensor(np.array(self.f_index_fluid2_gt), device=self.lattice.device,\n",
    "                                       dtype=torch.int64)  # the batch-index has to be integer\n",
    "        \n",
    "        self.d_lt = self.lattice.convert_to_tensor(np.array(self.d_lt))\n",
    "        self.d_gt = self.lattice.convert_to_tensor(np.array(self.d_gt))\n",
    "        self.opposite_tensor = torch.tensor(self.lattice.stencil.opposite, device=self.lattice.device, dtype=torch.int64)  # batch-index has to be a tensor\n",
    "\n",
    "        f_collided_lt = torch.zeros_like(self.d_lt)  # float-tensor with number of (x_b nodes with d<=0.5) values\n",
    "        f_collided_gt = torch.zeros_like(self.d_gt)  # float-tensor with number of (x_b nodes with d>0.5) values\n",
    "        f_collided_lt_opposite = torch.zeros_like(self.d_lt)\n",
    "        f_collided_gt_opposite = torch.zeros_like(self.d_gt)\n",
    "        self.f_collided_lt = torch.stack((f_collided_lt, f_collided_lt_opposite), dim=1)\n",
    "        self.f_collided_gt = torch.stack((f_collided_gt, f_collided_gt_opposite), dim=1)\n",
    "\n",
    "        print(\"IBB initialization took \" + str(time.time() - t_init_start) + \"seconds\")\n",
    "\n",
    "    def __call__(self, f):\n",
    "\n",
    "        # BOUNCE (Bouzidi et al. (2001), as described in Kruger et al. (2017))\n",
    "        if self.lattice.D == 2:\n",
    "            # if d <= 0.5\n",
    "            # INTER1\n",
    "            # f[self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "            #   self.f_index_fluid1_lt[:, 1],\n",
    "            #   self.f_index_fluid1_lt[:, 2]] = 2 * self.d_lt * self.f_collided.to_dense()[self.f_index_fluid1_lt[:, 0],\n",
    "            #                                                                  self.f_index_fluid1_lt[:, 1],\n",
    "            #                                                                  self.f_index_fluid1_lt[:, 2]] \\\n",
    "            #                            + (1 - 2 * self.d_lt) * f[self.f_index_fluid1_lt[:, 0],\n",
    "            #                                                      self.f_index_fluid1_lt[:, 1],\n",
    "            #                                                      self.f_index_fluid1_lt[:, 2]]\n",
    "            #INTER2\n",
    "            f[self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "              self.f_index_fluid1_lt[:, 1],\n",
    "              self.f_index_fluid1_lt[:, 2]] = self.d_lt*(2*self.d_lt+1) * self.f_collided.to_dense()[self.f_index_fluid1_lt[:, 0],  # f_c\n",
    "                                                                                                     self.f_index_fluid1_lt[:, 1],\n",
    "                                                                                                     self.f_index_fluid1_lt[:, 2]] \\\n",
    "                                              + (1+2*self.d_lt) * (1-2*self.d_lt) * f[self.f_index_fluid1_lt[:, 0],  # f_c-1 (ginge auch mit fc.tpo_dense()[f_index2]\n",
    "                                                                                      self.f_index_fluid1_lt[:, 1],\n",
    "                                                                                      self.f_index_fluid1_lt[:, 2]] \\\n",
    "                                              - self.d_lt*(1-2*self.d_lt) * f[self.f_index_fluid2_lt[:, 0],  # f_c-2\n",
    "                                                                                      self.f_index_fluid2_lt[:, 1],\n",
    "                                                                                      self.f_index_fluid2_lt[:, 2]]\n",
    "\n",
    "            # if d > 0.5\n",
    "            #INTER1\n",
    "            # f[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "            #   self.f_index_fluid1_gt[:, 1],\n",
    "            #   self.f_index_fluid1_gt[:, 2]] = (1 / (2 * self.d_gt)) * self.f_collided.to_dense()[self.f_index_fluid1_gt[:, 0],\n",
    "            #                                                                          self.f_index_fluid1_gt[:, 1],\n",
    "            #                                                                          self.f_index_fluid1_gt[:, 2]] \\\n",
    "            #                            + (1 - 1 / (2 * self.d_gt)) * self.f_collided.to_dense()[\n",
    "            #                                self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "            #                                self.f_index_fluid1_gt[:, 1],\n",
    "            #                                self.f_index_fluid1_gt[:, 2]]\n",
    "            #INTER2\n",
    "            f[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "              self.f_index_fluid1_gt[:, 1],\n",
    "              self.f_index_fluid1_gt[:, 2]] = 1/(self.d_gt*(2*self.d_gt+1))*self.f_collided.to_dense()[self.f_index_fluid1_gt[:, 0],  # f_c\n",
    "                                                                                                       self.f_index_fluid1_gt[:, 1],\n",
    "                                                                                                       self.f_index_fluid1_gt[:, 2]] \\\n",
    "                                              + (2*self.d_gt-1)/self.d_gt * self.f_collided.to_dense()[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],  # f_c[opposite]\n",
    "                                                                                                       self.f_index_fluid1_gt[:, 1],\n",
    "                                                                                                       self.f_index_fluid1_gt[:, 2]] \\\n",
    "                                              + (1-2*self.d_gt)/(1+2*self.d_gt) * f[self.opposite_tensor[self.f_index_fluid1_gt[:,0]],  # f_c-1[opposite]\n",
    "                                                                                    self.f_index_fluid1_gt[:,1],\n",
    "                                                                                    self.f_index_fluid1_gt[:,2]]\n",
    "\n",
    "        if self.lattice.D == 3:\n",
    "            # if d <= 0.5\n",
    "            # f[self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "            #   self.f_index_fluid1_lt[:, 1],\n",
    "            #   self.f_index_fluid1_lt[:, 2],\n",
    "            #   self.f_index_fluid1_lt[:, 3]] = 2 * self.d_lt * self.f_collided.to_dense()[self.f_index_fluid1_lt[:, 0],\n",
    "            #                                                                  self.f_index_fluid1_lt[:, 1],\n",
    "            #                                                                  self.f_index_fluid1_lt[:, 2],\n",
    "            #                                                                  self.f_index_fluid1_lt[:, 3]] \\\n",
    "            #                              + (1 - 2 * self.d_lt) * f[self.f_index_fluid1_lt[:, 0],\n",
    "            #                                                        self.f_index_fluid1_lt[:, 1],\n",
    "            #                                                        self.f_index_fluid1_lt[:, 2],\n",
    "            #                                                        self.f_index_fluid1_lt[:, 3]]\n",
    "            #INTER2\n",
    "            f[self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "              self.f_index_fluid1_lt[:, 1],\n",
    "              self.f_index_fluid1_lt[:, 2],\n",
    "              self.f_index_fluid1_lt[:, 3]] = self.d_lt*(2*self.d_lt+1) * self.f_collided_lt[:, 0]\\\n",
    "                                              + (1+2*self.d_lt) * (1-2*self.d_lt) * f[self.f_index_fluid1_lt[:, 0],  # f_c-1 (ginge auch mit fc.tpo_dense()[f_index2]\n",
    "                                                                                      self.f_index_fluid1_lt[:, 1],\n",
    "                                                                                      self.f_index_fluid1_lt[:, 2],\n",
    "                                                                                      self.f_index_fluid1_lt[:, 3]] \\\n",
    "                                              - self.d_lt*(1-2*self.d_lt) * f[self.f_index_fluid2_lt[:, 0],  # f_c-2\n",
    "                                                                                      self.f_index_fluid2_lt[:, 1],\n",
    "                                                                                      self.f_index_fluid2_lt[:, 2],\n",
    "                                                                                      self.f_index_fluid2_lt[:, 3]]\n",
    "            print(\"inter1< done\")\n",
    "            # if d > 0.5\n",
    "            # f[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "            #   self.f_index_fluid1_gt[:, 1],\n",
    "            #   self.f_index_fluid1_gt[:, 2],\n",
    "            #   self.f_index_fluid1_gt[:, 3]] = (1 / (2 * self.d_gt)) * self.f_collided.to_dense()[self.f_index_fluid1_gt[:, 0],\n",
    "            #                                                                          self.f_index_fluid1_gt[:, 1],\n",
    "            #                                                                          self.f_index_fluid1_gt[:, 2],\n",
    "            #                                                                          self.f_index_fluid1_gt[:, 3]] \\\n",
    "            #                              + (1 - 1 / (2 * self.d_gt)) * self.f_collided.to_dense()[\n",
    "            #                                          self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "            #                                          self.f_index_fluid1_gt[:, 1],\n",
    "            #                                          self.f_index_fluid1_gt[:, 2],\n",
    "            #                                          self.f_index_fluid1_gt[:, 3]]\n",
    "            #INTER2\n",
    "            f[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "              self.f_index_fluid1_gt[:, 1],\n",
    "              self.f_index_fluid1_gt[:, 2],\n",
    "              self.f_index_fluid1_gt[:, 3]] = 1/(self.d_gt*(2*self.d_gt+1)) * self.f_collided_gt[:, 0]\\\n",
    "                                              + (2*self.d_gt-1)/self.d_gt * self.f_collided_gt[:, 1]\\\n",
    "                                              + (1-2*self.d_gt)/(1+2*self.d_gt) * f[self.opposite_tensor[self.f_index_fluid1_gt[:,0]],  # f_c-1[opposite]\n",
    "                                                                                    self.f_index_fluid1_gt[:,1],\n",
    "                                                                                    self.f_index_fluid1_gt[:,2],\n",
    "                                                                                    self.f_index_fluid1_gt[:,3]]\n",
    "\n",
    "        # CALCULATE FORCE\n",
    "        self.calc_force_on_boundary(f)\n",
    "        return f\n",
    "\n",
    "    def make_no_stream_mask(self, f_shape):\n",
    "        assert self.mask.shape == f_shape[1:]  # all dimensions of f except the 0th (q)\n",
    "        # no_stream_mask has to be dimensions: (q,x,y,z) (z optional), but CAN be (x,y,z) (z optional).\n",
    "        # ...in the latter case, torch.where broadcasts the mask to (q,x,y,z), so ALL q populations of a lattice-node are marked equally\n",
    "        return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "    def make_no_collision_mask(self, f_shape):\n",
    "        # INFO: pay attention to the initialization of observable/moment-fields (u, rho,...) on the boundary nodes,\n",
    "        # ...in the initial solution of your flow, especially if visualization or post processing uses the field-values\n",
    "        # ...in the whole domain (including the boundary region)!\n",
    "        assert self.mask.shape == f_shape[1:]\n",
    "        return self.lattice.convert_to_tensor(self.mask)\n",
    "\n",
    "    def calc_force_on_boundary(self, f_bounced):\n",
    "        ### force = e * (f_collided + f_bounced[opp.])\n",
    "        if self.lattice.D == 2:\n",
    "            self.force_sum = torch.einsum('i..., id -> d',\n",
    "                                          self.f_collided_lt[:, 0] + f_bounced[\n",
    "                                              self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "                                              self.f_index_fluid1_lt[:, 1],\n",
    "                                              self.f_index_fluid1_lt[:, 2]],\n",
    "                                          self.lattice.e[self.f_index_fluid1_lt[:, 0]]) \\\n",
    "                             + torch.einsum('i..., id -> d',\n",
    "                                            self.f_collided_gt[:, 0] + f_bounced[\n",
    "                                                self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "                                                self.f_index_fluid1_gt[:, 1],\n",
    "                                                self.f_index_fluid1_gt[:, 2]],\n",
    "                                            self.lattice.e[self.f_index_fluid1_gt[:, 0]])\n",
    "        if self.lattice.D == 3:\n",
    "            self.force_sum = torch.einsum('i..., id -> d',\n",
    "                                          self.f_collided_lt[:, 0] + f_bounced[\n",
    "                                              self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\n",
    "                                              self.f_index_fluid1_lt[:, 1],\n",
    "                                              self.f_index_fluid1_lt[:, 2],\n",
    "                                              self.f_index_fluid1_lt[:, 3]],\n",
    "                                          self.lattice.e[self.f_index_fluid1_lt[:, 0]]) \\\n",
    "                             + torch.einsum('i..., id -> d',\n",
    "                                            self.f_collided_gt[:, 0] + f_bounced[\n",
    "                                                self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\n",
    "                                                self.f_index_fluid1_gt[:, 1],\n",
    "                                                self.f_index_fluid1_gt[:, 2],\n",
    "                                                self.f_index_fluid1_gt[:, 3]],\n",
    "                                            self.lattice.e[self.f_index_fluid1_gt[:, 0]])\n",
    "\n",
    "    def store_f_collided(self, f_collided):\n",
    "        if self.lattice.D == 2:\n",
    "            self.f_collided_lt[:, 0] = torch.clone(f_collided[self.f_index_fluid1_lt[:, 0],  # q\n",
    "                                                          self.f_index_fluid1_lt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_lt[:, 2]])  # y\n",
    "            self.f_collided_lt[:, 1] = torch.clone(f_collided[self.opposite_tensor[self.f_index_fluid1_lt[:,0]],  # q\n",
    "                                                          self.f_index_fluid1_lt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_lt[:, 2]])  # y\n",
    "\n",
    "            self.f_collided_gt[:, 0] = torch.clone(f_collided[self.f_index_fluid1_gt[:, 0],  # q\n",
    "                                                          self.f_index_fluid1_gt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_gt[:, 2]])  # y\n",
    "            self.f_collided_gt[:, 1] = torch.clone(f_collided[self.opposite_tensor[self.f_index_fluid1_gt[:,0]],  # q\n",
    "                                                          self.f_index_fluid1_gt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_gt[:, 2]])  # y\n",
    "        if self.lattice.D == 3:\n",
    "            self.f_collided_lt[:, 0] = torch.clone(f_collided[self.f_index_fluid1_lt[:, 0],  # q\n",
    "                                                          self.f_index_fluid1_lt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_lt[:, 2],  # y\n",
    "                                                          self.f_index_fluid1_lt[:, 3]])  # z\n",
    "            self.f_collided_lt[:, 1] = torch.clone(f_collided[self.opposite_tensor[self.f_index_fluid1_lt[:,0]],  # q\n",
    "                                                          self.f_index_fluid1_lt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_lt[:, 2],  # y\n",
    "                                                          self.f_index_fluid1_lt[:, 3]])  # z\n",
    "\n",
    "            self.f_collided_gt[:, 0] = torch.clone(f_collided[self.f_index_fluid1_gt[:, 0],  # q\n",
    "                                                          self.f_index_fluid1_gt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_gt[:, 2],  # y\n",
    "                                                          self.f_index_fluid1_gt[:, 3]])  # z\n",
    "            self.f_collided_gt[:, 1] = torch.clone(f_collided[self.opposite_tensor[self.f_index_fluid1_gt[:,0]],  # q\n",
    "                                                          self.f_index_fluid1_gt[:, 1],  # x\n",
    "                                                          self.f_index_fluid1_gt[:, 2],  # y\n",
    "                                                          self.f_index_fluid1_gt[:, 3]])  # z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer as timer\n",
    "from lettuce import (\n",
    "    LettuceException, HalfwayBounceBackBoundary, FullwayBounceBackBoundary,\n",
    "    InterpolatedBounceBackBoundary, InterpolatedBounceBackBoundary_compact_v2,\n",
    "    FullwayBounceBackBoundary_compact, HalfwayBounceBackBoundary_compact_v1, HalfwayBounceBackBoundary_compact_v2,\n",
    "    HalfwayBounceBackBoundary_compact_v3\n",
    ")\n",
    "\n",
    "class Simulation:\n",
    "    \"\"\"High-level API for simulations.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    reporters : list\n",
    "        A list of reporters. Their call functions are invoked after every simulation step (and before the first one).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, flow, lattice, collision, streaming):\n",
    "        self.flow = flow\n",
    "        self.lattice = lattice\n",
    "        self.collision = collision\n",
    "        self.streaming = streaming\n",
    "        self.i = 0  # index of the current timestep\n",
    "\n",
    "        # M.Bille:\n",
    "        self.store_f_collided = []  # toggle if f is stored after collision and not overwritten through streaming,\n",
    "        # ...f_collided might be needed together with f_collided_and_streamed for boundary-conditions or calculation of\n",
    "        # ...momentum exchange (force on boundary, coefficient of drag etc.)\n",
    "        self.times = [[], [], [], [], []]  # list of lists for time-measurement (collision, streaming, boundary, reporters)\n",
    "        self.time_avg = dict()\n",
    "\n",
    "        # CALCULATE INITIAL SOLUTION of flow and CHECK initial solution for correct dimensions\n",
    "        grid = flow.grid\n",
    "        p, u = flow.initial_solution(grid)\n",
    "        assert list(p.shape) == [1] + list(grid[0].shape), \\\n",
    "            LettuceException(f\"Wrong dimension of initial pressure field. \"\n",
    "                             f\"Expected {[1] + list(grid[0].shape)}, \"\n",
    "                             f\"but got {list(p.shape)}.\")\n",
    "        assert list(u.shape) == [lattice.D] + list(grid[0].shape), \\\n",
    "            LettuceException(\"Wrong dimension of initial velocity field.\"\n",
    "                             f\"Expected {[lattice.D] + list(grid[0].shape)}, \"\n",
    "                             f\"but got {list(u.shape)}.\")\n",
    "\n",
    "        # INITIALIZE distribution function f: convert u and rho from numpy to torch.tensor\n",
    "        u = lattice.convert_to_tensor(flow.units.convert_velocity_to_lu(u))\n",
    "        rho = lattice.convert_to_tensor(flow.units.convert_pressure_pu_to_density_lu(p))\n",
    "        self.f = lattice.equilibrium(rho, lattice.convert_to_tensor(u))\n",
    "\n",
    "        # list of reporters\n",
    "        self.reporters = []\n",
    "\n",
    "        # Define masks, where collision or streaming are not applied\n",
    "        # (initialized with 0, later specified by e.g. boundary conditions)\n",
    "        x = flow.grid  # meshgrid, dimensions: D x nx x ny (x nz)\n",
    "        self.no_collision_mask = lattice.convert_to_tensor(np.zeros_like(x[0], dtype=bool))  # dimensions: nx x ny (x nz)\n",
    "        no_stream_mask = lattice.convert_to_tensor(np.zeros(self.f.shape, dtype=bool))\n",
    "            # \"self\" and \"no self\" because no_stream_mask is written to streaming-object in the init,\n",
    "            # ... no_collision_mask is used in the simulation.step()\n",
    "\n",
    "        # retrieve no-streaming and no-collision markings from all boundaries\n",
    "        self._boundaries = deepcopy(self.flow.boundaries)  # store locally to keep the flow free from the boundary state -> WHY?\n",
    "        for boundary in self._boundaries:\n",
    "            if hasattr(boundary, \"make_no_collision_mask\"):\n",
    "                # get no-collision markings from boundaries\n",
    "                self.no_collision_mask = self.no_collision_mask | boundary.make_no_collision_mask(self.f.shape)\n",
    "            if hasattr(boundary, \"make_no_stream_mask\"):\n",
    "                # get no-streaming markings from boundaries\n",
    "                no_stream_mask = no_stream_mask | boundary.make_no_stream_mask(self.f.shape)\n",
    "        if no_stream_mask.any():\n",
    "            # write no_streaming_mask to streaming-object\n",
    "            self.streaming.no_stream_mask = no_stream_mask\n",
    "\n",
    "        # define f_collided (post-collision, pre-streaming f) storage format for hwbb, ibb1, ibb1c1 or ibb1c2, ...\n",
    "        self.boundary_range = range(len(self._boundaries))\n",
    "        for boundary_index in self.boundary_range:\n",
    "            if hasattr(self._boundaries[boundary_index], \"store_f_collided\"):\n",
    "                self.store_f_collided.append(True)\n",
    "                self._boundaries[boundary_index].store_f_collided(self.f)\n",
    "            else:\n",
    "                self.store_f_collided.append(False)\n",
    "\n",
    "    def step(self, num_steps):\n",
    "        \"\"\" Take num_steps stream-and-collision steps and return performance in MLUPS.\n",
    "        M.Bille: added force_calculation on object/boundaries\n",
    "        M.Bille: added halfway bounce back boundary\n",
    "        \"\"\"\n",
    "        start = timer()\n",
    "        if self.i == 0:  # if this is the first timestep, calc. initial force on Object/walls/boundary/obstacle and call reporters\n",
    "            # reporters are called before the first timestep\n",
    "            self._report()\n",
    "        for _ in range(num_steps):  # simulate num_step timesteps\n",
    "            time1 = timer()\n",
    "\n",
    "            ### COLLISION\n",
    "            # Perform the collision routine everywhere, expect where the no_collision_mask is true\n",
    "            # ...and store post-collision population for halfway-bounce-back boundary condition\n",
    "            self.f = torch.where(self.no_collision_mask, self.f, self.collision(self.f))\n",
    "\n",
    "            time2 = timer()\n",
    "\n",
    "            ### STORE f_collided FOR BOUNDARIES needing pre-streaming populations for bounce or force-calculation\n",
    "            for boundary_index in self.boundary_range:\n",
    "                if self.store_f_collided[boundary_index]:\n",
    "                    self._boundaries[boundary_index].store_f_collided(self.f)\n",
    "\n",
    "            time3 = timer()\n",
    "\n",
    "            ### STREAMING\n",
    "            self.f = self.streaming(self.f)\n",
    "\n",
    "            time4 = timer()\n",
    "\n",
    "            ### BOUNDARY\n",
    "            # apply boundary conditions\n",
    "            for boundary in self._boundaries:\n",
    "                self.f = boundary(self.f)\n",
    "\n",
    "            # count step\n",
    "            self.i += 1\n",
    "\n",
    "            time5 = timer()\n",
    "            # call reporters\n",
    "            self._report()\n",
    "\n",
    "            time6 = timer()\n",
    "            self.times[0].append(time2-time1)  # time to collide\n",
    "            self.times[1].append(time3-time2)  # time to store f_collided\n",
    "            self.times[2].append(time4-time3)  # time to stream\n",
    "            self.times[3].append(time5-time4)  # time to boundary\n",
    "            self.times[4].append(time6-time5)  # time to report\n",
    "        end = timer()\n",
    "\n",
    "        # calculate individual runtimes (M.Bille)\n",
    "        if num_steps > 0:\n",
    "            self.time_avg = dict(time_collision=sum(self.times[0])/len(self.times[0]),\n",
    "                                 time_store_f_collided=sum(self.times[1])/len(self.times[1]),\n",
    "                                 time_streaming=sum(self.times[2])/len(self.times[2]),\n",
    "                                 time_boundary=sum(self.times[3])/len(self.times[3]),\n",
    "                                 time_reporter=sum(self.times[4])/len(self.times[4]))\n",
    "        else:  # no division by zero\n",
    "            self.time_avg = dict(time_collision=-1,\n",
    "                                 time_store_f_collided=-1,\n",
    "                                 time_streaming=-1,\n",
    "                                 time_boundary=-1,\n",
    "                                 time_reporter=-1)\n",
    "\n",
    "        # calculate runtime and performance in MLUPS\n",
    "        seconds = end - start\n",
    "        num_grid_points = self.lattice.rho(self.f).numel()\n",
    "        mlups = num_steps * num_grid_points / 1e6 / seconds\n",
    "        return mlups\n",
    "\n",
    "    def _report(self):\n",
    "        for reporter in self.reporters:\n",
    "            reporter(self.i, self.flow.units.convert_time_to_pu(self.i), self.f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from lettuce.unit import UnitConversion\n",
    "from lettuce.util import append_axes\n",
    "from lettuce.boundary import EquilibriumBoundaryPU, \\\n",
    "    BounceBackBoundary, EquilibriumOutletP, SlipBoundary\n",
    "\n",
    "\n",
    "class ObstacleCylinder:\n",
    "    \"\"\"\n",
    "        add description here: unified version of 2D and 3D cylinder flow\n",
    "        refined version of flow/obstacle.py, for cylinder-flow in 2D or 3D. The dimensions will be assumed from\n",
    "        lattice.D\n",
    "\n",
    "        Flow:\n",
    "        - inflow (EquilibriumBoundaryPU) at x=0, outflow (EquilibriumOutletP) at x=xmax\n",
    "        - further boundaries depend on parameters:\n",
    "            - lateral (y direction): periodic, no-slip wall, slip wall\n",
    "            - lateral (z direction): periodic (only if lattice.D==3)\n",
    "        - obstacle: cylinder obstacle centered at (y_lu/2, y_LU/2), with radius, uniform symmetry in z-direction\n",
    "            - obstacle mask has to be set externally?\n",
    "        - boundary condition for obstacle can be chosen: hwbb, fwbb, ibb1\n",
    "        - initial pertubation (trigger Von K√°rm√°n vortex street for Re>46) can be initialized in y and z direction\n",
    "        - initial velocity can be 0, u_char or a parabolic profile (parabolic if lateral_walls = \"bounceback\")\n",
    "        - inlet/inflow velocity can be uniform u_char or parabolic\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        <to fill>\n",
    "        ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, reynolds_number, mach_number, lattice, char_length_pu, char_length_lu, char_velocity_pu=1,\n",
    "                 lateral_walls='periodic', bc_type='fwbb', perturb_init=True, u_init=0,\n",
    "                 x_offset=0, y_offset=0):\n",
    "        # shape of the domain (2D or 3D):\n",
    "        if len(shape) != lattice.D:\n",
    "            raise ValueError(f\"{lattice.D}-dimensional lattice requires {lattice.D}-dimensional `shape`\")\n",
    "        if len(shape) == 2:\n",
    "            self.shape = (int(shape[0]), int(shape[1]))\n",
    "        elif len(shape) == 3:\n",
    "            self.shape = (int(shape[0]), int(shape[1]), int(shape[2]))\n",
    "        else:\n",
    "            print(\"WARNING: shape is not 2- or 3-dimensional...(!)\")\n",
    "        #self.shape = shape\n",
    "\n",
    "        self.char_length_pu = char_length_pu  # characteristic length\n",
    "\n",
    "        self.units = UnitConversion(\n",
    "            lattice,\n",
    "            reynolds_number=reynolds_number,\n",
    "            mach_number=mach_number,\n",
    "            characteristic_length_lu=char_length_lu,\n",
    "            characteristic_length_pu=char_length_pu,\n",
    "            characteristic_velocity_pu=char_velocity_pu  # reminder: u_char_lu = Ma * cs_lu = Ma * 1/sqrt(3)\n",
    "        )\n",
    "\n",
    "        # flow and boundary settings\n",
    "        self.perturb_init = perturb_init  # toggle: introduce asymmetry in initial solution to trigger v'Karman Vortex Street\n",
    "        self.u_init = u_init  # toggle: initial solution velocity profile type\n",
    "        self.lateral_walls = lateral_walls  # toggle: lateral walls to be bounce back (bounceback), slip wall (slip) or periodic (periodic)\n",
    "        self.bc_type = bc_type  # toggle: bounce back algorithm: halfway (hwbb) or fullway (fwbb)\n",
    "\n",
    "        # initialize masks (init with zeros)\n",
    "        self.solid_mask = np.zeros(shape=self.shape, dtype=bool)  # marks all solid nodes (obstacle, walls, ...)\n",
    "        self.in_mask = np.zeros(self.grid[0].shape, dtype=bool)  # marks all inlet nodes\n",
    "        self.wall_mask = np.zeros_like(self.solid_mask)  # marks lateral (top+bottom) walls\n",
    "        self._obstacle_mask = np.zeros_like(self.solid_mask)  # marks all obstacle nodes (for fluid-solid-force_calc.)\n",
    "\n",
    "        # cylinder geometry in LU (1-based indexing!)\n",
    "        self.x_offset = x_offset\n",
    "        self.y_offset = y_offset\n",
    "        self.radius = char_length_lu / 2\n",
    "        self.y_pos = self.shape[1] / 2 + 0.5 + self.y_offset  # y_position of cylinder-center in 1-based indexing\n",
    "        self.x_pos = self.y_pos + self.x_offset  # keep symmetry of cylinder in x and y direction\n",
    "\n",
    "        xyz = tuple(np.linspace(1, n, n) for n in self.shape)  # Tupel of index-lists (1-n (one-based!))\n",
    "        if self.units.lattice.D == 2:\n",
    "            x_lu, y_lu = np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y-index\n",
    "        elif self.units.lattice.D == 3:\n",
    "            x_lu, y_lu, z_lu = np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y- and z-index\n",
    "        else:\n",
    "            print(\"WARNING: something went wrong in LU-gird-index generation, lattice.D must be 2 or 3!\")\n",
    "\n",
    "        condition = np.sqrt((x_lu - self.x_pos) ** 2 + (y_lu - self.y_pos) ** 2) < self.radius\n",
    "        self.obstacle_mask[np.where(condition)] = 1\n",
    "        self.solid_mask[np.where(condition)] = 1\n",
    "\n",
    "        # indexing doesn't need z-Index for 3D, everything is broadcasted along z!\n",
    "        if self.lateral_walls == 'bounceback' or self.lateral_walls == 'slip':  # if top and bottom are link-based BC\n",
    "            self.wall_mask[:, [0, -1]] = True  # don't mark wall nodes as inlet\n",
    "            self.solid_mask[np.where(self.wall_mask)] = 1  # mark solid walls\n",
    "            self.in_mask[0, 1:-1] = True  # inlet on the left, except for top and bottom wall (y=0, y=y_max)\n",
    "        else:  # if lateral_wals == 'periodic', no walls\n",
    "            self.in_mask[0, :] = True  # inlet on the left (x=0)\n",
    "\n",
    "        # generate parabolic velocity profile for inlet BC if lateral_walls (top and bottom) are bounce back walls (== channel-flow)\n",
    "        self.u_inlet = self.units.characteristic_velocity_pu * self._unit_vector()  # u = [ux,uy,uz] = [1,0,0] in PU // uniform cahracteristic velocity in x-direction\n",
    "        if self.lateral_walls == 'bounceback':\n",
    "            ## parabolic velocity profile, zeroing on the edges\n",
    "            ## How to parabola:\n",
    "            ## 1.parabola in factoriezed form (GER: \"Nullstellenform\"): y = (x-x1)*(x-x2)\n",
    "            ## 2.parabola with a maximum and zero at x1=0 und x2=x0: y=-x*(x-x0)\n",
    "            ## 3.scale parabola, to make y_s(x_s)=1 the maximum: y=-x*(x-x0)*(1/(x0/2)¬≤)\n",
    "            ## (4. optional) scale amplitude with 1.5 to have a mean velocity of 1, also making the integral of a homogeneous velocity profile with u=1 and the parabolic profile being equal\n",
    "            (nx, ny, nz) = self.shape  # number of gridpoints in y direction\n",
    "            parabola_y = np.zeros((1, ny))\n",
    "            y_coordinates = np.linspace(0, ny,\n",
    "                                        ny)  # linspace() creates n points between 0 and ny, including 0 and ny:\n",
    "            # top and bottom velocity values will be zero to agree with wall-boundary-condition\n",
    "            parabola_y[:, 1:-1] = - 1.5 * np.array(self.u_inlet).max() * y_coordinates[1:-1] * (\n",
    "                        y_coordinates[1:-1] - ny) * 1 / (ny / 2) ** 2  # parabolic velocity profile\n",
    "            # scale with 1.5 to achieve a mean velocity of u_char! -> DIFFERENT FROM cylinder2D and cylinder3D (!)\n",
    "            if self.units.lattice.D == 2:\n",
    "                # in 2D u1 needs Dimension 1 x ny (!)\n",
    "                velocity_y = np.zeros_like(parabola_y)  # y-velocities = 0\n",
    "                self.u_inlet = np.stack([parabola_y, velocity_y], axis=0)  # stack/pack u-field\n",
    "            elif self.units.lattice.D == 3:\n",
    "                ones_z = np.ones(nz)\n",
    "                parabola_yz = parabola_y[:, :, np.newaxis] * ones_z\n",
    "                parabola_yz_zeros = np.zeros_like(parabola_yz)\n",
    "                # create u_xyz inlet yz-plane:\n",
    "                self.u_inlet = np.stack([parabola_yz, parabola_yz_zeros, parabola_yz_zeros], axis=0)  # stack/pack u-field\n",
    "\n",
    "    @property\n",
    "    def obstacle_mask(self):\n",
    "        return self._obstacle_mask\n",
    "\n",
    "    @obstacle_mask.setter\n",
    "    def obstacle_mask(self, m):\n",
    "        assert isinstance(m, np.ndarray) and m.shape == self.shape\n",
    "        self._obstacle_mask = m.astype(bool)\n",
    "        # self.solid_mask[np.where(self._obstacle_mask)] = 1  # (!) this line is not doing what it should! solid_mask is now defined in the initial solution (see below)!\n",
    "\n",
    "    def initial_solution(self, x):\n",
    "        p = np.zeros_like(x[0], dtype=float)[None, ...]\n",
    "        u_max_pu = self.units.characteristic_velocity_pu * self._unit_vector()\n",
    "        u_max_pu = append_axes(u_max_pu, self.units.lattice.D)\n",
    "        self.solid_mask[np.where(self.obstacle_mask)] = 1  # This line is needed, because the obstacle_mask.setter does not define the solid_mask properly (see above) #OLD\n",
    "        ### initial velocity field: \"u_init\"-parameter\n",
    "        # 0: uniform u=0\n",
    "        # 1: uniform u=1 or parabolic (depends on lateral_walls -> bounceback => parabolic; slip, periodic => uniform)\n",
    "        u = (1 - self.solid_mask) * u_max_pu\n",
    "        if self.u_init == 0:\n",
    "            u = u * 0  # uniform u=0\n",
    "        else:\n",
    "            if self.lateral_walls == 'bounceback':  # parabolic along y, uniform along x and z (similar to poiseuille-flow)\n",
    "                ny = self.shape[1]  # number of gridpoints in y direction\n",
    "                ux_factor = np.zeros(ny)  # vector for one column (u(x=0))\n",
    "                # multiply parabolic profile with every column of the velocity field:\n",
    "                y_coordinates = np.linspace(0, ny, ny)\n",
    "                ux_factor[1:-1] = - y_coordinates[1:-1] * (y_coordinates[1:-1] - ny) * 1 / (ny / 2) ** 2\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u = np.einsum('k,ijk->ijk', ux_factor, u)\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    u = np.einsum('k,ijkl->ijkl', ux_factor, u)\n",
    "            else:  # lateral_walls == periodic or slip\n",
    "                # initiale velocity u_PU=1 on every fluid node\n",
    "                u = (1 - self.solid_mask) * u_max_pu\n",
    "\n",
    "        ### perturb initial velocity field-symmetry (in y and z) to trigger 'von Karman' vortex street\n",
    "        if self.perturb_init:  # perturb initial solution in y\n",
    "            # overlays a sine-wave on the second column of nodes x_lu=1 (index 1)\n",
    "            ny = x[1].shape[1]\n",
    "            if u.max() < 0.5 * self.units.characteristic_velocity_pu:\n",
    "                # add perturbation for small velocities\n",
    "                #OLD 2D: u[0][1] += np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * self.units.characteristic_velocity_pu * 1.0\n",
    "                amplitude_y = np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * self.units.characteristic_velocity_pu * 0.1\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u[0][1] += amplitude_y\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    nz = x[2].shape[2]\n",
    "                    plane_yz = np.ones_like(u[0, 1])  # plane of ones\n",
    "                    u[0][1] = np.einsum('y,yz->yz', amplitude_y, plane_yz)  # plane of amplitude in y\n",
    "                    amplitude_z = np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * self.units.characteristic_velocity_pu * 0.1  # amplitude in z\n",
    "                   # print(\"amplitude y:\", amplitude_y.shape)\n",
    "                   # print(\"u[0][1]:\", u[0][1].shape)\n",
    "                   # print(\"amplitude z:\", amplitude_z.shape)\n",
    "                    # factor = 1 + np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * 0.3  # pertubation in z-direction\n",
    "                    u[0][1] += np.einsum('z,yz->yz', amplitude_z, plane_yz)\n",
    "            else:\n",
    "                # multiply scaled down perturbation if velocity field is already near u_char\n",
    "                #OLD 2D: u[0][1] *= 1 + np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * 0.3\n",
    "                factor = 1 + np.sin(np.linspace(0, ny, ny) / ny * 2 * np.pi) * 0.1\n",
    "                if self.units.lattice.D == 2:\n",
    "                    u[0][1] *= factor\n",
    "                elif self.units.lattice.D == 3:\n",
    "                    nz = x[2].shape[1]\n",
    "                    plane_yz = np.ones_like(u[0, 1, :, :])\n",
    "                    u[0][1] = np.einsum('y,yz->yz', factor, u[0][1])\n",
    "                    factor = 1 + np.sin(np.linspace(0, nz, nz) / nz * 2 * np.pi) * 0.1  # pertubation in z-direction\n",
    "                    u[0][1] = np.einsum('z,yz->yz', factor, u[0][1])\n",
    "        return p, u\n",
    "\n",
    "    @property\n",
    "    def grid(self):\n",
    "        # THIS IS NOT USED AT THE MOMENT. QUESTION: SHOULD THIS BE ONE- OR ZERO-BASED? Indexing or \"node-number\"?\n",
    "        xyz = tuple(self.units.convert_length_to_pu(np.linspace(0, n, n)) for n in self.shape)  # tuple of lists of x,y,(z)-values/indices\n",
    "        return np.meshgrid(*xyz, indexing='ij')  # meshgrid of x-, y- (und z-)values/indices\n",
    "\n",
    "    @property\n",
    "    def boundaries(self):\n",
    "        # inlet (\"left side\", x[0],y[1:-1], z[:])\n",
    "        inlet_boundary = EquilibriumBoundaryPU(\n",
    "            self.in_mask,\n",
    "            self.units.lattice, self.units,\n",
    "            # self.units.characteristic_velocity_pu * self._unit_vector())\n",
    "            self.u_inlet)  # works with a 1 x D vector or an ny x D vector thanks to einsum-magic in EquilibriumBoundaryPU\n",
    "\n",
    "        # lateral walls (\"top and bottom walls\", x[:], y[0,-1], z[:])\n",
    "        lateral_boundary = None  # stays None if lateral_walls == 'periodic'\n",
    "        if self.lateral_walls == 'bounceback':\n",
    "            if self.bc_type == 'hwbb' or self.bc_type == 'HWBB':  # use halfway bounce back\n",
    "                lateral_boundary = HalfwayBounceBackBoundary(self.wall_mask, self.units.lattice)\n",
    "            else:  # else use fullway bounce back\n",
    "                lateral_boundary = FullwayBounceBackBoundary(self.wall_mask, self.units.lattice)\n",
    "        elif self.lateral_walls == 'slip' or self.bc_type == 'SLIP':  # use slip-wal√∂l (symmetry boundary)\n",
    "            lateral_boundary = SlipBoundary(self.wall_mask, self.units.lattice, 1)  # slip on x(z)-plane\n",
    "\n",
    "        # outlet (\"right side\", x[-1],y[:], (z[:]))\n",
    "        if self.units.lattice.D == 2:\n",
    "            outlet_boundary = EquilibriumOutletP(self.units.lattice, [1, 0])  # outlet in positive x-direction\n",
    "        else: # self.units.lattice.D == 3:\n",
    "            outlet_boundary = EquilibriumOutletP(self.units.lattice, [1, 0, 0])  # outlet in positive x-direction\n",
    "\n",
    "        # obstacle (for example: obstacle \"cylinder\" with radius centered at position x_pos, y_pos) -> to be set via obstacle_mask.setter\n",
    "        obstacle_boundary = None\n",
    "        # (!) the obstacle_boundary should alway be the last boundary in the list of boundaries to correctly calculate forces on the obstacle\n",
    "        if self.bc_type == 'hwbb' or self.bc_type == 'HWBB':\n",
    "            obstacle_boundary = HalfwayBounceBackBoundary(self.obstacle_mask, self.units.lattice)\n",
    "        elif self.bc_type == 'ibb1' or self.bc_type == 'IBB1':\n",
    "            obstacle_boundary = InterpolatedBounceBackBoundary(self.obstacle_mask, self.units.lattice,\n",
    "                                                               x_center=(self.shape[1] / 2 - 0.5),\n",
    "                                                               y_center=(self.shape[1] / 2 - 0.5), radius=self.radius)\n",
    "        elif self.bc_type == 'ibb1c1':\n",
    "            obstacle_boundary = InterpolatedBounceBackBoundary_compact_v1(self.obstacle_mask, self.units.lattice,\n",
    "                                                               x_center=(self.shape[1] / 2 - 0.5),\n",
    "                                                               y_center=(self.shape[1] / 2 - 0.5), radius=self.radius)\n",
    "        elif self.bc_type == 'ibb1c2':\n",
    "            obstacle_boundary = InterpolatedBounceBackBoundary_compact_v2(self.obstacle_mask, self.units.lattice,\n",
    "                                                                          x_center=(self.shape[1] / 2 - 0.5),\n",
    "                                                                          y_center=(self.shape[1] / 2 - 0.5),\n",
    "                                                                          radius=self.radius)\n",
    "        elif self.bc_type == 'fwbbc':\n",
    "            obstacle_boundary = FullwayBounceBackBoundary_compact(self.obstacle_mask, self.units.lattice)\n",
    "        elif self.bc_type == 'hwbbc1':\n",
    "            obstacle_boundary = HalfwayBounceBackBoundary_compact_v1(self.obstacle_mask, self.units.lattice)\n",
    "        elif self.bc_type == 'hwbbc2':\n",
    "            obstacle_boundary = HalfwayBounceBackBoundary_compact_v2(self.obstacle_mask, self.units.lattice)\n",
    "        elif self.bc_type == 'hwbbc3':\n",
    "            obstacle_boundary = HalfwayBounceBackBoundary_compact_v3(self.obstacle_mask, self.units.lattice)\n",
    "        else:  # use Fullway Bounce Back\n",
    "            obstacle_boundary = FullwayBounceBackBoundary(self.obstacle_mask, self.units.lattice)\n",
    "\n",
    "        if lateral_boundary is None:  # if lateral boundary is periodic...don't return a boundary-object\n",
    "            return [\n",
    "                inlet_boundary,\n",
    "                outlet_boundary,\n",
    "                obstacle_boundary\n",
    "            ]\n",
    "        else:\n",
    "            return [\n",
    "                inlet_boundary,\n",
    "                outlet_boundary,\n",
    "                lateral_boundary,\n",
    "                obstacle_boundary\n",
    "            ]\n",
    "\n",
    "    def _unit_vector(self, i=0):\n",
    "        return np.eye(self.units.lattice.D)[i]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT 0 , i 1  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 0 0\n",
      "POINT 0 , i 2  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 0 0\n",
      "POINT 0 , i 3  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 1 0\n",
      "POINT 0 , i 4  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 -1 0\n",
      "POINT 0 , i 7  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 1 1\n",
      "POINT 0 , i 8  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 -1 -1\n",
      "POINT 0 , i 9  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 1 -1\n",
      "POINT 0 , i 10  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 0 -1 1\n",
      "POINT 0 , i 11  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 0 1\n",
      "POINT 0 , i 12  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 0 -1\n",
      "POINT 0 , i 13  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 0 -1\n",
      "POINT 0 , i 14  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 0 1\n",
      "POINT 0 , i 15  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 1 0\n",
      "POINT 0 , i 16  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 -1 0\n",
      "POINT 0 , i 17  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 -1 0\n",
      "POINT 0 , i 18  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 1 0\n",
      "POINT 0 , i 19  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 1 1\n",
      "POINT 0 , i 20  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 -1 -1\n",
      "POINT 0 , i 21  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 1 -1\n",
      "POINT 0 , i 22  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 -1 1\n",
      "POINT 0 , i 23  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 -1 1\n",
      "POINT 0 , i 24  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 1 -1\n",
      "POINT 0 , i 25  b1 [ 0  0 -1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 1 -1 -1\n",
      "POINT 0 , i 26  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 0 -1 1 1\n",
      "POINT 1 , i 1  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 0 0\n",
      "POINT 1 , i 2  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 0 0\n",
      "POINT 1 , i 3  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 0 1 0\n",
      "POINT 1 , i 4  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 0 -1 0\n",
      "POINT 1 , i 7  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 0 1 1\n",
      "POINT 1 , i 8  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 0 -1 -1\n",
      "POINT 1 , i 9  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 0 1 -1\n",
      "POINT 1 , i 10  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 0 -1 1\n",
      "POINT 1 , i 11  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 0 1\n",
      "POINT 1 , i 12  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 -1 0 -1\n",
      "POINT 1 , i 13  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 1 0 -1\n",
      "POINT 1 , i 14  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 0 1\n",
      "POINT 1 , i 15  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 1 0\n",
      "POINT 1 , i 16  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 -1 0\n",
      "POINT 1 , i 17  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 -1 0\n",
      "POINT 1 , i 18  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 1 0\n",
      "POINT 1 , i 19  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 1 1\n",
      "POINT 1 , i 20  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 -1 -1 -1\n",
      "POINT 1 , i 21  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 1 1 -1\n",
      "POINT 1 , i 22  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 -1 1\n",
      "POINT 1 , i 23  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 1 -1 1\n",
      "POINT 1 , i 24  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 -1 1 -1\n",
      "POINT 1 , i 25  b1 [0 0 0] ; b2 [ 0  0 -1] for boundaryPoint x,y,z,ci 2 2 1 1 -1 -1\n",
      "POINT 1 , i 26  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 1 -1 1 1\n",
      "POINT 2 , i 1  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 0 0\n",
      "POINT 2 , i 2  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 0 0\n",
      "POINT 2 , i 3  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 1 0\n",
      "POINT 2 , i 4  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 -1 0\n",
      "POINT 2 , i 7  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 1 1\n",
      "POINT 2 , i 8  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 -1 -1\n",
      "POINT 2 , i 9  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 1 -1\n",
      "POINT 2 , i 10  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 0 -1 1\n",
      "POINT 2 , i 11  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 0 1\n",
      "POINT 2 , i 12  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 0 -1\n",
      "POINT 2 , i 13  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 0 -1\n",
      "POINT 2 , i 14  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 0 1\n",
      "POINT 2 , i 15  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 1 0\n",
      "POINT 2 , i 16  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 -1 0\n",
      "POINT 2 , i 17  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 -1 0\n",
      "POINT 2 , i 18  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 1 0\n",
      "POINT 2 , i 19  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 1 1\n",
      "POINT 2 , i 20  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 -1 -1\n",
      "POINT 2 , i 21  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 1 -1\n",
      "POINT 2 , i 22  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 -1 1\n",
      "POINT 2 , i 23  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 -1 1\n",
      "POINT 2 , i 24  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 1 -1\n",
      "POINT 2 , i 25  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 1 -1 -1\n",
      "POINT 2 , i 26  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 2 -1 1 1\n",
      "POINT 3 , i 1  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 0 0\n",
      "POINT 3 , i 2  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 0 0\n",
      "POINT 3 , i 3  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 0 1 0\n",
      "POINT 3 , i 4  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 0 -1 0\n",
      "POINT 3 , i 7  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 0 1 1\n",
      "POINT 3 , i 8  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 0 -1 -1\n",
      "POINT 3 , i 9  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 0 1 -1\n",
      "POINT 3 , i 10  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 0 -1 1\n",
      "POINT 3 , i 11  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 1 0 1\n",
      "POINT 3 , i 12  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 0 -1\n",
      "POINT 3 , i 13  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 0 -1\n",
      "POINT 3 , i 14  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 -1 0 1\n",
      "POINT 3 , i 15  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 1 0\n",
      "POINT 3 , i 16  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 -1 0\n",
      "POINT 3 , i 17  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 -1 0\n",
      "POINT 3 , i 18  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 1 0\n",
      "POINT 3 , i 19  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 1 1 1\n",
      "POINT 3 , i 20  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 -1 -1\n",
      "POINT 3 , i 21  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 1 -1\n",
      "POINT 3 , i 22  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 -1 -1 1\n",
      "POINT 3 , i 23  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 1 -1 1\n",
      "POINT 3 , i 24  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 -1 1 -1\n",
      "POINT 3 , i 25  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 3 1 -1 -1\n",
      "POINT 3 , i 26  b1 [0 0 0] ; b2 [0 0 1] for boundaryPoint x,y,z,ci 2 2 3 -1 1 1\n",
      "POINT 4 , i 1  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 0 0\n",
      "POINT 4 , i 2  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 0 0\n",
      "POINT 4 , i 3  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 1 0\n",
      "POINT 4 , i 4  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 -1 0\n",
      "POINT 4 , i 7  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 1 1\n",
      "POINT 4 , i 8  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 -1 -1\n",
      "POINT 4 , i 9  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 1 -1\n",
      "POINT 4 , i 10  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 0 -1 1\n",
      "POINT 4 , i 11  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 0 1\n",
      "POINT 4 , i 12  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 0 -1\n",
      "POINT 4 , i 13  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 0 -1\n",
      "POINT 4 , i 14  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 0 1\n",
      "POINT 4 , i 15  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 1 0\n",
      "POINT 4 , i 16  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 -1 0\n",
      "POINT 4 , i 17  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 -1 0\n",
      "POINT 4 , i 18  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 1 0\n",
      "POINT 4 , i 19  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 1 1\n",
      "POINT 4 , i 20  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 -1 -1\n",
      "POINT 4 , i 21  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 1 -1\n",
      "POINT 4 , i 22  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 -1 1\n",
      "POINT 4 , i 23  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 -1 1\n",
      "POINT 4 , i 24  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 1 -1\n",
      "POINT 4 , i 25  b1 [0 0 0] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 1 -1 -1\n",
      "POINT 4 , i 26  b1 [0 0 1] ; b2 [0 0 0] for boundaryPoint x,y,z,ci 2 2 4 -1 1 1\n",
      "IBB initialization took 0.014454841613769531seconds\n"
     ]
    }
   ],
   "source": [
    "### SIMULATOR SETUP\n",
    "\n",
    "# stencil\n",
    "if stencil_choice == \"D3Q15\":\n",
    "    stencil=lt.D3Q15\n",
    "elif stencil_choice == \"D3Q19\":\n",
    "    stencil=lt.D3Q19\n",
    "else: # stencil_choice==\"D3Q27\"\n",
    "    stencil=lt.D3Q27\n",
    "\n",
    "# lattice\n",
    "# lattice = lt.Lattice(lt.D2Q9, \"cuda:0\", dtype=torch.float64, native=False)  # for \"new lettuce\"\n",
    "lattice = lt.Lattice(stencil, \"cpu\", dtype=torch.float64)  #for \"old lettuce\"\n",
    "    # stencil, device, dtype\n",
    "\n",
    "# flow = ObstacleMax3D(reynolds_number=re, mach_number=Ma,\n",
    "#                    lattice=lattice,\n",
    "#                    char_length_pu=setup_diameter,\n",
    "#                    char_length_lu=gridpoints_per_diameter,\n",
    "#                    char_velocity_pu=flow_velocity,\n",
    "#                    x_lu=domain_length_in_D*gridpoints_per_diameter,\n",
    "#                    y_lu=domain_height_in_D*gridpoints_per_diameter,\n",
    "#                    z_lu=domain_width_in_D*gridpoints_per_diameter,\n",
    "#                    lateral_walls=lateral_walls,\n",
    "#                    bb_type=bb_type,\n",
    "#                    perturb_init=perturb_init,\n",
    "#                    u_init=u_init\n",
    "#                   )\n",
    "flow = ObstacleCylinder(shape=(domain_length_in_D*gridpoints_per_diameter,\n",
    "                               domain_height_in_D*gridpoints_per_diameter,\n",
    "                               domain_width_in_D*gridpoints_per_diameter),\n",
    "                        reynolds_number=re, mach_number=Ma,\n",
    "                        lattice=lattice,\n",
    "                        char_length_pu=setup_diameter,\n",
    "                        char_length_lu=gridpoints_per_diameter,\n",
    "                        char_velocity_pu=flow_velocity,\n",
    "                        lateral_walls=lateral_walls,\n",
    "                        bc_type=bc_type,\n",
    "                        perturb_init=perturb_init,\n",
    "                        u_init=u_init\n",
    "                        )\n",
    "\n",
    "# # define a Cylinder-Obstacle\n",
    "# radius_LU = 0.5 * gridpoints_per_diameter\n",
    "# y_pos_LU = 0.5 * gridpoints_per_diameter * domain_height_in_D + 0.5\n",
    "# x_pos_LU = y_pos_LU\n",
    "#\n",
    "# index_list = tuple(np.linspace(1,n,n) for n in flow.shape)  # Tupel index lists (1-n (non zero-based!))\n",
    "# xLU, yLU, zLU = np.meshgrid(*index_list, indexing='ij')  # meshgrid of x-, y- (and z-)indizes/indexs?/indexes?! - this is simulation, not grammar...\n",
    "#\n",
    "# condition = np.sqrt((xLU - x_pos_LU) ** 2 + (yLU - y_pos_LU) ** 2) < radius_LU\n",
    "# flow.obstacle_mask[np.where(condition)] = 1\n",
    "\n",
    "### simulation object (simulator)\n",
    "tau = flow.units.relaxation_parameter_lu  # relaxation parameter\n",
    "re_g = flow.units.characteristic_velocity_lu/(lattice.stencil.cs**2 * (tau-0.5))  # grid reynolds number (should be O(10))\n",
    "\n",
    "# collision\n",
    "if collision_choice == \"reg\":\n",
    "    collision=lt.RegularizedCollision(lattice, tau)\n",
    "elif collision_choice == \"kbc\":\n",
    "    collision=lt.KBCCollision3D(lattice,tau)\n",
    "else: # collision_choice = \"bgk\":\n",
    "    collision=lt.BGKCollision(lattice, tau)\n",
    "\n",
    "# simulation\n",
    "sim = Simulation(flow, lattice,\n",
    "                    collision,\n",
    "                    # lt.BGKCollision(lattice, tau),\n",
    "                    # lt.RegularizedCollision(lattice, tau),\n",
    "                    # lt.KBCCollision2D(lattice,tau),\n",
    "                    lt.StandardStreaming(lattice)\n",
    "                   )\n",
    "    # Flow, Lattice-Parameter, CollisionOperator-Object(Parameter), Streaming-Object\n",
    "\n",
    "### Reporter\n",
    "\n",
    "# VTK Reporter -> Visualization\n",
    "if output_vtk:\n",
    "    VTKreport = lt.VTKReporter(lattice, flow, interval=int(flow.units.convert_time_to_lu(1/vtk_fps)), filename_base=vtk_path,\n",
    "                               solid_mask=flow.solid_mask  # pin observables inside the obstacle-mask to ZERO for visualization\n",
    "                               )\n",
    "    sim.reporters.append(VTKreport)\n",
    "    # export obstacle\n",
    "    mask_dict = dict()\n",
    "    mask_dict[\"mask\"] = flow.obstacle_mask.astype(int)\n",
    "    imageToVTK(\n",
    "        path=output_path+dir_name+\"/vtk/obstacle_point\",\n",
    "        pointData=mask_dict\n",
    "    )\n",
    "    imageToVTK(\n",
    "        path=output_path+dir_name+\"/vtk/obstacle_cell\",\n",
    "        cellData=mask_dict\n",
    "    )\n",
    "\n",
    "# Observable reporter: drag coefficient\n",
    "DragObservable = lt.DragCoefficient(lattice,flow,sim._boundaries[-1],area=setup_diameter*flow.units.convert_length_to_pu(gridpoints_per_diameter*domain_width_in_D))  # ! area A=2*r is in PU and 1-dimensional in 2D\n",
    "Dragreport = lt.ObservableReporter(DragObservable, out=None)\n",
    "sim.reporters.append(Dragreport)\n",
    "\n",
    "# Observable reporter: lift coefficient\n",
    "LiftObservable = lt.LiftCoefficient(lattice,flow,sim._boundaries[-1],area=setup_diameter*flow.units.convert_length_to_pu(gridpoints_per_diameter*domain_width_in_D))\n",
    "Liftreport = lt.ObservableReporter(LiftObservable, out=None)\n",
    "sim.reporters.append(Liftreport)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# AverageVelocity Reporter:\n",
    "if calculate_velocity_profile:\n",
    "    # define positions\n",
    "    position_1 = flow.x_pos-0.5 + 1.06 * flow.radius * 2  #int(round(flow.x_pos + 1.06 * flow.radius * 2 , 0))\n",
    "    position_2 = flow.x_pos-0.5 + 1.54 * flow.radius * 2  #int(round(flow.x_pos + 1.54 * flow.radius * 2 , 0))\n",
    "    position_3 = flow.x_pos-0.5 + 2.02 * flow.radius * 2  #int(round(flow.x_pos + 2.02 * flow.radius * 2 , 0))\n",
    "    print(\"V_avg positions:\" + \" p1: \" + str(position_1) + \" p2:  \" + str(position_2) + \" p3:  \" + str(position_3))\n",
    "\n",
    "    # create and append AvgVelocity-reporter\n",
    "    AvgVelocity1 = lt.AverageVelocityReporter(lattice,flow, position_1)\n",
    "    sim.reporters.append(AvgVelocity1)\n",
    "    AvgVelocity2 = lt.AverageVelocityReporter(lattice,flow, position_2)\n",
    "    sim.reporters.append(AvgVelocity2)\n",
    "    AvgVelocity3 = lt.AverageVelocityReporter(lattice,flow, position_3)\n",
    "    sim.reporters.append(AvgVelocity3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# NaNReporter: stop if NaN is detected (default interval is 100 steps)\n",
    "NaNReporter = lt.NaNReporter(flow, lattice, n_steps, T_target)  # default interval of 100\n",
    "sim.reporters.append(NaNReporter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# show domain slice\n",
    "#plt.imshow(sim._boundaries[-1].mask[:,:,0].T, origin=\"lower\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fd7622905e0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show pertubation in x=1 slice\n",
    "plt.imshow(lattice.convert_to_numpy(lattice.u(sim.f))[0,1,:,:], origin=\"lower\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.999999999999\n"
     ]
    }
   ],
   "source": [
    "### grid reynolds number\n",
    "print(re_g)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "### export parameters\n",
    "\n",
    "if output_data:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_parameters.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \"+timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-Parameters   ###\")\n",
    "    output_file.write(\"\\nRe = \"+str(re))\n",
    "    output_file.write(\"\\nn_steps = \"+str(n_steps))\n",
    "    output_file.write(\"\\nT_target = \"+str(flow.units.convert_time_to_pu(n_steps))+\" seconds\")\n",
    "    output_file.write(\"\\ngridpoints_per_diameter (gpd) = \"+str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \"+str(gpd_setup)+\" to \"+str(gridpoints_per_diameter)+\" because D/Y is even\")\n",
    "    output_file.write(\"\\nDpX (D/X) = \" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\nDpY (D/Y) = \"+str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\nDpZ (D/Z) = \"+str(domain_width_in_D))\n",
    "    output_file.write(\"\\nshape_LU: \"+ str(flow.shape))\n",
    "    output_file.write((\"\\ntotal_number_of_gridpoints: \"+str(lattice.rho(sim.f).numel())))\n",
    "    output_file.write(\"\\nbc_type = \"+str(bc_type))\n",
    "    output_file.write(\"\\nlateral_walls = \"+str(lateral_walls))\n",
    "    output_file.write(\"\\nstencil = \"+str(stencil_choice))\n",
    "    output_file.write(\"\\ncollision = \" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nMa = \" + str(Ma))\n",
    "    output_file.write(\"\\ntau = \" + str(tau))\n",
    "    output_file.write(\"\\ngrid_reynolds_number (Re_g) = \" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nsetup_diameter_PU = \" + str(setup_diameter))\n",
    "    output_file.write(\"\\nflow_velocity_PU = \" + str(flow_velocity))\n",
    "    output_file.write(\"\\nu_init = \" + str(u_init))\n",
    "    output_file.write(\"\\nperturb_init = \" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\noutput_vtk = \" + str(output_vtk))\n",
    "    output_file.write(\"\\nvtk_fps = \" + str(vtk_fps))\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPD = 1\n",
      "area_rel: 1.2732395447351628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbille/lettuce/lettuce/max.py:69: RuntimeWarning: invalid value encountered in divide\n",
      "  radii_relative = radii / (\n",
      "/home/mbille/lettuce/lettuce/max.py:71: RuntimeWarning: invalid value encountered in divide\n",
      "  radii_q_relative = radii_q / (radius_LU - 0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lettuce.max import draw_circular_mask\n",
    "if output_data:\n",
    "    draw_circular_mask(lattice, gridpoints_per_diameter, output_data=output_data, filebase=output_path+dir_name, print_data=True)\n",
    "else:\n",
    "    draw_circular_mask(lattice, gridpoints_per_diameter, output_data=output_data, print_data=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SIMULATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for dimension 3 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m### simple simulation\u001B[39;00m\n\u001B[1;32m      3\u001B[0m t_start\u001B[38;5;241m=\u001B[39mtime\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 5\u001B[0m mlups \u001B[38;5;241m=\u001B[39m \u001B[43msim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#simulation\u001B[39;00m\n\u001B[1;32m      7\u001B[0m t_end\u001B[38;5;241m=\u001B[39mtime\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      8\u001B[0m runtime\u001B[38;5;241m=\u001B[39mt_end\u001B[38;5;241m-\u001B[39mt_start\n",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36mSimulation.step\u001B[0;34m(self, num_steps)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m### BOUNDARY\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# apply boundary conditions\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m boundary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_boundaries:\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mboundary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# count step\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mi \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mInterpolatedBounceBackBoundary_compact_v1.__call__\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m    324\u001B[0m     f[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopposite_tensor[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:, \u001B[38;5;241m0\u001B[39m]],\n\u001B[1;32m    325\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:, \u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    326\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:, \u001B[38;5;241m2\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_gt\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_gt\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_collided\u001B[38;5;241m.\u001B[39mto_dense()[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:, \u001B[38;5;241m0\u001B[39m],  \u001B[38;5;66;03m# f_c\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    333\u001B[0m                                                                             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:,\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    334\u001B[0m                                                                             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_gt[:,\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlattice\u001B[38;5;241m.\u001B[39mD \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m    337\u001B[0m     \u001B[38;5;66;03m# if d <= 0.5\u001B[39;00m\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# f[self.opposite_tensor[self.f_index_fluid1_lt[:, 0]],\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;66;03m#                                                        self.f_index_fluid1_lt[:, 3]]\u001B[39;00m\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;66;03m#INTER2\u001B[39;00m\n\u001B[1;32m    350\u001B[0m     f[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopposite_tensor[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m0\u001B[39m]],\n\u001B[1;32m    351\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    352\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m2\u001B[39m],\n\u001B[1;32m    353\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m3\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_collided_lt[:, \u001B[38;5;241m0\u001B[39m]\\\n\u001B[1;32m    354\u001B[0m                                       \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt) \u001B[38;5;241m*\u001B[39m f[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m0\u001B[39m],  \u001B[38;5;66;03m# f_c-1 (ginge auch mit fc.tpo_dense()[f_index2]\u001B[39;00m\n\u001B[1;32m    355\u001B[0m                                                                               \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    356\u001B[0m                                                                               \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m2\u001B[39m],\n\u001B[1;32m    357\u001B[0m                                                                               \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_index_fluid1_lt[:, \u001B[38;5;241m3\u001B[39m]] \\\n\u001B[0;32m--> 358\u001B[0m                                       \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_lt) \u001B[38;5;241m*\u001B[39m \u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_index_fluid2_lt\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# f_c-2\u001B[39;49;00m\n\u001B[1;32m    359\u001B[0m \u001B[43m                                                                              \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_index_fluid2_lt\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m                                                                              \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_index_fluid2_lt\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m                                                                              \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf_index_fluid2_lt\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minter1< done\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;66;03m# if d > 0.5\u001B[39;00m\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;66;03m# f[self.opposite_tensor[self.f_index_fluid1_gt[:, 0]],\u001B[39;00m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;66;03m#   self.f_index_fluid1_gt[:, 1],\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;66;03m#                                          self.f_index_fluid1_gt[:, 3]]\u001B[39;00m\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m#INTER2\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: index 6 is out of bounds for dimension 3 with size 5"
     ]
    }
   ],
   "source": [
    "### simple simulation\n",
    "\n",
    "t_start=time.time()\n",
    "\n",
    "mlups = sim.step(n_steps) #simulation\n",
    "\n",
    "t_end=time.time()\n",
    "runtime=t_end-t_start\n",
    "print(\"MLUPS:\", mlups)\n",
    "print(\"PU-Time: \",flow.units.convert_time_to_pu(n_steps),\" seconds\")\n",
    "print(\"number of steps:\",n_steps)\n",
    "print(\"runtime: \",runtime, \"seconds (\", round(runtime/60,2),\"minutes )\")\n",
    "\n",
    "c_time = sim.time_avg[\"time_collision\"]\n",
    "fc_time = sim.time_avg[\"time_store_f_collided\"]\n",
    "s_time = sim.time_avg[\"time_streaming\"]\n",
    "b_time = sim.time_avg[\"time_boundary\"]\n",
    "r_time = sim.time_avg[\"time_reporter\"]\n",
    "sum_time = sim.time_avg[\"time_collision\"] + sim.time_avg[\"time_store_f_collided\"] + sim.time_avg[\"time_streaming\"] + sim.time_avg[\"time_boundary\"] + sim.time_avg[\"time_reporter\"]\n",
    "\n",
    "print(\"collision avg. time:\", sim.time_avg[\"time_collision\"], \"seconds (\" + str(round(100 * c_time/sum_time, 2)) + \" %)\")\n",
    "print(\"f_c_store avg. time:\", sim.time_avg[\"time_store_f_collided\"], \"seconds (\" + str(round(100 * fc_time/sum_time, 2)) + \" %)\")\n",
    "print(\"streaming avg. time:\", sim.time_avg[\"time_streaming\"], \"seconds (\" + str(round(100 * s_time/sum_time, 2)) + \" %)\")\n",
    "print(\"boundary avg. time:\", sim.time_avg[\"time_boundary\"], \"seconds (\" + str(round(100 * b_time/sum_time, 2)) + \" %)\")\n",
    "print(\"reporter avg. time:\", sim.time_avg[\"time_reporter\"], \"seconds (\" + str(round(100 * r_time/sum_time, 2)) + \" %)\")\n",
    "\n",
    "print(\"current GPU VRAM (MB): \", torch.cuda.memory_allocated(device=\"cuda:0\")/1024/1024)\n",
    "print(\"max. GPU VRAM (MB): \", torch.cuda.max_memory_allocated(device=\"cuda:0\")/1024/1024)\n",
    "\n",
    "[cpuLoad1,cpuLoad5,cpuLoad15] = [x / psutil.cpu_count() * 100 for x in psutil.getloadavg()]\n",
    "print(\"CPU % avg. over last 1 min, 5 min, 15 min; \", round(cpuLoad1,2), round(cpuLoad5,2), round(cpuLoad15,2))\n",
    "\n",
    "ram = psutil.virtual_memory()\n",
    "print(\"current total RAM usage [MB]: \" + str(round(ram.used/(1024*1024),2)) + \" of \" + str(round(ram.total/(1024*1024),2)) + \" MB\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim._boundaries[-1].f_index_fluid2_gt[:,3].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### export stats\n",
    "if output_data:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_stats.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \"+timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-STATS  ###\")\n",
    "    output_file.write(\"\\nruntime = \"+str(runtime)+ \" seconds (=\"+str(runtime/60)+\" minutes)\")\n",
    "    output_file.write(\"\\nMLUPS = \"+str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\navg. Collision-Time [s] = \" + str(c_time) + \" (\" + str(round(100 * c_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. store_fcl-Time [s] = \" + str(fc_time) + \" (\" + str(round(100 * fc_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Streaming-Time [s] = \" + str(s_time) + \" (\" + str(round(100 * s_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Boundary-Time  [s] = \" + str(b_time) + \" (\" + str(round(100 * b_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Reporter-Time  [s] = \" + str(r_time) + \" (\" + str(round(100 * r_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nVRAM_current [MB] = \" + str(torch.cuda.memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\nVRAM_peak [MB] = \" + str(torch.cuda.max_memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nCPU load % avg. over last 1, 5, 15 min: \" + str(round(cpuLoad1, 2)) + \" %, \" + str(round(cpuLoad5, 2)) + \" %, \" + str(round(cpuLoad15, 2)) + \" %\")\n",
    "    output_file.write(\"\\ntotal current RAM usage [MB]: \" + str(round(ram.used/(1024*1024),2)) + \" of \" + str(round(ram.total/(1024*1024),2)) + \" MB\")\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Output Clock\n",
    "#\n",
    "# print(\"Clock:\")\n",
    "# print(np.array(Clock.out))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# p1_LS1993 = np.genfromtxt('/home/mbille/lettuce/myTest/DiIlio_Fig09_data/Fig09_ux_profile_pos1_LS1993.csv', delimiter=';')\n",
    "# plt.plot(p1_LS1993[:,0], p1_LS1993[:,1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Avg Velocity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot AvgVelocity (ist per Reporter schon in PU, normalisierung mit u_char nicht n√∂tig, da u_char = 1 in PU)\n",
    "\n",
    "if calculate_velocity_profile:\n",
    "    avg_u_start = 0.5\n",
    "\n",
    "    # import reference data: (data is: first collumn Y/D, second column u_d/u_char)\n",
    "    # ux\n",
    "    p1_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_LS1993.csv', delimiter=';')\n",
    "    p2_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p3_LS1993_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_LS1993.csv', delimiter=';')\n",
    "\n",
    "    p1_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p2_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p3_KM2000_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_KM2000.csv', delimiter=';')\n",
    "\n",
    "    p1_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_WR2008.csv', delimiter=';')\n",
    "    p2_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_WR2008.csv', delimiter=';')\n",
    "    p3_WR2008_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_WR2008.csv', delimiter=';')\n",
    "\n",
    "    p1_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p2_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p3_DI2018_ux = np.genfromtxt(diIlio_path + 'Fig09_ux_profile_pos3_DI2018.csv', delimiter=';')\n",
    "\n",
    "    # uy\n",
    "    p1_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_LS1993.csv', delimiter=';')\n",
    "    p2_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p3_LS1993_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_LS1993.csv', delimiter=';')\n",
    "\n",
    "    p1_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p2_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p3_KM2000_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_KM2000.csv', delimiter=';')\n",
    "\n",
    "    p1_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_WR2008.csv', delimiter=';')\n",
    "    p2_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_WR2008.csv', delimiter=';')\n",
    "    p3_WR2008_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_WR2008.csv', delimiter=';')\n",
    "\n",
    "    p1_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p2_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p3_DI2018_uy = np.genfromtxt(diIlio_path + 'Fig10_uy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "\n",
    "    # uxux\n",
    "    p1_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_KM2000.csv', delimiter=';')\n",
    "    p1_R2016_uxux  = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_KM2000.csv', delimiter=';')\n",
    "    p2_LS1993_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uxux  = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_DI2018_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_KM2000_uxux = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_KM2000.csv', delimiter=';')\n",
    "    p3_R2016_uxux  = np.genfromtxt(diIlio_path + 'Fig11_uxux_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # uyuy\n",
    "    p1_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_LS1993_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_DI2018_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_R2016_uyuy = np.genfromtxt(diIlio_path + 'Fig12_uyuy_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # uxuy\n",
    "    p1_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_BM1994.csv', delimiter=';')\n",
    "    p1_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_DI2018.csv', delimiter=';')\n",
    "    p1_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos1_R2016.csv', delimiter=';')\n",
    "    p2_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_BM1994.csv', delimiter=';')\n",
    "    p2_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_DI2018.csv', delimiter=';')\n",
    "    p2_LS1993_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_LS1993.csv', delimiter=';')\n",
    "    p2_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos2_R2016.csv', delimiter=';')\n",
    "    p3_BM1994_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_BM1994.csv', delimiter=';')\n",
    "    p3_DI2018_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_DI2018.csv', delimiter=';')\n",
    "    p3_R2016_uxuy = np.genfromtxt(diIlio_path + 'Fig13_uxuy_profile_pos3_R2016.csv', delimiter=';')\n",
    "\n",
    "    # output sim data to files (not averaged over time)\n",
    "    if output_data and output_velocity_profile:\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_1_timeseries.npy\", np.array(AvgVelocity1.out))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_2_timeseries.npy\", np.array(AvgVelocity2.out))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_3_timeseries.npy\", np.array(AvgVelocity3.out))\n",
    "\n",
    "    u1 = np.array(AvgVelocity1.out)[int(avg_u_start*np.array(AvgVelocity1.out).shape[0]-1):]\n",
    "    u2 = np.array(AvgVelocity2.out)[int(avg_u_start*np.array(AvgVelocity2.out).shape[0]-1):]\n",
    "    u3 = np.array(AvgVelocity3.out)[int(avg_u_start*np.array(AvgVelocity3.out).shape[0]-1):]\n",
    "\n",
    "    avg_u1 = np.mean(u1, axis=0)  # time average\n",
    "    avg_u2 = np.mean(u2, axis=0)  # time average\n",
    "    avg_u3 = np.mean(u3, axis=0)  # time average\n",
    "\n",
    "    if output_data:  # output (time-mean) velocity profiles\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_1_t-avg.npy\", avg_u1)\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_2_t-avg.npy\", avg_u2)\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_3_t-avg.npy\", avg_u3)\n",
    "\n",
    "    avg_u1_x = avg_u1[0]  # u_x component over y at pos 1\n",
    "    avg_u2_x = avg_u2[0]  # u_x component over y at pos 2\n",
    "    avg_u3_x = avg_u3[0]  # u_x component over y at pos 3\n",
    "\n",
    "    avg_u1_y = avg_u1[1]  # u_y component over y at pos 1\n",
    "    avg_u2_y = avg_u2[1]  # u_y component over y at pos 2\n",
    "    avg_u3_y = avg_u3[1]  # u_y component over y at pos 3\n",
    "\n",
    "    y_in_D = (np.arange(avg_u1_x.shape[0])+1-flow.y_pos)/flow.units.characteristic_length_lu  # y/D for figure\n",
    "    if output_data:\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_YinD.npy\", y_in_D)\n",
    "    cm=1/2.54\n",
    "    # PLOT ux\n",
    "    fig, (ax_ux, ax_uy) = plt.subplots(1,2, constrained_layout=True, figsize=(30*cm,10*cm))\n",
    "    ax_ux.plot(y_in_D,avg_u1_x, y_in_D, avg_u2_x, y_in_D, avg_u3_x)\n",
    "    ax_ux.set_xlabel(\"y/D\")\n",
    "    ax_ux.set_ylabel(r\"$\\bar{u}_{x}$/$u_{char}$\")\n",
    "    ax_ux.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    # OPT. TO DO: add secondary axis for LU-grid\n",
    "    # ...needs 'function' to convert from y/D in LU and LU in y/D\n",
    "\n",
    "    # OPT. TO DO: make folder for AvgVelocity-stuff\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_x.png\")\n",
    "    # plt.show()\n",
    "\n",
    "    # PLOT uy\n",
    "    #fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_uy.plot(y_in_D,avg_u1_y, y_in_D, avg_u2_y, y_in_D, avg_u3_y)\n",
    "    ax_uy.set_xlabel(\"y/D\")\n",
    "    ax_uy.set_ylabel(r\"$\\bar{u}_{y}$/$u_{char}$\")\n",
    "    ax_uy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    # OPT. TO DO: add secondary axis for LU-grid\n",
    "    # ...needs 'function' to convert from y/D in LU and LU in y/D\n",
    "    # OPT. TO DO: make folder for AvgVelocity-stuff\n",
    "    # !!! QUESTION: is x/D the position measured FROM the cylinder (x_pos), or measured from x=0 ?\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_velocity_noReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # PLOT ux against references\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D,avg_u1_x, y_in_D, avg_u2_x-1, y_in_D, avg_u3_x-2)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p1_LS1993_ux[:,0], p1_LS1993_ux[:,1], p2_LS1993_ux[:,0], p2_LS1993_ux[:,1], p3_LS1993_ux[:,0], p3_LS1993_ux[:,1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_ux[:,0], p1_KM2000_ux[:,1], p2_KM2000_ux[:,0], p2_KM2000_ux[:,1], p3_KM2000_ux[:,0], p3_KM2000_ux[:,1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_WR = ax.plot(p1_WR2008_ux[:,0], p1_WR2008_ux[:,1], p2_WR2008_ux[:,0], p2_WR2008_ux[:,1], p3_WR2008_ux[:,0], p3_WR2008_ux[:,1])\n",
    "    plt.setp(ref_WR, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Wissink & Rodi (2008)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_ux[:,0], p1_DI2018_ux[:,1], p2_DI2018_ux[:,0], p2_DI2018_ux[:,1], p3_DI2018_ux[:,0], p3_DI2018_ux[:,1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\bar{u}_{x}$/$u_{char}$\")\n",
    "    ax.set_ylim([-2.5,+2])\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_KM[0], ref_WR[0], ref_DI[0]], loc= 'best')\n",
    "   # ax_ux.text(-3, 1.5, \"x/D = 1.06\", fontstile='italic')\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_ux_withReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # PLOT uy against references\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D,avg_u1_y, y_in_D, avg_u2_y-1, y_in_D, avg_u3_y-2)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p1_LS1993_uy[:,0], p1_LS1993_uy[:,1], p2_LS1993_uy[:,0], p2_LS1993_uy[:,1], p3_LS1993_uy[:,0], p3_LS1993_uy[:,1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_uy[:,0], p1_KM2000_uy[:,1], p2_KM2000_uy[:,0], p2_KM2000_uy[:,1], p3_KM2000_uy[:,0], p3_KM2000_uy[:,1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_WR = ax.plot(p1_WR2008_uy[:,0], p1_WR2008_uy[:,1], p2_WR2008_uy[:,0], p2_WR2008_uy[:,1], p3_WR2008_uy[:,0], p3_WR2008_uy[:,1])\n",
    "    plt.setp(ref_WR, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Wissink & Rodi (2008)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uy[:,0], p1_DI2018_uy[:,1], p2_DI2018_uy[:,0], p2_DI2018_uy[:,1], p3_DI2018_uy[:,0], p3_DI2018_uy[:,1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\bar{u}_{y}$/$u_{char}$\")\n",
    "    ax.set_ylim([-2.5,+1.5])\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_KM[0], ref_WR[0], ref_DI[0]], loc= 'best')\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_uy_withReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    ## turbulent Reynolds stresses\n",
    "\n",
    "    # diff between timeseries and time_average -> u'\n",
    "    u1_diff = u1-avg_u1\n",
    "    u2_diff = u2-avg_u2\n",
    "    u3_diff = u3-avg_u3\n",
    "\n",
    "    # square of diff -> u'^2\n",
    "    u1_diff_sq = u1_diff**2\n",
    "    u2_diff_sq = u2_diff**2\n",
    "    u3_diff_sq = u3_diff**2\n",
    "\n",
    "    # ux'*uy'\n",
    "    u1_diff_xy = u1_diff[:, 0, :]*u1_diff[:, 1, :]\n",
    "    u2_diff_xy = u2_diff[:, 0, :]*u2_diff[:, 1, :]\n",
    "    u3_diff_xy = u3_diff[:, 0, :]*u3_diff[:, 1, :]\n",
    "\n",
    "    # time_average of u'¬≤ and ux'uy'\n",
    "    u1_diff_sq_mean = np.mean(u1_diff_sq, axis=0)  # time average\n",
    "    u2_diff_sq_mean = np.mean(u2_diff_sq, axis=0)  # time average\n",
    "    u3_diff_sq_mean = np.mean(u3_diff_sq, axis=0)  # time average\n",
    "    u1_diff_xy_mean = np.mean(u1_diff_xy, axis=0)  # time average\n",
    "    u2_diff_xy_mean = np.mean(u2_diff_xy, axis=0)  # time average\n",
    "    u3_diff_xy_mean = np.mean(u3_diff_xy, axis=0)  # time average\n",
    "\n",
    "    if output_data:  # save reynolds stresses\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_1_ReStress_x.npy\", np.array([y_in_D, u1_diff_sq_mean[0]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_2_ReStress_x.npy\", np.array([y_in_D, u2_diff_sq_mean[0]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_3_ReStress_x.npy\", np.array([y_in_D, u3_diff_sq_mean[0]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_1_ReStress_y.npy\", np.array([y_in_D, u1_diff_sq_mean[1]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_2_ReStress_y.npy\", np.array([y_in_D, u2_diff_sq_mean[1]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_3_ReStress_y.npy\", np.array([y_in_D, u3_diff_sq_mean[1]]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_1_ReShearStress.npy\", np.array([y_in_D, u1_diff_xy_mean]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_2_ReShearStress.npy\", np.array([y_in_D, u2_diff_xy_mean]))\n",
    "        np.save(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_3_ReShearStress.npy\", np.array([y_in_D, u3_diff_xy_mean]))\n",
    "\n",
    "\n",
    "    fig, (ax_xx, ax_yy, ax_xy) = plt.subplots(1,3, figsize=(40*cm,10*cm), constrained_layout=True)\n",
    "    ax_xx.plot(y_in_D,u1_diff_sq_mean[0],y_in_D,u2_diff_sq_mean[0],y_in_D,u3_diff_sq_mean[0])\n",
    "    ax_xx.set_xlabel(\"y/D\")\n",
    "    ax_xx.set_ylabel(r\"$\\overline{u_{x}'u_{x}'}$/$u_{char}^2$\")\n",
    "    ax_xx.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_uxux.png\")\n",
    "    # plt.show()\n",
    "\n",
    "    #fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_yy.plot(y_in_D,u1_diff_sq_mean[1], y_in_D,u2_diff_sq_mean[1], y_in_D,u3_diff_sq_mean[1])\n",
    "    ax_yy.set_xlabel(\"y/D\")\n",
    "    ax_yy.set_ylabel(r\"$\\overline{u_{y}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax_yy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "    # if output_data:\n",
    "    #     plt.savefig(output_path+dir_name+\"/AvgVelocity_uyuy.png\")\n",
    "    # plt.show()\n",
    "\n",
    "    #fig, ax = plt.subplots(constrained_layout=True)\n",
    "    ax_xy.plot(y_in_D,u1_diff_xy_mean, y_in_D,u2_diff_xy_mean, y_in_D,u3_diff_xy_mean)\n",
    "    ax_xy.set_xlabel(\"y/D\")\n",
    "    ax_xy.set_ylabel(r\"$\\overline{u_{x}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax_xy.legend([\"x/D = 1.06\", \"x/D = 1.54\", \"x/D = 2.02\"])\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_reynoldsStresses_noReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    #plot reynolds stresses against reference\n",
    "    # uxux - streamwise\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D,u1_diff_sq_mean[0], y_in_D, u2_diff_sq_mean[0]-0.5, y_in_D, u3_diff_sq_mean[0]-1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uxux[:,0], p2_LS1993_uxux[:,1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uxux[:,0], p1_R2016_uxux[:,1], p3_R2016_uxux[:,0], p3_R2016_uxux[:,1], p3_R2016_uxux[:,0], p3_R2016_uxux[:,1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_KM = ax.plot(p1_KM2000_uxux[:,0], p1_KM2000_uxux[:,1], p2_KM2000_uxux[:,0], p2_KM2000_uxux[:,1], p3_KM2000_uxux[:,0], p3_KM2000_uxux[:,1])\n",
    "    plt.setp(ref_KM, ls=\"dotted\", lw=1.5, marker=\"\", color=\"k\", label=\"Kravchenko & Moin (2000)\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uxux[:,0], p2_BM1994_uxux[:,1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uxux[:,0], p1_DI2018_uxux[:,1], p2_DI2018_uxux[:,0], p2_DI2018_uxux[:,1], p3_DI2018_uxux[:,0], p3_DI2018_uxux[:,1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{x}'u_{x}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2,0.8])\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.legend(handles=[my_data[0], ref_LS[0], ref_R[0], ref_KM[0], ref_BM[0], ref_DI[0]], loc= 'best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_uxux_withReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # uyuy - cross-stream\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D,u1_diff_sq_mean[1], y_in_D, u2_diff_sq_mean[1]-0.5, y_in_D, u3_diff_sq_mean[1]-1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uyuy[:,0], p2_BM1994_uyuy[:,1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uyuy[:,0], p2_LS1993_uyuy[:,1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uyuy[:,0], p1_R2016_uyuy[:,1], p3_R2016_uyuy[:,0], p3_R2016_uyuy[:,1], p3_R2016_uyuy[:,0], p3_R2016_uyuy[:,1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uyuy[:,0], p1_DI2018_uyuy[:,1], p2_DI2018_uyuy[:,0], p2_DI2018_uyuy[:,1], p3_DI2018_uyuy[:,0], p3_DI2018_uyuy[:,1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{y}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2,0.8])\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.legend(handles=[my_data[0], ref_BM[0], ref_LS[0], ref_R[0], ref_DI[0]], loc='best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_uyuy_withReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # uxuy - Reynolds shear stress\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    my_data = ax.plot(y_in_D,u1_diff_xy_mean, y_in_D, u2_diff_xy_mean-0.5, y_in_D, u3_diff_xy_mean-1)\n",
    "    plt.setp(my_data, ls=\"-\", lw=1, marker=\"\", color=\"red\", label=\"lettuce\")\n",
    "    ref_BM = ax.plot(p2_BM1994_uxuy[:,0], p2_BM1994_uxuy[:,1])\n",
    "    plt.setp(ref_BM, ls=\"dashdot\", lw=1.5, marker=\"\", color=\"k\", label=\"Beaudan & Moin (1994)\")\n",
    "    ref_LS = ax.plot(p2_LS1993_uxuy[:,0], p2_LS1993_uxuy[:,1])\n",
    "    plt.setp(ref_LS, ls=\"\", lw=1, marker=\"s\", fillstyle='none', color=\"k\", label=\"Lorenco & Shih (1993)\")\n",
    "    ref_R = ax.plot(p1_R2016_uxuy[:,0], p1_R2016_uxuy[:,1], p3_R2016_uxuy[:,0], p3_R2016_uxuy[:,1], p3_R2016_uxuy[:,0], p3_R2016_uxuy[:,1])\n",
    "    plt.setp(ref_R, ls=\"--\", lw=1.5, marker=\"\", color=\"k\", label=\"Rajani et al. (2016)\")\n",
    "    ref_DI = ax.plot(p1_DI2018_uxuy[:,0], p1_DI2018_uxuy[:,1], p2_DI2018_uxuy[:,0], p2_DI2018_uxuy[:,1], p3_DI2018_uxuy[:,0], p3_DI2018_uxuy[:,1])\n",
    "    plt.setp(ref_DI, ls=\"--\", lw=1.5, marker=\"\", color=\"tab:blue\", label=\"Di Ilio et al. (2018)\")\n",
    "    ax.set_xlabel(\"y/D\")\n",
    "    ax.set_ylabel(r\"$\\overline{u_{x}'u_{y}'}$/$u_{char}^2$\")\n",
    "    ax.set_ylim([-1.2,0.8])\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.legend(handles=[my_data[0], ref_BM[0], ref_LS[0], ref_R[0], ref_DI[0]], loc='best')\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/AvgVelocity_Data\"+\"/AvgVelocity_uxuy_withReference.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # (!) standard plot/figure size in python is 6.4 x 4.8 inches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### plot Drag coefficient\n",
    "\n",
    "drag_coefficient = np.array(Dragreport.out)\n",
    "#print('  stepLU        ', 'timePU        ', 'Cd')\n",
    "#print(drag_coefficient) # prints: stepLU, timePU, value\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.plot(drag_coefficient[:,1],drag_coefficient[:,2])\n",
    "ax.set_xlabel(\"physical time / s\")\n",
    "ax.set_ylabel(\"Coefficient of Drag Cd\")\n",
    "ax.set_ylim([0.5,1.6])\n",
    "ax.set_ylim([0.5,3])\n",
    "secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "if output_data:  # save plot with standard y limits\n",
    "    plt.savefig(output_path+dir_name+\"/drag_coefficient.png\")\n",
    "    np.savetxt(output_path+dir_name+\"/drag_coefficient.txt\", drag_coefficient, header=\"stepLU  |  timePU  |  Cd  FROM str(timestamp)\")\n",
    "\n",
    "ax.set_ylim([drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].min()*0.5,drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].max()*1.2])\n",
    "if output_data:  # save plot with adjusted y limits\n",
    "    plt.savefig(output_path+dir_name+\"/drag_coefficient_adjusted.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### calculate mean drag_coefficient in periodic region:\n",
    "try:\n",
    "    values = drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2]\n",
    "\n",
    "    peaks_max = find_peaks(values, prominence=((values.max()-values.min())/2))\n",
    "    peaks_min = find_peaks(-values, prominence=((values.max()-values.min())/2))\n",
    "    # find peaks only works correctly, if simulation is converged in the periodic region...\n",
    "\n",
    "    if peaks_min[0].shape[0] - peaks_max[0].shape[0] > 0:\n",
    "        peak_number = peaks_max[0].shape[0]\n",
    "    else:\n",
    "        peak_number = peaks_min[0].shape[0]\n",
    "\n",
    "    if peaks_min[0][0] < peaks_max[0][0]:\n",
    "        first_peak = peaks_min[0][0]\n",
    "        last_peak = peaks_max[0][peak_number-1]\n",
    "    else:\n",
    "        first_peak = peaks_max[0][0]\n",
    "        last_peak = peaks_min[0][peak_number-1]\n",
    "\n",
    "    drag_mean = values[first_peak:last_peak].mean()\n",
    "    drag_mean_simple = values.mean()\n",
    "\n",
    "    print(\"Cd, simple mean:     \",drag_mean_simple)\n",
    "    print(\"Cd, peak_finder mean:\",drag_mean)\n",
    "    print(\"start time of 'mean'-ing:\",drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1),1])\n",
    "    ## plotting peaks from peak_finder:\n",
    "    drag_stepsLU = drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,0]\n",
    "    peak_max_y = values[peaks_max[0]]\n",
    "    peak_max_x = drag_stepsLU[peaks_max[0]]\n",
    "    peak_min_y = values[peaks_min[0]]\n",
    "    peak_min_x = drag_stepsLU[peaks_min[0]]\n",
    "\n",
    "    plt.plot(drag_stepsLU, values)\n",
    "    plt.scatter(peak_max_x[:peak_number],peak_max_y[:peak_number])\n",
    "    plt.scatter(peak_min_x[:peak_number],peak_min_y[:peak_number])\n",
    "    plt.scatter(drag_stepsLU[first_peak],values[first_peak])\n",
    "    plt.scatter(drag_stepsLU[last_peak],values[last_peak])\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/drag_coefficient_peakfinder.png\")\n",
    "    peakfinder=True\n",
    "except:\n",
    "    print(\"peak-finding didn't work... probably no significant peaks visible (Re<46?), or periodic region not reached (T too small)\")\n",
    "    values = drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2]\n",
    "    drag_mean_simple = values.mean()\n",
    "    peakfinder=False\n",
    "    print(\"Cd, simple mean:\",drag_mean_simple)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### plot Lift coefficient\n",
    "\n",
    "lift_coefficient = np.array(Liftreport.out)\n",
    "# print('  stepLU        ', 'timePU        ', 'Cl')\n",
    "# print(lift_coefficient) # prints: stepLU, timePU, value\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.plot(lift_coefficient[:,1],lift_coefficient[:,2])\n",
    "ax.set_xlabel(\"physical time / s\")\n",
    "ax.set_ylabel(\"Coefficient of Lift Cl\")\n",
    "ax.set_ylim([-1.1,1.1])\n",
    "secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "if output_data:\n",
    "    plt.savefig(output_path+dir_name+\"/lift_coefficient.png\")\n",
    "    np.savetxt(output_path+dir_name+\"/lift_coefficient.txt\", lift_coefficient, header=\"stepLU  |  timePU  |  Cl  FROM str(timestamp)\")\n",
    "plt.show()\n",
    "\n",
    "Cl_min = lift_coefficient[int(lift_coefficient[:,2].shape[0]*0.5):,2].min()\n",
    "Cl_max = lift_coefficient[int(lift_coefficient[:,2].shape[0]*0.5):,2].max()\n",
    "\n",
    "print(\"Cl_peaks: \\nmin\", Cl_min,\"\\nmax\", Cl_max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### prototyped fft for frequency detection and calculation of strouhal-number\n",
    "# ! Drag_frequency is 2* Strouhal-Freq. Lift-freq. is Strouhal-Freq.\n",
    "\n",
    "try:\n",
    "    X = np.fft.fft(lift_coefficient[:,2])   # fft result (amplitudes)\n",
    "    N = len(X)  # number of freqs\n",
    "    n = np.arange(N)   # freq index\n",
    "    T = N*flow.units.convert_time_to_pu(1)   # total time measured (T_PU)\n",
    "    freq = n/T   # frequencies (x-axis of spectrum)\n",
    "\n",
    "    plt.figure\n",
    "    plt.stem(freq, np.abs(X), 'b', markerfmt=\" \", basefmt=\"-b\")   # plot spectrum |X|(f)\n",
    "    plt.xlabel(\"Freq (Hz)\")\n",
    "    plt.ylabel(\"FFT Amplitude |X(freq)|\")\n",
    "    plt.xlim(0,1)\n",
    "    #print(\"max. Amplitude np.abx(X).max():\", np.abs(X).max())   # for debugging\n",
    "    plt.ylim(0,np.abs(X[:int(X.shape[0]*0.5)]).max())   # ylim, where highes peak is on left half of full spectrum\n",
    "\n",
    "    if output_data:\n",
    "        plt.savefig(output_path+dir_name+\"/fft_Cl.png\")\n",
    "\n",
    "    freq_res = freq[1]-freq[0]   # frequency-resolution\n",
    "    X_abs = np.abs(X[:int(X.shape[0]*0.4)])   # get |X| Amplitude for left half of full spectrum\n",
    "    freq_peak = freq[np.argmax(X_abs)]    # find frequency with the highest amplitude\n",
    "    print(\"Frequency Peak:\", freq_peak, \"+-\", freq_res, \"Hz\")\n",
    "    # f = Strouhal for St=f*D/U and D=U=1 in PU\n",
    "except:\n",
    "    print(\"Strouhal-calculation failed, check simulation data\")\n",
    "    freq_res=0\n",
    "    freq_peak=0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save notebook to simulation_output\n",
    "if output_data:\n",
    "    try:\n",
    "        shutil.copy(str(os.getcwd())+\"/cylinder3D_development_v2.ipynb\",output_path+dir_name+\"/script.ipynb\")\n",
    "    except:\n",
    "        print(\"script could not be saved\")\n",
    "else:\n",
    "    print(\"output_data-toggle is FALSE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### plot Drag coefficient AND Lift Coefficient\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "drag_ax = ax.plot(drag_coefficient[:,1],drag_coefficient[:,2], color=\"tab:blue\", label=\"Drag\")\n",
    "ax.set_xlabel(\"physical time / s\")\n",
    "ax.set_ylabel(\"Coefficient of Drag Cd\")\n",
    "ax.set_ylim([0.5,1.6])\n",
    "\n",
    "secax = ax.secondary_xaxis('top', functions=(flow.units.convert_time_to_lu, flow.units.convert_time_to_pu))\n",
    "secax.set_xlabel(\"timesteps (simulation time / LU)\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "lift_ax = ax2.plot(lift_coefficient[:,1],lift_coefficient[:,2], color=\"tab:orange\", label=\"Lift\")\n",
    "ax2.set_ylabel(\"Coefficient of Lift Cl\")\n",
    "ax2.set_ylim([-1.1,1.1])\n",
    "\n",
    "\n",
    "fig.legend(loc=\"upper left\", bbox_to_anchor=(0,1), bbox_transform=ax.transAxes)\n",
    "\n",
    "if output_data:\n",
    "    plt.savefig(output_path+dir_name+\"/dragAndLift_coefficient.png\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Analysis of GPU memory usage (tensors)\n",
    "\n",
    "if output_data:\n",
    "### cudas own memory summary\n",
    "    print(torch.cuda.memory_summary(device=\"cuda:0\"))\n",
    "    ### CUDA-VRAM-summary:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_GPU_memory_summary.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \"+timestamp+\"\\n\\n\")\n",
    "    output_file.write(torch.cuda.memory_summary(device=\"cuda:0\"))\n",
    "    output_file.close()\n",
    "\n",
    "### list present torch tensors:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_GPU_list_of_tensors.txt\", \"a\")\n",
    "    total_bytes = 0\n",
    "    import gc\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj,'data') and torch.is_tensor(obj.data)):\n",
    "                output_file.write(\"\\n\"+str(obj.size())+\", \"+str(obj.nelement()*obj.element_size()))\n",
    "                total_bytes = total_bytes+obj.nelement()*obj.element_size()\n",
    "        except:\n",
    "            pass\n",
    "    #output_file.write(\"\\n\\ntotal bytes for tensors:\"+str(total_bytes))\n",
    "    output_file.close()\n",
    "\n",
    "### count occurence of tensors in list of tensors:\n",
    "    from collections import Counter\n",
    "    my_file = open(output_path+dir_name+\"/\"+timestamp + \"_GPU_list_of_tensors.txt\",\"r\")\n",
    "    data=my_file.read()\n",
    "    my_file.close()\n",
    "    data_into_list=data.split(\"\\n\")\n",
    "    c = Counter(data_into_list)\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_GPU_counted_tensors.txt\", \"a\")\n",
    "    for k,v in c.items():\n",
    "        output_file.write(\"type,size,bytes: {}, number: {}\\n\".format(k,v) )\n",
    "    output_file.write(\"\\ntotal bytes for tensors:\"+str(total_bytes))\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# output data\n",
    "if output_data:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_parms_stats_obs.txt\", \"a\")\n",
    "    output_file.write(\"DATA for \"+timestamp)\n",
    "    output_file.write(\"\\n\\n###   SIM-Parameters   ###\")\n",
    "    output_file.write(\"\\nRe = \"+str(re))\n",
    "    output_file.write(\"\\nn_steps = \"+str(n_steps))\n",
    "    output_file.write(\"\\nT_target = \"+str(flow.units.convert_time_to_pu(n_steps))+\" seconds\")\n",
    "    output_file.write(\"\\ngridpoints_per_diameter (gpd) = \"+str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \"+str(gpd_setup)+\" to \"+str(gridpoints_per_diameter)+\" because D/Y is even\")\n",
    "    output_file.write(\"\\nDpX (D/X) = \" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\nDpY (D/Y) = \"+str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\nDpZ (D/Z) = \"+str(domain_width_in_D))\n",
    "    output_file.write(\"\\nshape_LU: \"+ str(flow.shape))\n",
    "    output_file.write((\"\\ntotal_number_of_gridpoints: \"+str(lattice.rho(sim.f).numel())))\n",
    "    output_file.write(\"\\nbc_type = \"+str(bc_type))\n",
    "    output_file.write(\"\\nlateral_walls = \"+str(lateral_walls))\n",
    "    output_file.write(\"\\nstencil = \"+str(stencil_choice))\n",
    "    output_file.write(\"\\ncollision = \" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nMa = \" + str(Ma))\n",
    "    output_file.write(\"\\ntau = \" + str(tau))\n",
    "    output_file.write(\"\\ngrid_reynolds_number (Re_g) = \" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nsetup_diameter_PU = \" + str(setup_diameter))\n",
    "    output_file.write(\"\\nflow_velocity_PU = \" + str(flow_velocity))\n",
    "    output_file.write(\"\\nu_init = \" + str(u_init))\n",
    "    output_file.write(\"\\nperturb_init = \" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\noutput_vtk = \" + str(output_vtk))\n",
    "    output_file.write(\"\\nvtk_fps = \" + str(vtk_fps))\n",
    "\n",
    "    output_file.write(\"\\n\\n###   SIM-STATS  ###\")\n",
    "    output_file.write(\"\\nruntime = \"+str(runtime)+ \" seconds (=\"+str(runtime/60)+\" minutes)\")\n",
    "    output_file.write(\"\\nMLUPS = \"+str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\navg. Collision-Time [s] = \" + str(c_time) + \" (\" + str(round(100 * c_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. store_fcl-Time [s] = \" + str(fc_time) + \" (\" + str(round(100 * fc_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Streaming-Time [s] = \" + str(s_time) + \" (\" + str(round(100 * s_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Boundary-Time  [s] = \" + str(b_time) + \" (\" + str(round(100 * b_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\navg. Reporter-Time  [s] = \" + str(r_time) + \" (\" + str(round(100 * r_time/sum_time, 2)) + \" %)\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nVRAM_current [MB] = \" + str(torch.cuda.memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\nVRAM_peak [MB] = \" + str(torch.cuda.max_memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nCPU load % avg. over last 1, 5, 15 min: \" + str(round(cpuLoad1, 2)) + \" %, \" + str(round(cpuLoad5, 2)) + \" %, \" + str(round(cpuLoad15, 2)) + \" %\")\n",
    "    output_file.write(\"\\ntotal current RAM usage [MB]: \" + str(round(ram.used/(1024*1024),2)) + \" of \" + str(round(ram.total/(1024*1024),2)) + \" MB\")\n",
    "\n",
    "    output_file.write(\"\\n\\n###   OBSERVABLES   ###\")\n",
    "    output_file.write(\"\\nCoefficient of drag between \"+str(round(drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1),1],2))+\" s and \"+str(round(drag_coefficient[int(drag_coefficient.shape[0]-1),1],2))+\" s:\")\n",
    "    output_file.write(\"\\nCd_mean, simple      = \"+str(drag_mean_simple))\n",
    "    if peakfinder:\n",
    "        output_file.write(\"\\nCd_mean, peak_finder = \"+str(drag_mean))\n",
    "    else:\n",
    "        output_file.write(\"\\nnoPeaksFound\")\n",
    "    output_file.write(\"\\nCd_min = \"+str(drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].min()))\n",
    "    output_file.write(\"\\nCd_max = \"+str(drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].max()))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nCoefficient of lift:\")\n",
    "    output_file.write(\"\\nCl_min = \"+str(Cl_min))\n",
    "    output_file.write(\"\\nCl_max = \"+str(Cl_max))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\nStrouhal number:\")\n",
    "    output_file.write(\"\\nSt +- df = \"+str(freq_peak)+\" +- \"+str(freq_res)+\" Hz\")\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if output_data:\n",
    "    output_file = open(output_path+dir_name+\"/\"+timestamp + \"_parms_stats_obs_copyable.txt\", \"a\")\n",
    "\n",
    "    output_file.write(\"DATA for \"+timestamp)\n",
    "    output_file.write(\"\\n\\n###   Data:   ###\")\n",
    "    output_file.write(\"\\nRe, n_steps, t_target(PU), GPD, DpX, DpY, (DpZ), shape_LU, gridpoints, bc_type, lateral_walls, stencil, collision, Ma, tau, Re_grid, setup_diameter_PU, flow_velocity_PU, u_init, perturb_init, output_vtk, vtk_fps, runtime, MLUPS, c_time, fc_time, s_time, b_time, r_time, VRAM_current_MB, VRAM_peak_MB, periodic_start, Cd_mean, Cd_mean_pf, Cd_min, Cd_max, Cl_min, Cl_max, St, df\")\n",
    "    output_file.write(\"\\n\" + str(re))\n",
    "    output_file.write(\"\\n\" + str(n_steps))\n",
    "    output_file.write(\"\\n\" + str(flow.units.convert_time_to_pu(n_steps)))\n",
    "    output_file.write(\"\\n\" + str(gridpoints_per_diameter))\n",
    "    if gpd_correction:\n",
    "        output_file.write(\"\\ngpd was corrected from: \"+str(gpd_setup)+\" to \"+str(gridpoints_per_diameter)+\" because D/Y is even\")\n",
    "    output_file.write(\"\\n\" + str(domain_length_in_D))\n",
    "    output_file.write(\"\\n\" + str(domain_height_in_D))\n",
    "    if lattice.D == 3:\n",
    "        output_file.write(\"\\n\" + str(domain_width_in_D))\n",
    "    output_file.write(\"\\n\" + str(flow.shape))\n",
    "    output_file.write(\"\\n\" + str(lattice.rho(sim.f).numel()))\n",
    "    output_file.write(\"\\n\"+str(bc_type))\n",
    "    output_file.write(\"\\n\"+str(lateral_walls))\n",
    "    output_file.write(\"\\n\"+str(stencil_choice))\n",
    "    output_file.write(\"\\n\" + str(collision_choice))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(Ma))\n",
    "    output_file.write(\"\\n\" + str(tau))\n",
    "    output_file.write(\"\\n\" + str(re_g))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(setup_diameter))\n",
    "    output_file.write(\"\\n\" + str(flow_velocity))\n",
    "    output_file.write(\"\\n\" + str(u_init))\n",
    "    output_file.write(\"\\n\" + str(perturb_init))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(output_vtk))\n",
    "    output_file.write(\"\\n\" + str(vtk_fps))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "    output_file.write(\"\\n\"+str(runtime))\n",
    "    output_file.write(\"\\n\"+str(mlups))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(c_time))\n",
    "    output_file.write(\"\\n\" + str(fc_time))\n",
    "    output_file.write(\"\\n\" + str(s_time))\n",
    "    output_file.write(\"\\n\" + str(b_time))\n",
    "    output_file.write(\"\\n\" + str(r_time))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\" + str(torch.cuda.memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\n\" + str(torch.cuda.max_memory_allocated(lattice.device)/1024/1024))\n",
    "    output_file.write(\"\\n\")\n",
    "\n",
    "    output_file.write(\"\\n\" + str(periodic_start))\n",
    "    output_file.write(\"\\n\"+str(drag_mean_simple))\n",
    "    if peakfinder:\n",
    "        output_file.write(\"\\n\"+str(drag_mean))\n",
    "    else:\n",
    "        output_file.write(\"\\nnoPeaksFound\")\n",
    "    output_file.write(\"\\n\"+str(drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].min()))\n",
    "    output_file.write(\"\\n\"+str(drag_coefficient[int(drag_coefficient.shape[0]*periodic_start-1):,2].max()))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\"+str(Cl_min))\n",
    "    output_file.write(\"\\n\"+str(Cl_max))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.write(\"\\n\"+str(freq_peak))\n",
    "    output_file.write(\"\\n\"+str(freq_res))\n",
    "    output_file.write(\"\\n\")\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"current VRAM (MB): \", torch.cuda.memory_allocated(device=\"cuda:0\")/1024/1024)\n",
    "print(\"max. VRAM (MB): \", torch.cuda.max_memory_allocated(device=\"cuda:0\")/1024/1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
